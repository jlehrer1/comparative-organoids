{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382382fc",
   "metadata": {},
   "source": [
    "# TabNet Model Test\n",
    "\n",
    "In this notebook, we'll test a training loop for the TabNet model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee99168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.lib.neural import *\n",
    "from models.lib.data import *\n",
    "from models.lib.train import train_loop\n",
    "\n",
    "from helper import gene_intersection\n",
    "from pytorch_tabnet.tab_network import TabNet\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08f142",
   "metadata": {},
   "source": [
    "First, we'll define our train, val and test sets, then generate the associated DataLoaders and try training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a49e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_single_dataset(\n",
    "    datafile='../data/interim/primary_bhaduri_T.csv',\n",
    "    labelfile='../data/processed/labels/primary_bhaduri_labels.csv',\n",
    "    class_label='Type',\n",
    "    normalize=True,\n",
    "    skip=3,\n",
    ")\n",
    "\n",
    "refgenes = gene_intersection()\n",
    "currgenes = train.dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce9fcef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([0., 0., 0.,  ..., 0., 0., 0.]), 4),\n",
       " (tensor([0., 0., 0.,  ..., 0., 0., 0.]), 4),\n",
       " (tensor([0., 0., 0.,  ..., 0., 0., 0.]), 4))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0], val[0], test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4616620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149180, 37296, 37296)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08d28a",
   "metadata": {},
   "source": [
    "Now, we'll subset and define our DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3d56255",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Subset(train, range(10))\n",
    "val = Subset(train, range(10))\n",
    "test = Subset(test, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a294382",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(train, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22819810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0477, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1793, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0.0000, 0.1265, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train:\n",
    "    print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "701767d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1281, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train))[0]\n",
    "sample = clean_sample(sample, refgenes, currgenes)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "975322f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabNet(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=18,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31634cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TabNetClassifier' object has no attribute '__attr__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_61260/949045621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabNetClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__attr__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabNetClassifier' object has no attribute '__attr__'"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "classifier = TabNetClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b36a0f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, running loss is 0.003861255943775177\n",
      "Epoch 1, running loss is 0.0038433924317359926\n",
      "Epoch 2, running loss is 0.0038303643465042113\n",
      "Epoch 3, running loss is 0.0038204428553581236\n",
      "Epoch 4, running loss is 0.003812532424926758\n",
      "Epoch 5, running loss is 0.0038059064745903015\n",
      "Epoch 6, running loss is 0.003800087571144104\n",
      "Epoch 7, running loss is 0.0037947577238082886\n",
      "Epoch 8, running loss is 0.0037896955013275147\n",
      "Epoch 9, running loss is 0.0037847691774368286\n",
      "Epoch 10, running loss is 0.0037798789143562318\n",
      "Epoch 11, running loss is 0.0037749558687210083\n",
      "Epoch 12, running loss is 0.0037699565291404724\n",
      "Epoch 13, running loss is 0.003764839470386505\n",
      "Epoch 14, running loss is 0.0037595871090888976\n",
      "Epoch 15, running loss is 0.0037541866302490236\n",
      "Epoch 16, running loss is 0.003748604357242584\n",
      "Epoch 17, running loss is 0.0037428417801856993\n",
      "Epoch 18, running loss is 0.0037368693947792053\n",
      "Epoch 19, running loss is 0.0037306669354438783\n",
      "Epoch 20, running loss is 0.003724181056022644\n",
      "Epoch 21, running loss is 0.003717319071292877\n",
      "Epoch 22, running loss is 0.0037097367644309998\n",
      "Epoch 23, running loss is 0.0036991393566131593\n",
      "Epoch 24, running loss is 0.003584144115447998\n",
      "Epoch 25, running loss is 0.0035640886425971985\n",
      "Epoch 26, running loss is 0.003555639386177063\n",
      "Epoch 27, running loss is 0.0035477784276008607\n",
      "Epoch 28, running loss is 0.0035400742292404173\n",
      "Epoch 29, running loss is 0.0035322555899620057\n",
      "Epoch 30, running loss is 0.0035240623354911805\n",
      "Epoch 31, running loss is 0.0035149723291397093\n",
      "Epoch 32, running loss is 0.003492993116378784\n",
      "Epoch 33, running loss is 0.003467039167881012\n",
      "Epoch 34, running loss is 0.003426077365875244\n",
      "Epoch 35, running loss is 0.0033756399154663084\n",
      "Epoch 36, running loss is 0.0033138930797576905\n",
      "Epoch 37, running loss is 0.006055089235305786\n",
      "Epoch 38, running loss is 0.008555739521980285\n",
      "Epoch 39, running loss is 0.00850286841392517\n",
      "Epoch 40, running loss is 0.00845530092716217\n",
      "Epoch 41, running loss is 0.008405460715293885\n",
      "Epoch 42, running loss is 0.008355497121810914\n",
      "Epoch 43, running loss is 0.008306251168251037\n",
      "Epoch 44, running loss is 0.008257696032524109\n",
      "Epoch 45, running loss is 0.008209798336029053\n",
      "Epoch 46, running loss is 0.008162513971328736\n",
      "Epoch 47, running loss is 0.008115716576576233\n",
      "Epoch 48, running loss is 0.008069311380386352\n",
      "Epoch 49, running loss is 0.008023241758346558\n",
      "Epoch 50, running loss is 0.007977464199066163\n",
      "Epoch 51, running loss is 0.007931754589080811\n",
      "Epoch 52, running loss is 0.007886003255844116\n",
      "Epoch 53, running loss is 0.007840362191200257\n",
      "Epoch 54, running loss is 0.007794927358627319\n",
      "Epoch 55, running loss is 0.0077497738599777224\n",
      "Epoch 56, running loss is 0.007704952359199524\n",
      "Epoch 57, running loss is 0.007660484313964844\n",
      "Epoch 58, running loss is 0.007616404294967651\n",
      "Epoch 59, running loss is 0.007572712898254394\n",
      "Epoch 60, running loss is 0.00752941906452179\n",
      "Epoch 61, running loss is 0.0074865293502807614\n",
      "Epoch 62, running loss is 0.007444061636924744\n",
      "Epoch 63, running loss is 0.007406413555145264\n",
      "Epoch 64, running loss is 0.007372821569442749\n",
      "Epoch 65, running loss is 0.007341585159301758\n",
      "Epoch 66, running loss is 0.007311667203903198\n",
      "Epoch 67, running loss is 0.0072824424505233765\n",
      "Epoch 68, running loss is 0.007253553867340088\n",
      "Epoch 69, running loss is 0.00722476601600647\n",
      "Epoch 70, running loss is 0.007195926308631897\n",
      "Epoch 71, running loss is 0.007166978120803833\n",
      "Epoch 72, running loss is 0.00713786780834198\n",
      "Epoch 73, running loss is 0.007108584046363831\n",
      "Epoch 74, running loss is 0.007079139947891235\n",
      "Epoch 75, running loss is 0.007049582600593567\n",
      "Epoch 76, running loss is 0.007019879817962646\n",
      "Epoch 77, running loss is 0.006990039944648743\n",
      "Epoch 78, running loss is 0.0069600921869277955\n",
      "Epoch 79, running loss is 0.00693004846572876\n",
      "Epoch 80, running loss is 0.006899924278259278\n",
      "Epoch 81, running loss is 0.0068697422742843624\n",
      "Epoch 82, running loss is 0.006839525699615478\n",
      "Epoch 83, running loss is 0.00680927574634552\n",
      "Epoch 84, running loss is 0.006779024600982666\n",
      "Epoch 85, running loss is 0.006748775839805603\n",
      "Epoch 86, running loss is 0.006718559861183166\n",
      "Epoch 87, running loss is 0.006688379049301148\n",
      "Epoch 88, running loss is 0.006658248901367188\n",
      "Epoch 89, running loss is 0.006628182530403137\n",
      "Epoch 90, running loss is 0.006598188877105713\n",
      "Epoch 91, running loss is 0.006568286418914795\n",
      "Epoch 92, running loss is 0.0065384840965270995\n",
      "Epoch 93, running loss is 0.006508783102035522\n",
      "Epoch 94, running loss is 0.0064792042970657346\n",
      "Epoch 95, running loss is 0.006449747085571289\n",
      "Epoch 96, running loss is 0.006420424580574036\n",
      "Epoch 97, running loss is 0.006391240358352661\n",
      "Epoch 98, running loss is 0.0063621985912322996\n",
      "Epoch 99, running loss is 0.006333310604095459\n",
      "Epoch 100, running loss is 0.0063045734167099\n",
      "Epoch 101, running loss is 0.006275993585586548\n",
      "Epoch 102, running loss is 0.00624755859375\n",
      "Epoch 103, running loss is 0.0062192374467849735\n",
      "Epoch 104, running loss is 0.00619066059589386\n",
      "Epoch 105, running loss is 0.006163176894187927\n",
      "Epoch 106, running loss is 0.006138207912445068\n",
      "Epoch 107, running loss is 0.006114670634269714\n",
      "Epoch 108, running loss is 0.0060918772220611575\n",
      "Epoch 109, running loss is 0.006069394946098328\n",
      "Epoch 110, running loss is 0.00604694128036499\n",
      "Epoch 111, running loss is 0.006024355292320252\n",
      "Epoch 112, running loss is 0.006001541018486023\n",
      "Epoch 113, running loss is 0.005978447794914246\n",
      "Epoch 114, running loss is 0.005955067873001099\n",
      "Epoch 115, running loss is 0.005931403040885925\n",
      "Epoch 116, running loss is 0.005907474160194397\n",
      "Epoch 117, running loss is 0.005883325934410095\n",
      "Epoch 118, running loss is 0.005859008431434632\n",
      "Epoch 119, running loss is 0.005834710597991943\n",
      "Epoch 120, running loss is 0.0058107304573059085\n",
      "Epoch 121, running loss is 0.005787014365196228\n",
      "Epoch 122, running loss is 0.00576342225074768\n",
      "Epoch 123, running loss is 0.005739845633506775\n",
      "Epoch 124, running loss is 0.005716217160224915\n",
      "Epoch 125, running loss is 0.005692551136016846\n",
      "Epoch 126, running loss is 0.005668839812278748\n",
      "Epoch 127, running loss is 0.005645034909248352\n",
      "Epoch 128, running loss is 0.005621099472045898\n",
      "Epoch 129, running loss is 0.0055970227718353275\n",
      "Epoch 130, running loss is 0.005572822690010071\n",
      "Epoch 131, running loss is 0.005548498034477234\n",
      "Epoch 132, running loss is 0.005524061918258667\n",
      "Epoch 133, running loss is 0.005499534010887146\n",
      "Epoch 134, running loss is 0.005474943518638611\n",
      "Epoch 135, running loss is 0.00545029878616333\n",
      "Epoch 136, running loss is 0.005425631403923035\n",
      "Epoch 137, running loss is 0.005400943756103516\n",
      "Epoch 138, running loss is 0.0053762710094451905\n",
      "Epoch 139, running loss is 0.0053516185283660886\n",
      "Epoch 140, running loss is 0.005326998233795166\n",
      "Epoch 141, running loss is 0.005302435755729675\n",
      "Epoch 142, running loss is 0.005277932286262512\n",
      "Epoch 143, running loss is 0.005253498554229736\n",
      "Epoch 144, running loss is 0.00522915244102478\n",
      "Epoch 145, running loss is 0.005204908847808838\n",
      "Epoch 146, running loss is 0.005180751085281372\n",
      "Epoch 147, running loss is 0.005156701803207398\n",
      "Epoch 148, running loss is 0.005132761597633362\n",
      "Epoch 149, running loss is 0.005108940005302429\n",
      "Epoch 150, running loss is 0.005085230469703674\n",
      "Epoch 151, running loss is 0.0050616395473480225\n",
      "Epoch 152, running loss is 0.005038161873817444\n",
      "Epoch 153, running loss is 0.005014796257019043\n",
      "Epoch 154, running loss is 0.00499152660369873\n",
      "Epoch 155, running loss is 0.004968333542346954\n",
      "Epoch 156, running loss is 0.00494516521692276\n",
      "Epoch 157, running loss is 0.004921945333480835\n",
      "Epoch 158, running loss is 0.00489847719669342\n",
      "Epoch 159, running loss is 0.004874249696731567\n",
      "Epoch 160, running loss is 0.004847676753997803\n",
      "Epoch 161, running loss is 0.005200695395469666\n",
      "Epoch 162, running loss is 0.00481104165315628\n",
      "Epoch 163, running loss is 0.004785133600234985\n",
      "Epoch 164, running loss is 0.00475964367389679\n",
      "Epoch 165, running loss is 0.004734668433666229\n",
      "Epoch 166, running loss is 0.0047100579738616945\n",
      "Epoch 167, running loss is 0.004685359001159668\n",
      "Epoch 168, running loss is 0.004660466015338898\n",
      "Epoch 169, running loss is 0.004635772109031678\n",
      "Epoch 170, running loss is 0.004611504673957825\n",
      "Epoch 171, running loss is 0.004587804973125458\n",
      "Epoch 172, running loss is 0.0045647165179252625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173, running loss is 0.004542267024517059\n",
      "Epoch 174, running loss is 0.004520441591739655\n",
      "Epoch 175, running loss is 0.004499209523200989\n",
      "Epoch 176, running loss is 0.004478539526462555\n",
      "Epoch 177, running loss is 0.004458394646644592\n",
      "Epoch 178, running loss is 0.004438740313053131\n",
      "Epoch 179, running loss is 0.004419521391391754\n",
      "Epoch 180, running loss is 0.004400703012943268\n",
      "Epoch 181, running loss is 0.004382257461547852\n",
      "Epoch 182, running loss is 0.0043641459941864014\n",
      "Epoch 183, running loss is 0.004346339702606201\n",
      "Epoch 184, running loss is 0.0043288213014602665\n",
      "Epoch 185, running loss is 0.004311559796333313\n",
      "Epoch 186, running loss is 0.004294542074203492\n",
      "Epoch 187, running loss is 0.004277738332748413\n",
      "Epoch 188, running loss is 0.004261143505573273\n",
      "Epoch 189, running loss is 0.00424473375082016\n",
      "Epoch 190, running loss is 0.004228494763374328\n",
      "Epoch 191, running loss is 0.004212416112422943\n",
      "Epoch 192, running loss is 0.004196484982967377\n",
      "Epoch 193, running loss is 0.004180691838264465\n",
      "Epoch 194, running loss is 0.004165025651454926\n",
      "Epoch 195, running loss is 0.00414949357509613\n",
      "Epoch 196, running loss is 0.004134084284305573\n",
      "Epoch 197, running loss is 0.004118777513504028\n",
      "Epoch 198, running loss is 0.0041035693883895875\n",
      "Epoch 199, running loss is 0.00408845454454422\n",
      "Epoch 200, running loss is 0.004073435962200164\n",
      "Epoch 201, running loss is 0.004058507978916168\n",
      "Epoch 202, running loss is 0.004043671786785125\n",
      "Epoch 203, running loss is 0.004028919041156769\n",
      "Epoch 204, running loss is 0.004014253914356232\n",
      "Epoch 205, running loss is 0.0039996904134750365\n",
      "Epoch 206, running loss is 0.0039852079749107365\n",
      "Epoch 207, running loss is 0.003970785140991211\n",
      "Epoch 208, running loss is 0.003956425189971924\n",
      "Epoch 209, running loss is 0.003942142426967621\n",
      "Epoch 210, running loss is 0.003927944004535675\n",
      "Epoch 211, running loss is 0.003913828432559967\n",
      "Epoch 212, running loss is 0.003899793326854706\n",
      "Epoch 213, running loss is 0.0038858255743980407\n",
      "Epoch 214, running loss is 0.003871929347515106\n",
      "Epoch 215, running loss is 0.0038581034541130066\n",
      "Epoch 216, running loss is 0.0038443470001220705\n",
      "Epoch 217, running loss is 0.0038306528329849245\n",
      "Epoch 218, running loss is 0.0038170289993286134\n",
      "Epoch 219, running loss is 0.0038034671545028684\n",
      "Epoch 220, running loss is 0.003789968192577362\n",
      "Epoch 221, running loss is 0.003776530623435974\n",
      "Epoch 222, running loss is 0.0037631624937057495\n",
      "Epoch 223, running loss is 0.003749851882457733\n",
      "Epoch 224, running loss is 0.003736605644226074\n",
      "Epoch 225, running loss is 0.0037234225869178772\n",
      "Epoch 226, running loss is 0.0037102997303009033\n",
      "Epoch 227, running loss is 0.003697240948677063\n",
      "Epoch 228, running loss is 0.003684239983558655\n",
      "Epoch 229, running loss is 0.003671298623085022\n",
      "Epoch 230, running loss is 0.0036584219336509706\n",
      "Epoch 231, running loss is 0.003645603656768799\n",
      "Epoch 232, running loss is 0.003632842302322388\n",
      "Epoch 233, running loss is 0.003620140850543976\n",
      "Epoch 234, running loss is 0.0036074957251548767\n",
      "Epoch 235, running loss is 0.003594907522201538\n",
      "Epoch 236, running loss is 0.003582383394241333\n",
      "Epoch 237, running loss is 0.0035699141025543214\n",
      "Epoch 238, running loss is 0.003557509183883667\n",
      "Epoch 239, running loss is 0.0035451698303222657\n",
      "Epoch 240, running loss is 0.0035328859090805052\n",
      "Epoch 241, running loss is 0.003520660400390625\n",
      "Epoch 242, running loss is 0.00350847452878952\n",
      "Epoch 243, running loss is 0.0034963491559028624\n",
      "Epoch 244, running loss is 0.003484267294406891\n",
      "Epoch 245, running loss is 0.0034722268581390383\n",
      "Epoch 246, running loss is 0.0034602442383766174\n",
      "Epoch 247, running loss is 0.0034483343362808226\n",
      "Epoch 248, running loss is 0.0034365028142929075\n",
      "Epoch 249, running loss is 0.0034247344732284547\n",
      "Epoch 250, running loss is 0.003413017690181732\n",
      "Epoch 251, running loss is 0.003401362597942352\n",
      "Epoch 252, running loss is 0.0033897531032562257\n",
      "Epoch 253, running loss is 0.0033782032132148743\n",
      "Epoch 254, running loss is 0.0033666974306106566\n",
      "Epoch 255, running loss is 0.0033552435040473936\n",
      "Epoch 256, running loss is 0.003343835175037384\n",
      "Epoch 257, running loss is 0.0033324754238128664\n",
      "Epoch 258, running loss is 0.0033211755752563478\n",
      "Epoch 259, running loss is 0.0033099168539047243\n",
      "Epoch 260, running loss is 0.003298715054988861\n",
      "Epoch 261, running loss is 0.0032875528931617737\n",
      "Epoch 262, running loss is 0.0032764437794685366\n",
      "Epoch 263, running loss is 0.0032653805613517763\n",
      "Epoch 264, running loss is 0.003254367411136627\n",
      "Epoch 265, running loss is 0.0032434046268463137\n",
      "Epoch 266, running loss is 0.0032324820756912233\n",
      "Epoch 267, running loss is 0.0032216131687164305\n",
      "Epoch 268, running loss is 0.003210805356502533\n",
      "Epoch 269, running loss is 0.0032000550627708435\n",
      "Epoch 270, running loss is 0.003189338147640228\n",
      "Epoch 271, running loss is 0.0031786584854125977\n",
      "Epoch 272, running loss is 0.0031680262088775637\n",
      "Epoch 273, running loss is 0.003157428503036499\n",
      "Epoch 274, running loss is 0.0031468838453292845\n",
      "Epoch 275, running loss is 0.0031363752484321592\n",
      "Epoch 276, running loss is 0.0031259161233901976\n",
      "Epoch 277, running loss is 0.0031155121326446535\n",
      "Epoch 278, running loss is 0.0031051620841026305\n",
      "Epoch 279, running loss is 0.0030948448181152342\n",
      "Epoch 280, running loss is 0.003084566593170166\n",
      "Epoch 281, running loss is 0.0030743226408958433\n",
      "Epoch 282, running loss is 0.003064118027687073\n",
      "Epoch 283, running loss is 0.003053950369358063\n",
      "Epoch 284, running loss is 0.003043825328350067\n",
      "Epoch 285, running loss is 0.003033756613731384\n",
      "Epoch 286, running loss is 0.0030237385630607606\n",
      "Epoch 287, running loss is 0.003013744652271271\n",
      "Epoch 288, running loss is 0.0030037748813629152\n",
      "Epoch 289, running loss is 0.0029938390851020815\n",
      "Epoch 290, running loss is 0.002983931005001068\n",
      "Epoch 291, running loss is 0.0029740464687347413\n",
      "Epoch 292, running loss is 0.002964177131652832\n",
      "Epoch 293, running loss is 0.0029543244838714598\n",
      "Epoch 294, running loss is 0.0029444944858551024\n",
      "Epoch 295, running loss is 0.0029346290230751037\n",
      "Epoch 296, running loss is 0.002924717366695404\n",
      "Epoch 297, running loss is 0.002914774715900421\n",
      "Epoch 298, running loss is 0.0029048365354537964\n",
      "Epoch 299, running loss is 0.0028949224948883055\n",
      "Epoch 300, running loss is 0.002885041534900665\n",
      "Epoch 301, running loss is 0.0028752130270004272\n",
      "Epoch 302, running loss is 0.002865435481071472\n",
      "Epoch 303, running loss is 0.0028557202219963076\n",
      "Epoch 304, running loss is 0.0028460550308227538\n",
      "Epoch 305, running loss is 0.0028364482522010804\n",
      "Epoch 306, running loss is 0.0028268980979919436\n",
      "Epoch 307, running loss is 0.0028173822164535524\n",
      "Epoch 308, running loss is 0.0028079172968864443\n",
      "Epoch 309, running loss is 0.0027985358238220214\n",
      "Epoch 310, running loss is 0.0027892225980758667\n",
      "Epoch 311, running loss is 0.002779967188835144\n",
      "Epoch 312, running loss is 0.002770769000053406\n",
      "Epoch 313, running loss is 0.002761615216732025\n",
      "Epoch 314, running loss is 0.002752505540847778\n",
      "Epoch 315, running loss is 0.002743444740772247\n",
      "Epoch 316, running loss is 0.002734423577785492\n",
      "Epoch 317, running loss is 0.0027254381775856018\n",
      "Epoch 318, running loss is 0.002716493904590607\n",
      "Epoch 319, running loss is 0.002707589864730835\n",
      "Epoch 320, running loss is 0.0026987236738204956\n",
      "Epoch 321, running loss is 0.002689887881278992\n",
      "Epoch 322, running loss is 0.002681100368499756\n",
      "Epoch 323, running loss is 0.0026723411679267883\n",
      "Epoch 324, running loss is 0.002663639783859253\n",
      "Epoch 325, running loss is 0.0026549765467643737\n",
      "Epoch 326, running loss is 0.0026463404297828673\n",
      "Epoch 327, running loss is 0.002637738585472107\n",
      "Epoch 328, running loss is 0.0026291733980178832\n",
      "Epoch 329, running loss is 0.0026206159591674804\n",
      "Epoch 330, running loss is 0.002612074911594391\n",
      "Epoch 331, running loss is 0.0026035505533218385\n",
      "Epoch 332, running loss is 0.00259505033493042\n",
      "Epoch 333, running loss is 0.002586568892002106\n",
      "Epoch 334, running loss is 0.0025781354308128356\n",
      "Epoch 335, running loss is 0.002569744884967804\n",
      "Epoch 336, running loss is 0.002561367750167847\n",
      "Epoch 337, running loss is 0.0025530126690864563\n",
      "Epoch 338, running loss is 0.002544685006141663\n",
      "Epoch 339, running loss is 0.0025363841652870176\n",
      "Epoch 340, running loss is 0.002528117001056671\n",
      "Epoch 341, running loss is 0.002519880533218384\n",
      "Epoch 342, running loss is 0.0025116923451423646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343, running loss is 0.002503548264503479\n",
      "Epoch 344, running loss is 0.0024954354763031005\n",
      "Epoch 345, running loss is 0.002487339377403259\n",
      "Epoch 346, running loss is 0.0024792774021625517\n",
      "Epoch 347, running loss is 0.00247123658657074\n",
      "Epoch 348, running loss is 0.00246323361992836\n",
      "Epoch 349, running loss is 0.00245527982711792\n",
      "Epoch 350, running loss is 0.002447372376918793\n",
      "Epoch 351, running loss is 0.002439487725496292\n",
      "Epoch 352, running loss is 0.0024316222965717316\n",
      "Epoch 353, running loss is 0.002423783242702484\n",
      "Epoch 354, running loss is 0.0024159781634807585\n",
      "Epoch 355, running loss is 0.002408214807510376\n",
      "Epoch 356, running loss is 0.002400512248277664\n",
      "Epoch 357, running loss is 0.0023928342759609224\n",
      "Epoch 358, running loss is 0.00238517090678215\n",
      "Epoch 359, running loss is 0.0023775303363800047\n",
      "Epoch 360, running loss is 0.002368471026420593\n",
      "Epoch 361, running loss is 0.0023588427901268007\n",
      "Epoch 362, running loss is 0.002356565296649933\n",
      "Epoch 363, running loss is 0.002362112253904343\n",
      "Epoch 364, running loss is 0.002373543232679367\n",
      "Epoch 365, running loss is 0.0023938284814357755\n",
      "Epoch 366, running loss is 0.0024272297322750092\n",
      "Epoch 367, running loss is 0.0024655424058437347\n",
      "Epoch 368, running loss is 0.0025028416514396665\n",
      "Epoch 369, running loss is 0.0025311455130577086\n",
      "Epoch 370, running loss is 0.00254690021276474\n",
      "Epoch 371, running loss is 0.0030972063541412354\n",
      "Epoch 372, running loss is 0.003089125156402588\n",
      "Epoch 373, running loss is 0.0030708995461463926\n",
      "Epoch 374, running loss is 0.003042249083518982\n",
      "Epoch 375, running loss is 0.002978908121585846\n",
      "Epoch 376, running loss is 0.0023843935132026673\n",
      "Epoch 377, running loss is 0.002326599955558777\n",
      "Epoch 378, running loss is 0.0022793766856193543\n",
      "Epoch 379, running loss is 0.0027419865131378175\n",
      "Epoch 380, running loss is 0.0026957592368125915\n",
      "Epoch 381, running loss is 0.002643405795097351\n",
      "Epoch 382, running loss is 0.0025904929637908937\n",
      "Epoch 383, running loss is 0.0025398361682891844\n",
      "Epoch 384, running loss is 0.002492770552635193\n",
      "Epoch 385, running loss is 0.00244970440864563\n",
      "Epoch 386, running loss is 0.0024106203019618987\n",
      "Epoch 387, running loss is 0.0023753422498703\n",
      "Epoch 388, running loss is 0.002343589812517166\n",
      "Epoch 389, running loss is 0.002315075695514679\n",
      "Epoch 390, running loss is 0.0022894603013992308\n",
      "Epoch 391, running loss is 0.0022664296627044676\n",
      "Epoch 392, running loss is 0.002245672643184662\n",
      "Epoch 393, running loss is 0.002226896733045578\n",
      "Epoch 394, running loss is 0.0022098433971405027\n",
      "Epoch 395, running loss is 0.0021942734718322756\n",
      "Epoch 396, running loss is 0.0021799786388874056\n",
      "Epoch 397, running loss is 0.002166769504547119\n",
      "Epoch 398, running loss is 0.002154500335454941\n",
      "Epoch 399, running loss is 0.0021430368721485136\n",
      "Epoch 400, running loss is 0.002132261395454407\n",
      "Epoch 401, running loss is 0.002122098803520203\n",
      "Epoch 402, running loss is 0.0021124795079231263\n",
      "Epoch 403, running loss is 0.0021034401655197145\n",
      "Epoch 404, running loss is 0.0020953725278377534\n",
      "Epoch 405, running loss is 0.0020887356996536254\n",
      "Epoch 406, running loss is 0.0020829278230667116\n",
      "Epoch 407, running loss is 0.002077542692422867\n",
      "Epoch 408, running loss is 0.002072320431470871\n",
      "Epoch 409, running loss is 0.0020670837163925173\n",
      "Epoch 410, running loss is 0.0020617446303367614\n",
      "Epoch 411, running loss is 0.00205624982714653\n",
      "Epoch 412, running loss is 0.002050575911998749\n",
      "Epoch 413, running loss is 0.002044723331928253\n",
      "Epoch 414, running loss is 0.002038701772689819\n",
      "Epoch 415, running loss is 0.0020325252413749694\n",
      "Epoch 416, running loss is 0.0020262107253074648\n",
      "Epoch 417, running loss is 0.0020197826623916627\n",
      "Epoch 418, running loss is 0.002013256549835205\n",
      "Epoch 419, running loss is 0.002006648927927017\n",
      "Epoch 420, running loss is 0.001999979168176651\n",
      "Epoch 421, running loss is 0.001993263363838196\n",
      "Epoch 422, running loss is 0.001986509561538696\n",
      "Epoch 423, running loss is 0.0019797320663928987\n",
      "Epoch 424, running loss is 0.0019729411602020263\n",
      "Epoch 425, running loss is 0.001966148018836975\n",
      "Epoch 426, running loss is 0.0019593553245067594\n",
      "Epoch 427, running loss is 0.001952575147151947\n",
      "Epoch 428, running loss is 0.0019458059966564179\n",
      "Epoch 429, running loss is 0.0019390587508678436\n",
      "Epoch 430, running loss is 0.00193233922123909\n",
      "Epoch 431, running loss is 0.0019256408512592317\n",
      "Epoch 432, running loss is 0.0019189731776714325\n",
      "Epoch 433, running loss is 0.0019123387336730958\n",
      "Epoch 434, running loss is 0.0019057387113571168\n",
      "Epoch 435, running loss is 0.0018991705775260924\n",
      "Epoch 436, running loss is 0.001892644464969635\n",
      "Epoch 437, running loss is 0.0018861515820026398\n",
      "Epoch 438, running loss is 0.001879696249961853\n",
      "Epoch 439, running loss is 0.0018732832372188569\n",
      "Epoch 440, running loss is 0.0018669044971466064\n",
      "Epoch 441, running loss is 0.0018605686724185943\n",
      "Epoch 442, running loss is 0.0018542744219303131\n",
      "Epoch 443, running loss is 0.0018480166792869568\n",
      "Epoch 444, running loss is 0.0018418020009994508\n",
      "Epoch 445, running loss is 0.0018356260657310486\n",
      "Epoch 446, running loss is 0.0018294879794120789\n",
      "Epoch 447, running loss is 0.001823389083147049\n",
      "Epoch 448, running loss is 0.0018173292279243468\n",
      "Epoch 449, running loss is 0.0018113084137439729\n",
      "Epoch 450, running loss is 0.0018053288757801057\n",
      "Epoch 451, running loss is 0.0017993876338005066\n",
      "Epoch 452, running loss is 0.0017934826016426087\n",
      "Epoch 453, running loss is 0.0017876169085502625\n",
      "Epoch 454, running loss is 0.0017817874252796172\n",
      "Epoch 455, running loss is 0.0017759925127029418\n",
      "Epoch 456, running loss is 0.0017702393233776093\n",
      "Epoch 457, running loss is 0.0017645229399204255\n",
      "Epoch 458, running loss is 0.0017588378489017487\n",
      "Epoch 459, running loss is 0.0017531885206699372\n",
      "Epoch 460, running loss is 0.0017475761473178864\n",
      "Epoch 461, running loss is 0.0017419998347759248\n",
      "Epoch 462, running loss is 0.0017364555597305298\n",
      "Epoch 463, running loss is 0.0017309476435184478\n",
      "Epoch 464, running loss is 0.0017254728078842164\n",
      "Epoch 465, running loss is 0.0017200301587581635\n",
      "Epoch 466, running loss is 0.0017146237194538116\n",
      "Epoch 467, running loss is 0.001709248721599579\n",
      "Epoch 468, running loss is 0.001703902930021286\n",
      "Epoch 469, running loss is 0.0016985976696014405\n",
      "Epoch 470, running loss is 0.0016933155059814453\n",
      "Epoch 471, running loss is 0.001688065528869629\n",
      "Epoch 472, running loss is 0.0016828535497188568\n",
      "Epoch 473, running loss is 0.0016776619851589204\n",
      "Epoch 474, running loss is 0.001672510951757431\n",
      "Epoch 475, running loss is 0.0016673856973648071\n",
      "Epoch 476, running loss is 0.0016622883081436157\n",
      "Epoch 477, running loss is 0.0016572220623493194\n",
      "Epoch 478, running loss is 0.0016521847248077393\n",
      "Epoch 479, running loss is 0.0016471736133098602\n",
      "Epoch 480, running loss is 0.0016421960294246674\n",
      "Epoch 481, running loss is 0.0016372406482696533\n",
      "Epoch 482, running loss is 0.0016323180496692657\n",
      "Epoch 483, running loss is 0.001627420037984848\n",
      "Epoch 484, running loss is 0.0016225519776344299\n",
      "Epoch 485, running loss is 0.0016177091002464294\n",
      "Epoch 486, running loss is 0.0016128949820995331\n",
      "Epoch 487, running loss is 0.0016081039607524872\n",
      "Epoch 488, running loss is 0.0016033412516117096\n",
      "Epoch 489, running loss is 0.0015986061096191406\n",
      "Epoch 490, running loss is 0.0015938977897167206\n",
      "Epoch 491, running loss is 0.0015892104804515839\n",
      "Epoch 492, running loss is 0.0015845470130443572\n",
      "Epoch 493, running loss is 0.0015799108147621155\n",
      "Epoch 494, running loss is 0.0015752997994422913\n",
      "Epoch 495, running loss is 0.0015707118809223175\n",
      "Epoch 496, running loss is 0.001566152572631836\n",
      "Epoch 497, running loss is 0.0015616162121295928\n",
      "Epoch 498, running loss is 0.0015570968389511108\n",
      "Epoch 499, running loss is 0.0015526063740253448\n",
      "Epoch 500, running loss is 0.00154813751578331\n",
      "Epoch 501, running loss is 0.001543693095445633\n",
      "Epoch 502, running loss is 0.0015392722189426422\n",
      "Epoch 503, running loss is 0.0015348710119724273\n",
      "Epoch 504, running loss is 0.0015304911136627198\n",
      "Epoch 505, running loss is 0.0015261353552341462\n",
      "Epoch 506, running loss is 0.0015218019485473632\n",
      "Epoch 507, running loss is 0.001517489105463028\n",
      "Epoch 508, running loss is 0.0015131995081901551\n",
      "Epoch 509, running loss is 0.0015089277923107146\n",
      "Epoch 510, running loss is 0.0015046773850917817\n",
      "Epoch 511, running loss is 0.0015004517138004303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512, running loss is 0.0014962412416934967\n",
      "Epoch 513, running loss is 0.001492053121328354\n",
      "Epoch 514, running loss is 0.0014878879487514496\n",
      "Epoch 515, running loss is 0.0014837396144866944\n",
      "Epoch 516, running loss is 0.0014796112477779388\n",
      "Epoch 517, running loss is 0.0014755068719387054\n",
      "Epoch 518, running loss is 0.0014714168012142181\n",
      "Epoch 519, running loss is 0.001467348039150238\n",
      "Epoch 520, running loss is 0.00146329864859581\n",
      "Epoch 521, running loss is 0.0014592680335044862\n",
      "Epoch 522, running loss is 0.0014552555978298188\n",
      "Epoch 523, running loss is 0.0014512614905834197\n",
      "Epoch 524, running loss is 0.0014472846686840058\n",
      "Epoch 525, running loss is 0.0014433269202709198\n",
      "Epoch 526, running loss is 0.0014393885433673858\n",
      "Epoch 527, running loss is 0.0014354661107063293\n",
      "Epoch 528, running loss is 0.0014315642416477203\n",
      "Epoch 529, running loss is 0.001427675187587738\n",
      "Epoch 530, running loss is 0.0014238092303276062\n",
      "Epoch 531, running loss is 0.0014199548959732055\n",
      "Epoch 532, running loss is 0.001416119784116745\n",
      "Epoch 533, running loss is 0.0014123035967350006\n",
      "Epoch 534, running loss is 0.001408504843711853\n",
      "Epoch 535, running loss is 0.0014047196507453918\n",
      "Epoch 536, running loss is 0.0014009538292884826\n",
      "Epoch 537, running loss is 0.00139720156788826\n",
      "Epoch 538, running loss is 0.0013934676349163055\n",
      "Epoch 539, running loss is 0.001389743983745575\n",
      "Epoch 540, running loss is 0.001386043131351471\n",
      "Epoch 541, running loss is 0.0013823512196540833\n",
      "Epoch 542, running loss is 0.0013786822557449341\n",
      "Epoch 543, running loss is 0.001375025361776352\n",
      "Epoch 544, running loss is 0.0013713847100734712\n",
      "Epoch 545, running loss is 0.0013677562773227693\n",
      "Epoch 546, running loss is 0.0013641469180583955\n",
      "Epoch 547, running loss is 0.00136055126786232\n",
      "Epoch 548, running loss is 0.0013569709658622742\n",
      "Epoch 549, running loss is 0.00135340616106987\n",
      "Epoch 550, running loss is 0.0013498544692993164\n",
      "Epoch 551, running loss is 0.0013463161885738373\n",
      "Epoch 552, running loss is 0.0013427940011024476\n",
      "Epoch 553, running loss is 0.0013392814993858338\n",
      "Epoch 554, running loss is 0.0013357889652252197\n",
      "Epoch 555, running loss is 0.0013323067128658294\n",
      "Epoch 556, running loss is 0.0013288398087024688\n",
      "Epoch 557, running loss is 0.0013253878057003022\n",
      "Epoch 558, running loss is 0.0013219460844993592\n",
      "Epoch 559, running loss is 0.0013185201585292816\n",
      "Epoch 560, running loss is 0.001315106898546219\n",
      "Epoch 561, running loss is 0.0013117073476314545\n",
      "Epoch 562, running loss is 0.0013083216547966003\n",
      "Epoch 563, running loss is 0.001304946094751358\n",
      "Epoch 564, running loss is 0.001301589161157608\n",
      "Epoch 565, running loss is 0.0012982389330863952\n",
      "Epoch 566, running loss is 0.0012949034571647644\n",
      "Epoch 567, running loss is 0.0012915822863578796\n",
      "Epoch 568, running loss is 0.0012882733345031738\n",
      "Epoch 569, running loss is 0.0012849786877632142\n",
      "Epoch 570, running loss is 0.0012816940248012543\n",
      "Epoch 571, running loss is 0.0012784209847450257\n",
      "Epoch 572, running loss is 0.0012751597166061402\n",
      "Epoch 573, running loss is 0.0012719105184078217\n",
      "Epoch 574, running loss is 0.0012686750292778015\n",
      "Epoch 575, running loss is 0.001265450119972229\n",
      "Epoch 576, running loss is 0.0012622421979904175\n",
      "Epoch 577, running loss is 0.0012590420246124268\n",
      "Epoch 578, running loss is 0.001255849450826645\n",
      "Epoch 579, running loss is 0.0012526705861091614\n",
      "Epoch 580, running loss is 0.0012495087087154389\n",
      "Epoch 581, running loss is 0.0012463539838790893\n",
      "Epoch 582, running loss is 0.001243208795785904\n",
      "Epoch 583, running loss is 0.0012400757521390914\n",
      "Epoch 584, running loss is 0.0012369561940431596\n",
      "Epoch 585, running loss is 0.0012338430434465407\n",
      "Epoch 586, running loss is 0.0012307470291852952\n",
      "Epoch 587, running loss is 0.0012276576459407807\n",
      "Epoch 588, running loss is 0.0012245795875787736\n",
      "Epoch 589, running loss is 0.0012215147167444229\n",
      "Epoch 590, running loss is 0.001218458265066147\n",
      "Epoch 591, running loss is 0.0012154142558574678\n",
      "Epoch 592, running loss is 0.0012123778462409974\n",
      "Epoch 593, running loss is 0.0012093546986579895\n",
      "Epoch 594, running loss is 0.0012063408643007277\n",
      "Epoch 595, running loss is 0.0012033368647098542\n",
      "Epoch 596, running loss is 0.0012003383040428161\n",
      "Epoch 597, running loss is 0.0011973606795072555\n",
      "Epoch 598, running loss is 0.0011943836510181426\n",
      "Epoch 599, running loss is 0.0011914195865392685\n",
      "Epoch 600, running loss is 0.0011884672939777375\n",
      "Epoch 601, running loss is 0.0011855220794677733\n",
      "Epoch 602, running loss is 0.001182587668299675\n",
      "Epoch 603, running loss is 0.001179663836956024\n",
      "Epoch 604, running loss is 0.0011767499893903732\n",
      "Epoch 605, running loss is 0.0011738455295562744\n",
      "Epoch 606, running loss is 0.0011709489673376082\n",
      "Epoch 607, running loss is 0.0011680634319782258\n",
      "Epoch 608, running loss is 0.0011651866137981416\n",
      "Epoch 609, running loss is 0.001162322536110878\n",
      "Epoch 610, running loss is 0.0011594659090042115\n",
      "Epoch 611, running loss is 0.0011566148698329926\n",
      "Epoch 612, running loss is 0.001153777539730072\n",
      "Epoch 613, running loss is 0.0011509470641613007\n",
      "Epoch 614, running loss is 0.0011481238901615142\n",
      "Epoch 615, running loss is 0.001145317181944847\n",
      "Epoch 616, running loss is 0.001142510399222374\n",
      "Epoch 617, running loss is 0.0011397174745798112\n",
      "Epoch 618, running loss is 0.0011369343847036362\n",
      "Epoch 619, running loss is 0.001134159117937088\n",
      "Epoch 620, running loss is 0.0011313901841640472\n",
      "Epoch 621, running loss is 0.0011286316066980362\n",
      "Epoch 622, running loss is 0.0011258818954229355\n",
      "Epoch 623, running loss is 0.0011231409013271333\n",
      "Epoch 624, running loss is 0.0011204072833061217\n",
      "Epoch 625, running loss is 0.0011176849156618119\n",
      "Epoch 626, running loss is 0.0011149712651968003\n",
      "Epoch 627, running loss is 0.0011122659593820572\n",
      "Epoch 628, running loss is 0.0011095687001943589\n",
      "Epoch 629, running loss is 0.0011068829894065857\n",
      "Epoch 630, running loss is 0.001104201227426529\n",
      "Epoch 631, running loss is 0.001101531684398651\n",
      "Epoch 632, running loss is 0.0010988693684339523\n",
      "Epoch 633, running loss is 0.0010962191969156264\n",
      "Epoch 634, running loss is 0.0010935744643211364\n",
      "Epoch 635, running loss is 0.0010909423232078551\n",
      "Epoch 636, running loss is 0.001088317409157753\n",
      "Epoch 637, running loss is 0.0010857097059488296\n",
      "Epoch 638, running loss is 0.001083112359046936\n",
      "Epoch 639, running loss is 0.0010805334150791168\n",
      "Epoch 640, running loss is 0.0010779749602079392\n",
      "Epoch 641, running loss is 0.0010754471272230149\n",
      "Epoch 642, running loss is 0.001072966530919075\n",
      "Epoch 643, running loss is 0.001070544868707657\n",
      "Epoch 644, running loss is 0.0010681729763746262\n",
      "Epoch 645, running loss is 0.0010658366978168487\n",
      "Epoch 646, running loss is 0.001063510775566101\n",
      "Epoch 647, running loss is 0.0010611870139837264\n",
      "Epoch 648, running loss is 0.0010588497668504715\n",
      "Epoch 649, running loss is 0.0010564939677715302\n",
      "Epoch 650, running loss is 0.001054120734333992\n",
      "Epoch 651, running loss is 0.0010517241060733794\n",
      "Epoch 652, running loss is 0.0010493093729019166\n",
      "Epoch 653, running loss is 0.0010468780994415284\n",
      "Epoch 654, running loss is 0.001044425368309021\n",
      "Epoch 655, running loss is 0.0010419607907533645\n",
      "Epoch 656, running loss is 0.0010394863784313202\n",
      "Epoch 657, running loss is 0.0010370028764009477\n",
      "Epoch 658, running loss is 0.0010345103591680527\n",
      "Epoch 659, running loss is 0.0010320104658603669\n",
      "Epoch 660, running loss is 0.0010295099765062331\n",
      "Epoch 661, running loss is 0.0010270112752914428\n",
      "Epoch 662, running loss is 0.001024504005908966\n",
      "Epoch 663, running loss is 0.001022002249956131\n",
      "Epoch 664, running loss is 0.001019497811794281\n",
      "Epoch 665, running loss is 0.0010170025378465652\n",
      "Epoch 666, running loss is 0.0010145032405853272\n",
      "Epoch 667, running loss is 0.0010120100528001785\n",
      "Epoch 668, running loss is 0.0010095225274562836\n",
      "Epoch 669, running loss is 0.0010070395469665527\n",
      "Epoch 670, running loss is 0.0010045617818832397\n",
      "Epoch 671, running loss is 0.0010020892322063447\n",
      "Epoch 672, running loss is 0.0009996233880519866\n",
      "Epoch 673, running loss is 0.0009971603006124496\n",
      "Epoch 674, running loss is 0.0009947087615728377\n",
      "Epoch 675, running loss is 0.0009922605007886887\n",
      "Epoch 676, running loss is 0.000989820808172226\n",
      "Epoch 677, running loss is 0.000987386479973793\n",
      "Epoch 678, running loss is 0.0009849601984024048\n",
      "Epoch 679, running loss is 0.0009825384616851806\n",
      "Epoch 680, running loss is 0.0009801267832517625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 681, running loss is 0.0009777218103408814\n",
      "Epoch 682, running loss is 0.000975324735045433\n",
      "Epoch 683, running loss is 0.0009729307889938354\n",
      "Epoch 684, running loss is 0.0009705465286970139\n",
      "Epoch 685, running loss is 0.0009681697934865952\n",
      "Epoch 686, running loss is 0.0009657973796129227\n",
      "Epoch 687, running loss is 0.0009634366631507873\n",
      "Epoch 688, running loss is 0.0009610813111066818\n",
      "Epoch 689, running loss is 0.0009587308019399643\n",
      "Epoch 690, running loss is 0.0009563906490802765\n",
      "Epoch 691, running loss is 0.0009540561586618423\n",
      "Epoch 692, running loss is 0.0009517272561788559\n",
      "Epoch 693, running loss is 0.0009494056552648545\n",
      "Epoch 694, running loss is 0.0009470938891172409\n",
      "Epoch 695, running loss is 0.0009447860717773437\n",
      "Epoch 696, running loss is 0.0009424856305122375\n",
      "Epoch 697, running loss is 0.0009401946514844894\n",
      "Epoch 698, running loss is 0.0009379084408283234\n",
      "Epoch 699, running loss is 0.0009356294572353363\n",
      "Epoch 700, running loss is 0.0009333591908216477\n",
      "Epoch 701, running loss is 0.0009310930967330932\n",
      "Epoch 702, running loss is 0.0009288337826728821\n",
      "Epoch 703, running loss is 0.0009265819936990738\n",
      "Epoch 704, running loss is 0.0009243372827768326\n",
      "Epoch 705, running loss is 0.000922100841999054\n",
      "Epoch 706, running loss is 0.0009198694676160812\n",
      "Epoch 707, running loss is 0.0009176427125930786\n",
      "Epoch 708, running loss is 0.0009154269844293594\n",
      "Epoch 709, running loss is 0.0009132152050733566\n",
      "Epoch 710, running loss is 0.0009110129624605179\n",
      "Epoch 711, running loss is 0.0009088113903999329\n",
      "Epoch 712, running loss is 0.0009066212922334671\n",
      "Epoch 713, running loss is 0.0009044335037469864\n",
      "Epoch 714, running loss is 0.0009022541344165802\n",
      "Epoch 715, running loss is 0.0009000812470912933\n",
      "Epoch 716, running loss is 0.0008979175239801407\n",
      "Epoch 717, running loss is 0.0008957573026418686\n",
      "Epoch 718, running loss is 0.000893605649471283\n",
      "Epoch 719, running loss is 0.0008914566785097122\n",
      "Epoch 720, running loss is 0.0008893179893493653\n",
      "Epoch 721, running loss is 0.0008871840685606003\n",
      "Epoch 722, running loss is 0.0008850566297769546\n",
      "Epoch 723, running loss is 0.0008829367160797119\n",
      "Epoch 724, running loss is 0.000880821943283081\n",
      "Epoch 725, running loss is 0.0008787143975496292\n",
      "Epoch 726, running loss is 0.0008766129612922668\n",
      "Epoch 727, running loss is 0.0008745189011096955\n",
      "Epoch 728, running loss is 0.0008724333345890045\n",
      "Epoch 729, running loss is 0.0008703484386205673\n",
      "Epoch 730, running loss is 0.0008682732284069062\n",
      "Epoch 731, running loss is 0.0008662108331918717\n",
      "Epoch 732, running loss is 0.0008641476929187775\n",
      "Epoch 733, running loss is 0.0008620967715978622\n",
      "Epoch 734, running loss is 0.0008600541204214096\n",
      "Epoch 735, running loss is 0.0008580201864242554\n",
      "Epoch 736, running loss is 0.0008559956401586532\n",
      "Epoch 737, running loss is 0.0008539844304323197\n",
      "Epoch 738, running loss is 0.0008519817888736725\n",
      "Epoch 739, running loss is 0.0008500012755393982\n",
      "Epoch 740, running loss is 0.0008480468392372131\n",
      "Epoch 741, running loss is 0.0008461380004882813\n",
      "Epoch 742, running loss is 0.00084452323615551\n",
      "Epoch 743, running loss is 0.0008422429859638214\n",
      "Epoch 744, running loss is 0.0008362782746553421\n",
      "Epoch 745, running loss is 0.00083245649933815\n",
      "Epoch 746, running loss is 0.0008299189805984497\n",
      "Epoch 747, running loss is 0.0008282017707824707\n",
      "Epoch 748, running loss is 0.0008271138370037079\n",
      "Epoch 749, running loss is 0.0008268918842077255\n",
      "Epoch 750, running loss is 0.0008257219940423965\n",
      "Epoch 751, running loss is 0.0008240267634391785\n",
      "Epoch 752, running loss is 0.0008226949721574783\n",
      "Epoch 753, running loss is 0.00082136370241642\n",
      "Epoch 754, running loss is 0.0008199488371610641\n",
      "Epoch 755, running loss is 0.000818411260843277\n",
      "Epoch 756, running loss is 0.0008167576044797898\n",
      "Epoch 757, running loss is 0.0008149905502796173\n",
      "Epoch 758, running loss is 0.0008131221681833267\n",
      "Epoch 759, running loss is 0.0008111600577831268\n",
      "Epoch 760, running loss is 0.0008091188967227936\n",
      "Epoch 761, running loss is 0.0008070062845945358\n",
      "Epoch 762, running loss is 0.0008048302680253983\n",
      "Epoch 763, running loss is 0.0008026053011417389\n",
      "Epoch 764, running loss is 0.0008003351837396622\n",
      "Epoch 765, running loss is 0.0007980303466320038\n",
      "Epoch 766, running loss is 0.0007956985384225846\n",
      "Epoch 767, running loss is 0.000793340727686882\n",
      "Epoch 768, running loss is 0.0007909638434648513\n",
      "Epoch 769, running loss is 0.0007885741442441941\n",
      "Epoch 770, running loss is 0.000786171555519104\n",
      "Epoch 771, running loss is 0.0007837638258934021\n",
      "Epoch 772, running loss is 0.0007813563942909241\n",
      "Epoch 773, running loss is 0.0007789412885904312\n",
      "Epoch 774, running loss is 0.0007765201479196549\n",
      "Epoch 775, running loss is 0.0007741031050682068\n",
      "Epoch 776, running loss is 0.0007716831564903259\n",
      "Epoch 777, running loss is 0.0007692756503820419\n",
      "Epoch 778, running loss is 0.0007668700069189072\n",
      "Epoch 779, running loss is 0.0007644698023796081\n",
      "Epoch 780, running loss is 0.0007620725035667419\n",
      "Epoch 781, running loss is 0.0007596822828054428\n",
      "Epoch 782, running loss is 0.0007572995871305466\n",
      "Epoch 783, running loss is 0.0007549311965703964\n",
      "Epoch 784, running loss is 0.0007525653392076492\n",
      "Epoch 785, running loss is 0.0007502070814371109\n",
      "Epoch 786, running loss is 0.0007478547841310501\n",
      "Epoch 787, running loss is 0.0007455122470855713\n",
      "Epoch 788, running loss is 0.0007431820780038834\n",
      "Epoch 789, running loss is 0.0007408641278743744\n",
      "Epoch 790, running loss is 0.0007385528832674026\n",
      "Epoch 791, running loss is 0.000736248716711998\n",
      "Epoch 792, running loss is 0.0007339538633823394\n",
      "Epoch 793, running loss is 0.0007316681742668152\n",
      "Epoch 794, running loss is 0.0007293980568647384\n",
      "Epoch 795, running loss is 0.0007271372526884079\n",
      "Epoch 796, running loss is 0.0007248814404010773\n",
      "Epoch 797, running loss is 0.0007226381450891495\n",
      "Epoch 798, running loss is 0.0007204015552997589\n",
      "Epoch 799, running loss is 0.0007181739807128906\n",
      "Epoch 800, running loss is 0.0007159458845853806\n",
      "Epoch 801, running loss is 0.0007137162238359451\n",
      "Epoch 802, running loss is 0.0007114896923303604\n",
      "Epoch 803, running loss is 0.0007092720270156861\n",
      "Epoch 804, running loss is 0.0007070641964673996\n",
      "Epoch 805, running loss is 0.0007048715651035308\n",
      "Epoch 806, running loss is 0.0007026919722557068\n",
      "Epoch 807, running loss is 0.0007005208730697632\n",
      "Epoch 808, running loss is 0.000698358565568924\n",
      "Epoch 809, running loss is 0.000696207731962204\n",
      "Epoch 810, running loss is 0.0006940685212612152\n",
      "Epoch 811, running loss is 0.0006919440627098084\n",
      "Epoch 812, running loss is 0.0006898253411054611\n",
      "Epoch 813, running loss is 0.0006877186894416809\n",
      "Epoch 814, running loss is 0.0006856191158294678\n",
      "Epoch 815, running loss is 0.0006835316121578216\n",
      "Epoch 816, running loss is 0.0006814582645893097\n",
      "Epoch 817, running loss is 0.0006793899089097977\n",
      "Epoch 818, running loss is 0.0006773315370082855\n",
      "Epoch 819, running loss is 0.000675281286239624\n",
      "Epoch 820, running loss is 0.0006732410937547684\n",
      "Epoch 821, running loss is 0.0006712131202220917\n",
      "Epoch 822, running loss is 0.0006691928207874298\n",
      "Epoch 823, running loss is 0.0006671784073114395\n",
      "Epoch 824, running loss is 0.0006651730835437775\n",
      "Epoch 825, running loss is 0.0006631794571876526\n",
      "Epoch 826, running loss is 0.0006611935794353485\n",
      "Epoch 827, running loss is 0.0006592161953449249\n",
      "Epoch 828, running loss is 0.0006572442501783371\n",
      "Epoch 829, running loss is 0.0006552805751562119\n",
      "Epoch 830, running loss is 0.0006533260643482208\n",
      "Epoch 831, running loss is 0.0006513828039169311\n",
      "Epoch 832, running loss is 0.0006494498252868652\n",
      "Epoch 833, running loss is 0.0006475213170051574\n",
      "Epoch 834, running loss is 0.0006456000357866287\n",
      "Epoch 835, running loss is 0.0006436894088983536\n",
      "Epoch 836, running loss is 0.0006417886912822723\n",
      "Epoch 837, running loss is 0.0006398919969797135\n",
      "Epoch 838, running loss is 0.0006380034983158112\n",
      "Epoch 839, running loss is 0.0006361211091279983\n",
      "Epoch 840, running loss is 0.0006342468410730362\n",
      "Epoch 841, running loss is 0.0006323809176683426\n",
      "Epoch 842, running loss is 0.0006305264681577683\n",
      "Epoch 843, running loss is 0.0006286780536174775\n",
      "Epoch 844, running loss is 0.0006268310546875\n",
      "Epoch 845, running loss is 0.0006249997392296791\n",
      "Epoch 846, running loss is 0.0006231757625937462\n",
      "Epoch 847, running loss is 0.0006213558092713356\n",
      "Epoch 848, running loss is 0.0006195404008030891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849, running loss is 0.0006177312880754471\n",
      "Epoch 850, running loss is 0.0006159341707825661\n",
      "Epoch 851, running loss is 0.000614144317805767\n",
      "Epoch 852, running loss is 0.0006123654916882514\n",
      "Epoch 853, running loss is 0.0006105886399745942\n",
      "Epoch 854, running loss is 0.0006088180840015411\n",
      "Epoch 855, running loss is 0.000607055276632309\n",
      "Epoch 856, running loss is 0.0006053056940436364\n",
      "Epoch 857, running loss is 0.0006035559624433518\n",
      "Epoch 858, running loss is 0.0006018146499991417\n",
      "Epoch 859, running loss is 0.000600077472627163\n",
      "Epoch 860, running loss is 0.0005983518436551094\n",
      "Epoch 861, running loss is 0.0005966341122984886\n",
      "Epoch 862, running loss is 0.0005949189886450768\n",
      "Epoch 863, running loss is 0.0005932118743658066\n",
      "Epoch 864, running loss is 0.0005915088206529617\n",
      "Epoch 865, running loss is 0.0005898163840174675\n",
      "Epoch 866, running loss is 0.0005881313607096672\n",
      "Epoch 867, running loss is 0.0005864521488547325\n",
      "Epoch 868, running loss is 0.0005847766250371933\n",
      "Epoch 869, running loss is 0.0005831073969602585\n",
      "Epoch 870, running loss is 0.0005814461410045624\n",
      "Epoch 871, running loss is 0.0005797933787107468\n",
      "Epoch 872, running loss is 0.0005781448632478714\n",
      "Epoch 873, running loss is 0.000576503835618496\n",
      "Epoch 874, running loss is 0.0005748691037297249\n",
      "Epoch 875, running loss is 0.0005732423812150955\n",
      "Epoch 876, running loss is 0.0005716200172901153\n",
      "Epoch 877, running loss is 0.0005700013041496277\n",
      "Epoch 878, running loss is 0.0005683878436684609\n",
      "Epoch 879, running loss is 0.0005667867884039879\n",
      "Epoch 880, running loss is 0.0005651894956827163\n",
      "Epoch 881, running loss is 0.0005635986104607582\n",
      "Epoch 882, running loss is 0.000562010370194912\n",
      "Epoch 883, running loss is 0.0005604286491870881\n",
      "Epoch 884, running loss is 0.0005588555335998536\n",
      "Epoch 885, running loss is 0.0005572893470525742\n",
      "Epoch 886, running loss is 0.0005557274073362351\n",
      "Epoch 887, running loss is 0.0005541699007153511\n",
      "Epoch 888, running loss is 0.0005526182800531387\n",
      "Epoch 889, running loss is 0.0005510715395212174\n",
      "Epoch 890, running loss is 0.0005495350435376167\n",
      "Epoch 891, running loss is 0.0005480033904314041\n",
      "Epoch 892, running loss is 0.0005464744940400124\n",
      "Epoch 893, running loss is 0.0005449531599879265\n",
      "Epoch 894, running loss is 0.0005434421077370644\n",
      "Epoch 895, running loss is 0.0005419310927391052\n",
      "Epoch 896, running loss is 0.000540425032377243\n",
      "Epoch 897, running loss is 0.0005389254167675972\n",
      "Epoch 898, running loss is 0.0005374279990792275\n",
      "Epoch 899, running loss is 0.0005359430983662605\n",
      "Epoch 900, running loss is 0.000534462071955204\n",
      "Epoch 901, running loss is 0.0005329837650060653\n",
      "Epoch 902, running loss is 0.0005315104499459267\n",
      "Epoch 903, running loss is 0.0005300436913967132\n",
      "Epoch 904, running loss is 0.0005285856127738952\n",
      "Epoch 905, running loss is 0.0005271287262439728\n",
      "Epoch 906, running loss is 0.000525677353143692\n",
      "Epoch 907, running loss is 0.0005242346599698067\n",
      "Epoch 908, running loss is 0.0005227958410978317\n",
      "Epoch 909, running loss is 0.000521361529827118\n",
      "Epoch 910, running loss is 0.0005199315398931503\n",
      "Epoch 911, running loss is 0.0005185049399733543\n",
      "Epoch 912, running loss is 0.0005170871689915657\n",
      "Epoch 913, running loss is 0.0005156737565994263\n",
      "Epoch 914, running loss is 0.0005142654106020928\n",
      "Epoch 915, running loss is 0.0005128603428602218\n",
      "Epoch 916, running loss is 0.0005114609375596046\n",
      "Epoch 917, running loss is 0.0005100691691040993\n",
      "Epoch 918, running loss is 0.000508679710328579\n",
      "Epoch 919, running loss is 0.000507296361029148\n",
      "Epoch 920, running loss is 0.0005059158429503441\n",
      "Epoch 921, running loss is 0.0005045425146818161\n",
      "Epoch 922, running loss is 0.0005031752958893776\n",
      "Epoch 923, running loss is 0.0005018093436956406\n",
      "Epoch 924, running loss is 0.0005004499852657318\n",
      "Epoch 925, running loss is 0.0004990973696112632\n",
      "Epoch 926, running loss is 0.0004977470263838768\n",
      "Epoch 927, running loss is 0.0004964027553796768\n",
      "Epoch 928, running loss is 0.0004950608685612679\n",
      "Epoch 929, running loss is 0.0004937246441841126\n",
      "Epoch 930, running loss is 0.0004923928901553154\n",
      "Epoch 931, running loss is 0.000491068921983242\n",
      "Epoch 932, running loss is 0.0004897473007440567\n",
      "Epoch 933, running loss is 0.0004884302243590355\n",
      "Epoch 934, running loss is 0.0004871181398630142\n",
      "Epoch 935, running loss is 0.0004858117178082466\n",
      "Epoch 936, running loss is 0.00048450928181409836\n",
      "Epoch 937, running loss is 0.00048320982605218885\n",
      "Epoch 938, running loss is 0.0004819175601005554\n",
      "Epoch 939, running loss is 0.000480627715587616\n",
      "Epoch 940, running loss is 0.0004793413355946541\n",
      "Epoch 941, running loss is 0.0004780605807900429\n",
      "Epoch 942, running loss is 0.0004767822101712227\n",
      "Epoch 943, running loss is 0.0004755105450749397\n",
      "Epoch 944, running loss is 0.00047424402087926866\n",
      "Epoch 945, running loss is 0.0004729793220758438\n",
      "Epoch 946, running loss is 0.0004717208817601204\n",
      "Epoch 947, running loss is 0.0004704664275050163\n",
      "Epoch 948, running loss is 0.0004692176729440689\n",
      "Epoch 949, running loss is 0.0004679723829030991\n",
      "Epoch 950, running loss is 0.00046673063188791276\n",
      "Epoch 951, running loss is 0.00046549346297979354\n",
      "Epoch 952, running loss is 0.0004642602801322937\n",
      "Epoch 953, running loss is 0.00046303175389766693\n",
      "Epoch 954, running loss is 0.0004618061706423759\n",
      "Epoch 955, running loss is 0.00046058576554059983\n",
      "Epoch 956, running loss is 0.0004593665525317192\n",
      "Epoch 957, running loss is 0.00045815486460924147\n",
      "Epoch 958, running loss is 0.0004569476470351219\n",
      "Epoch 959, running loss is 0.00045574296265840533\n",
      "Epoch 960, running loss is 0.00045454230159521104\n",
      "Epoch 961, running loss is 0.00045334625989198687\n",
      "Epoch 962, running loss is 0.0004521559551358223\n",
      "Epoch 963, running loss is 0.00045096643269062044\n",
      "Epoch 964, running loss is 0.00044978152960538863\n",
      "Epoch 965, running loss is 0.00044860187917947767\n",
      "Epoch 966, running loss is 0.0004474278911948204\n",
      "Epoch 967, running loss is 0.0004462536796927452\n",
      "Epoch 968, running loss is 0.0004450840502977371\n",
      "Epoch 969, running loss is 0.00044392075389623645\n",
      "Epoch 970, running loss is 0.000442761555314064\n",
      "Epoch 971, running loss is 0.00044160205870866773\n",
      "Epoch 972, running loss is 0.0004404482990503311\n",
      "Epoch 973, running loss is 0.0004393003135919571\n",
      "Epoch 974, running loss is 0.000438154824078083\n",
      "Epoch 975, running loss is 0.00043701451271772386\n",
      "Epoch 976, running loss is 0.0004358766973018646\n",
      "Epoch 977, running loss is 0.00043474413454532625\n",
      "Epoch 978, running loss is 0.0004336151108145714\n",
      "Epoch 979, running loss is 0.00043248631060123445\n",
      "Epoch 980, running loss is 0.0004313616827130318\n",
      "Epoch 981, running loss is 0.0004302434623241425\n",
      "Epoch 982, running loss is 0.0004291287437081337\n",
      "Epoch 983, running loss is 0.0004280170798301697\n",
      "Epoch 984, running loss is 0.0004269090294837952\n",
      "Epoch 985, running loss is 0.0004258034750819206\n",
      "Epoch 986, running loss is 0.0004247036948800087\n",
      "Epoch 987, running loss is 0.00042360588908195494\n",
      "Epoch 988, running loss is 0.000422511100769043\n",
      "Epoch 989, running loss is 0.00042142100632190703\n",
      "Epoch 990, running loss is 0.00042033620178699493\n",
      "Epoch 991, running loss is 0.0004192516952753067\n",
      "Epoch 992, running loss is 0.0004181712865829468\n",
      "Epoch 993, running loss is 0.00041709352284669877\n",
      "Epoch 994, running loss is 0.00041602421551942823\n",
      "Epoch 995, running loss is 0.0004149547219276428\n",
      "Epoch 996, running loss is 0.00041388772428035736\n",
      "Epoch 997, running loss is 0.0004128266125917435\n",
      "Epoch 998, running loss is 0.00041176851838827135\n",
      "Epoch 999, running loss is 0.0004107129201292992\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(train, disable=True)):\n",
    "        inputs, labels = data\n",
    "        # CLEAN INPUTS\n",
    "        inputs = clean_sample(inputs, refgenes, currgenes)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, mloss = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass ⬅\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch}, running loss is {running_loss/100}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd45de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
