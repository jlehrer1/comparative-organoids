{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff60c790",
   "metadata": {},
   "source": [
    "# TabNet Model Test\n",
    "\n",
    "In this notebook, we'll test a training loop for the TabNet model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8974d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.lib.neural import *\n",
    "from models.lib.data import *\n",
    "from models.lib.train import *\n",
    "\n",
    "import helper \n",
    "from helper import gene_intersection\n",
    "from pytorch_tabnet.tab_network import TabNet\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "from helper import seed_everything\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3149635",
   "metadata": {},
   "source": [
    "First, we'll define our train, val and test sets, then generate the associated DataLoaders and try training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0db55c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_single_dataset(\n",
    "    datafile='../data/interim/primary_bhaduri_T.csv',\n",
    "    labelfile='../data/processed/labels/primary_bhaduri_labels.csv',\n",
    "    class_label='Type',\n",
    "    normalize=True,\n",
    "    skip=3,\n",
    ")\n",
    "\n",
    "refgenes = gene_intersection()\n",
    "currgenes = train.dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d5ad471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../data/interim/primary_bhaduri_T.csv',\n",
       "  '../data/interim/allen_cortex_T.csv',\n",
       "  '../data/interim/allen_m1_region_T.csv',\n",
       "  '../data/interim/whole_brain_bhaduri_T.csv'],\n",
       " ['../data/processed/labels/primary_bhaduri_labels.csv',\n",
       "  '../data/processed/labels/allen_cortex_labels.csv',\n",
       "  '../data/processed/labels/allen_m1_region_labels.csv',\n",
       "  '../data/processed/labels/whole_brain_bhaduri_labels.csv'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = helper.INTERIM_DATA_AND_LABEL_FILES_LIST\n",
    "datafiles, labelfiles = zip(*t.items())\n",
    "datafiles = [f'../data/interim/{f}' for f in datafiles]\n",
    "labelfiles = [f'../data/processed/labels/{f}' for f in labelfiles]\n",
    "\n",
    "datafiles, labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d0c2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrain, fullval, fulltest = generate_loaders(\n",
    "    datafiles,\n",
    "    labelfiles,\n",
    "    'Type',\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98a889",
   "metadata": {},
   "source": [
    "Now, we'll subset and define our DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fe945bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = Subset(train, range(10))\n",
    "# val = Subset(train, range(10))\n",
    "# test = Subset(test, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fd8fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(train, batch_size=2)\n",
    "val = DataLoader(val, batch_size=2)\n",
    "test = DataLoader(test, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edcb60dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74590"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fad629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1107, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train))[0]\n",
    "sample = clean_sample(sample, refgenes, currgenes)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcb2cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1740, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([8, 4])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9692b548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7212, -1.4900, -1.4875, -0.8384,  0.7192, -1.9079,  2.2873, -1.1778,\n",
       "           1.4394,  0.0852,  2.8979,  1.5542, -0.4073,  2.4720,  0.3535, -1.4971,\n",
       "           0.7302,  0.3869],\n",
       "         [ 0.2523, -3.2524,  0.2527, -0.0890, -1.2329,  0.6200,  2.7651,  0.5081,\n",
       "          -2.0700, -0.4171,  3.0618, -0.4611, -2.4633, -0.4383,  1.4057,  0.1778,\n",
       "           0.7112,  0.7152]], grad_fn=<MmBackward0>),\n",
       " tensor(-8.6592, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TabNet(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=18,\n",
    ")\n",
    "\n",
    "model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da622121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.neural import TabNetGeneClassifier\n",
    "\n",
    "model = TabNetGeneClassifier(input_dim=len(refgenes), output_dim=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74a6ef7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8933, -0.3937,  0.0965,  0.8868,  1.7275, -1.8121, -0.5918, -1.8454,\n",
       "         -0.3578, -1.0836, -0.6907, -0.6712,  0.3328, -1.2917,  0.3095, -1.0449,\n",
       "          0.7997, -0.5279],\n",
       "        [-0.6963,  0.4636, -0.7859,  2.6002,  0.2334, -0.1801,  0.8615, -0.6257,\n",
       "         -3.6933, -1.7297, -1.4980, -1.5532,  0.8441, -0.4745, -1.1023, -2.3745,\n",
       "          1.9691,  0.0044]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a7873b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:j5sgbefl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">kind-water-29</strong>: <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/j5sgbefl\" target=\"_blank\">https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/j5sgbefl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220403_155434-j5sgbefl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:j5sgbefl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/julian/Documents/Projects/organoid-classification/notebooks/wandb/run-20220403_155701-3uhntfni</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/3uhntfni\" target=\"_blank\">summer-dew-30</a></strong> to <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_90439/1341757409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Step with optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             F.sgd(params_with_grad,\n\u001b[0m\u001b[1;32m    137\u001b[0m                   \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                   \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "wandb.init()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "mod = 10\n",
    "wandb.watch(model)\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    for i, data in enumerate(train):\n",
    "        inputs, labels = data\n",
    "        # CLEAN INPUTS\n",
    "        inputs = clean_sample(inputs, refgenes, currgenes)\n",
    "        # Forward pass âž¡\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass â¬…\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "\n",
    "        if i % mod == 0: # record every 2000 mini batches \n",
    "            metric_results = calculate_metrics(\n",
    "                outputs=outputs,\n",
    "                labels=labels,\n",
    "                append_str='train',\n",
    "                num_classes=model.output_dim,\n",
    "                subset='weighted_accuracy',\n",
    "            )\n",
    "\n",
    "            wandb.log(metric_results)\n",
    "            running_loss = running_loss / mod\n",
    "            wandb.log({f\"batch_train_loss\": loss})\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            \n",
    "    wandb.log({f\"epoch_train_loss\": epoch_loss / len(train)})\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad(): # save memory but not computing gradients \n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(val):\n",
    "            inputs, labels = data\n",
    "            # CLEAN INPUTS\n",
    "            inputs = clean_sample(inputs, refgenes, currgenes)\n",
    "            # Forward pass âž¡\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if i % mod == 0: #every 2000 mini batches \n",
    "                running_loss = running_loss / mod\n",
    "                wandb.log({\"val_loss\": loss})\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                metric_results = calculate_metrics(\n",
    "                    outputs=outputs,\n",
    "                    labels=labels,\n",
    "                    num_classes=model.output_dim,\n",
    "                    subset='weighted_accuracy',\n",
    "                    append_str='val',\n",
    "                )\n",
    "            \n",
    "            wandb.log(metric_results)\n",
    "    \n",
    "        wandb.log({f\"epoch_val_loss\": epoch_loss / len(train)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cad30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eebec76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b242e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['asdf']\n",
    "subset = ([subset] if isinstance(subset, str) else subset)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12fad261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "class_label = 'Type'\n",
    "current_labels = pd.read_csv(labelfiles[0]).loc[:, class_label]\n",
    "\n",
    "# Make stratified split on labels\n",
    "trainsplit, valsplit = train_test_split(current_labels, stratify=current_labels)\n",
    "trainsplit, testsplit = train_test_split(trainsplit, stratify=trainsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d174e8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsplit.keys == valsplit.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37b26274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(valsplit.keys()).intersection(trainsplit.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f36e1af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(valsplit.keys()).intersection(testsplit.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3796e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
