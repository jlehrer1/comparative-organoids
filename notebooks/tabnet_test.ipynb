{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f6ea9a",
   "metadata": {},
   "source": [
    "# TabNet Model Test\n",
    "\n",
    "In this notebook, we'll test a training loop for the TabNet model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9edaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.lib.neural import *\n",
    "from models.lib.data import *\n",
    "from models.lib.train import *\n",
    "\n",
    "import helper \n",
    "from helper import gene_intersection\n",
    "from pytorch_tabnet.tab_network import TabNet\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "from helper import seed_everything\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e117d9",
   "metadata": {},
   "source": [
    "First, we'll define our train, val and test sets, then generate the associated DataLoaders and try training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113c0f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../data/interim/primary_bhaduri_T.csv',\n",
       "  '../data/interim/allen_cortex_T.csv',\n",
       "  '../data/interim/allen_m1_region_T.csv',\n",
       "  '../data/interim/whole_brain_bhaduri_T.csv'],\n",
       " ['../data/processed/labels/primary_bhaduri_labels.csv',\n",
       "  '../data/processed/labels/allen_cortex_labels.csv',\n",
       "  '../data/processed/labels/allen_m1_region_labels.csv',\n",
       "  '../data/processed/labels/whole_brain_bhaduri_labels.csv'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = helper.INTERIM_DATA_AND_LABEL_FILES_LIST\n",
    "datafiles, labelfiles = zip(*t.items())\n",
    "datafiles = [f'../data/interim/{f}' for f in datafiles]\n",
    "labelfiles = [f'../data/processed/labels/{f}' for f in labelfiles]\n",
    "refgenes = gene_intersection()\n",
    "\n",
    "datafiles, labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b5ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4b79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba013226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_single_dataset(\n",
    "    datafiles[0],\n",
    "    labelfiles[0],\n",
    "    'Type',\n",
    "    skip=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25decdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19765\n"
     ]
    }
   ],
   "source": [
    "print(len(train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8462d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_map, _, _ = generate_single_dataloader(\n",
    "    datafile=datafiles[0], \n",
    "    labelfile=labelfiles[0], \n",
    "    class_label='Type',\n",
    "    skip=3,\n",
    "    map_genes=True\n",
    ")\n",
    "\n",
    "trainloader_nomap, _, _ = generate_single_dataloader(\n",
    "    datafile=datafiles[0], \n",
    "    labelfile=labelfiles[0], \n",
    "    class_label='Type',\n",
    "    skip=3,\n",
    "    map_genes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050516bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (X, y) in enumerate(tqdm(trainloader_map)):\n",
    "#     if i == 200:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee3b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (X, y) in enumerate(tqdm(trainloader_nomap)):\n",
    "#     if i == 200:\n",
    "#         break\n",
    "#     X = clean_sample(X, refgenes, train.features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79be48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = generate_loaders(\n",
    "    datafiles,\n",
    "    labelfiles,\n",
    "    'Type',\n",
    "    num_workers=0,\n",
    "    collocate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f76bf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, y in train_loader:\n",
    "#     print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb88c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16604"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(refgenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f15f491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.neural import TabNetGeneClassifier\n",
    "\n",
    "model = TabNetGeneClassifier(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=19\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3775abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, refgenes, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.refgenes = refgenes\n",
    "        self.currgenes = self.dataset.columns \n",
    "            \n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            yield clean_sample(batch[0], self.refgenes, self.currgenes), batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f6d065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = SampleLoader(refgenes=refgenes, dataset=train, batch_size=11, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbc26eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for X, y in test:\n",
    "#     print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2fbb6",
   "metadata": {},
   "source": [
    "## PyTorch-Lightning compatible TabNet architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dd564eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.neural import GeneClassifier\n",
    "from models.lib.neural import TabNetGeneClassifier\n",
    "\n",
    "base_model = TabNetGeneClassifier(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=19,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d03f3715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16604"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a510881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. input_dim = 16604, output_dim = 19. Metrics are {'accuracy': <function accuracy at 0x7fcb92c3a3a0>, 'precision': <function precision at 0x7fcb92c4fee0>, 'recall': <function recall at 0x7fcb92c58040>} and weighted_metrics = False\n"
     ]
    }
   ],
   "source": [
    "classifier = GeneClassifier(\n",
    "    input_dim=base_model.input_dim,\n",
    "    output_dim=base_model.output_dim,\n",
    "    model=base_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1012853f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1563e+00,  6.1421e-01, -5.7720e-02, -2.7440e-01, -5.6809e-01,\n",
       "          1.8822e+00, -1.2550e-01,  1.3234e+00, -8.8077e-01, -1.2354e+00,\n",
       "          8.6221e-01,  2.3478e-01, -8.8579e-01,  3.1630e-01, -4.0054e-01,\n",
       "         -6.8034e-01,  4.7086e-01, -1.2678e-01,  2.0564e+00],\n",
       "        [-7.0576e-01,  1.0763e+00,  5.6336e-01, -2.5588e-01,  4.9470e-01,\n",
       "          1.3941e+00,  6.4407e-01,  7.1527e-01, -4.2848e-01, -7.9584e-01,\n",
       "          2.2693e-01, -2.7052e-01, -1.6280e-01,  2.1129e-01, -4.2792e-01,\n",
       "         -4.8361e-01,  1.1165e-01,  4.4577e-01,  9.5899e-02],\n",
       "        [-6.3847e-01,  6.4753e-01,  1.7418e-01, -1.1129e-01,  6.8863e-01,\n",
       "          1.5467e+00,  2.1099e-01,  2.5876e-01,  1.6656e-01, -5.7681e-01,\n",
       "         -3.4057e-01, -1.0942e-01, -2.9596e-01, -9.8176e-01, -4.5809e-01,\n",
       "         -5.2466e-01, -5.0747e-02, -1.1558e-01,  3.1388e-01],\n",
       "        [-6.6908e-01,  1.7688e+00,  2.1910e+00, -5.6762e-01,  1.2389e+00,\n",
       "          2.4301e+00,  4.3955e-01,  4.3395e-01, -1.8290e+00, -1.1862e+00,\n",
       "          8.8571e-01, -1.4787e+00, -1.1812e+00, -4.1179e-01, -1.3818e+00,\n",
       "          9.4088e-01,  8.5684e-01,  1.4514e+00,  5.0098e-01],\n",
       "        [-2.2161e+00,  1.1417e+00, -1.0629e-01, -1.2895e-01,  1.0485e+00,\n",
       "          2.0709e+00, -6.8129e-01,  1.9417e-01, -5.3651e-01,  1.7439e-01,\n",
       "          3.7674e-01, -8.2991e-01, -1.1924e+00, -3.4774e+00, -8.8798e-01,\n",
       "         -5.5767e-01,  1.0095e+00, -1.0525e+00,  3.1296e+00],\n",
       "        [-2.8919e+00,  2.5401e+00,  1.5934e+00,  4.5068e-01, -3.8544e-01,\n",
       "          2.0510e+00,  6.6423e-01, -7.2358e-02, -2.6335e+00, -1.3754e+00,\n",
       "         -7.3763e-02, -4.1948e+00, -1.2712e+00, -3.8368e+00, -5.9872e-01,\n",
       "         -4.1418e+00,  1.2433e+00, -4.0871e+00,  1.6209e+00],\n",
       "        [-7.0999e-01,  7.0262e-01,  4.4889e-01, -1.3786e-01,  1.3820e-01,\n",
       "          1.0454e+00, -1.2100e-01,  6.5836e-01, -5.0872e-01, -4.1669e-01,\n",
       "          9.3687e-02,  8.5506e-02, -3.0742e-01, -1.4643e-01,  3.8458e-03,\n",
       "         -3.9572e-01,  3.8373e-01, -2.6176e-02,  8.0708e-01],\n",
       "        [-1.4844e+00,  7.7983e-01,  1.6869e-01, -8.2471e-01, -1.1882e-01,\n",
       "          2.1071e+00,  4.5944e-01,  8.2710e-01, -5.1827e-01, -1.1473e+00,\n",
       "          5.2886e-01, -5.2321e-01, -1.3217e+00, -5.5921e-01, -1.0633e+00,\n",
       "         -4.6686e-01,  1.3258e-01, -2.1913e-01,  1.8151e+00],\n",
       "        [-2.1657e+00,  2.4054e+00,  2.5917e+00, -1.1969e+00, -1.4287e-01,\n",
       "          1.6230e+00,  8.3962e-01,  1.0676e+00, -2.6338e+00, -9.7550e-01,\n",
       "          8.1769e-01, -2.1846e+00, -1.5145e+00, -2.5790e-02, -6.3884e-01,\n",
       "         -6.6998e-01,  1.1607e+00, -2.4500e-01,  1.4701e+00],\n",
       "        [-3.3217e-01,  1.8790e-01, -9.8990e-02,  7.1566e-02, -1.7401e-01,\n",
       "          1.1947e+00, -2.1969e-01,  6.3805e-01, -1.9443e-01, -7.7726e-01,\n",
       "          1.0544e-01,  4.1724e-01, -2.9484e-01,  3.6681e-02, -7.5879e-02,\n",
       "         -4.8931e-01,  1.1549e-01, -1.1912e-01,  7.6430e-01],\n",
       "        [-7.7904e-01,  1.2135e+00,  7.1919e-01, -6.1823e-01,  1.0392e+00,\n",
       "          2.7635e+00,  9.3847e-01,  5.8765e-01, -7.1687e-01, -1.5415e+00,\n",
       "          9.7882e-01, -9.2903e-01, -1.0820e+00, -2.9941e-01, -1.8300e+00,\n",
       "          5.0118e-01,  1.1975e-01,  1.3300e+00,  6.6454e-01]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(test))[0]\n",
    "\n",
    "classifier(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8338e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl \n",
    "from typing import *\n",
    "\n",
    "class GeneDataModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        datafiles: List[str],\n",
    "        labelfiles: List[str],\n",
    "        class_label: str,\n",
    "        batch_size: int=16,\n",
    "        num_workers=32,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.datafiles = datafiles\n",
    "        self.labelfiles = labelfiles\n",
    "        self.class_label = class_label\n",
    "        \n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.trainloaders = []\n",
    "        self.valloaders = []\n",
    "        self.testloaders = []\n",
    "        \n",
    "        self.args = args,\n",
    "        self.kwargs = kwargs,\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # Download data from S3 here \n",
    "        pass \n",
    "    \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        for datafile, labelfile in zip(self.datafiles, self.labelfiles):\n",
    "            train, val, test = generate_single_dataloader(\n",
    "                datafile=datafile,\n",
    "                labelfile=labelfile,\n",
    "                class_lable=self.class_label,\n",
    "                *self.args,\n",
    "                **self.kwargs,\n",
    "            )\n",
    "            \n",
    "            self.trainloaders.append(train)\n",
    "            self.valloaders.append(val)\n",
    "            self.testloaders.append(test)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return self.trainloaders\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.valloaders\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "715b7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = GeneDataModule(datafiles, labelfiles, 'Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff2c2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniconda3/envs/base-data-science/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=GeneDataModule())` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=GeneDataModule())`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_96670/2109022103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(model, module)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2124a9",
   "metadata": {},
   "source": [
    "Now, we'll subset and define our DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31975f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1eseo35v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_train_loss</td><td>▄█▁▂</td></tr><tr><td>epoch_train_loss</td><td>▁</td></tr><tr><td>epoch_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>█▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁</td></tr><tr><td>weighted_accuracy_test</td><td>█▁▁▁</td></tr><tr><td>weighted_accuracy_train</td><td>▁▁█▃</td></tr><tr><td>weighted_accuracy_val</td><td>██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_train_loss</td><td>1.6601</td></tr><tr><td>epoch_train_loss</td><td>0.00138</td></tr><tr><td>epoch_val_loss</td><td>0.0056</td></tr><tr><td>test_loss</td><td>2.62397</td></tr><tr><td>val_loss</td><td>3.08289</td></tr><tr><td>weighted_accuracy_test</td><td>0.0</td></tr><tr><td>weighted_accuracy_train</td><td>0.25</td></tr><tr><td>weighted_accuracy_val</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-wind-38</strong>: <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/1eseo35v\" target=\"_blank\">https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/1eseo35v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220404_111127-1eseo35v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1eseo35v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/julian/Documents/Projects/organoid-classification/notebooks/wandb/run-20220404_114512-tcrzlziw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/tcrzlziw\" target=\"_blank\">dazzling-water-39</a></strong> to <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On loader idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 2/29836 [00:00<39:25, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n",
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 6/29836 [00:00<33:59, 14.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n",
      "On minibatch i = 5/10\n",
      "On minibatch i = 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 10/29836 [00:00<34:11, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 7/10\n",
      "On minibatch i = 8/10\n",
      "On minibatch i = 9/10\n",
      "On minibatch i = 10/10\n",
      "On loader idx = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 2/7602 [00:00<10:28, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n",
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 4/7602 [00:00<10:30, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n",
      "On minibatch i = 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 8/7602 [00:00<10:40, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 6/10\n",
      "On minibatch i = 7/10\n",
      "On minibatch i = 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 10/7602 [00:00<10:51, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 9/10\n",
      "On minibatch i = 10/10\n",
      "On loader idx = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                 | 0/12245 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 2/12245 [00:00<18:58, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 4/12245 [00:00<18:09, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n",
      "On minibatch i = 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 6/12245 [00:00<18:23, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 6/10\n",
      "On minibatch i = 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 8/12245 [00:00<18:23, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 10/12245 [00:00<18:46, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 9/10\n",
      "On minibatch i = 10/10\n",
      "On loader idx = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/105528 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 2/105528 [00:00<2:08:29, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 4/105528 [00:00<2:02:53, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 6/105528 [00:00<2:04:06, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 5/10\n",
      "On minibatch i = 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 8/105528 [00:00<2:02:24, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 7/10\n",
      "On minibatch i = 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 10/105528 [00:00<2:04:51, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 10/105528 [00:00<2:06:33, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 10/10\n",
      "On loader i = 10\n",
      "On loader i = 10\n",
      "On loader i = 10\n",
      "On loader i = 10\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "wandb.init()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "mod = 10\n",
    "wandb.watch(model)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    for idx, train in enumerate(train_loader):\n",
    "        print(f'On loader {idx = }')\n",
    "        for i, data in enumerate(tqdm(train)):\n",
    "            print(f'On minibatch {i = }/10')\n",
    "            if i == 10:\n",
    "                break \n",
    "            inputs, labels = data\n",
    "            # CLEAN INPUTS\n",
    "            inputs = clean_sample(inputs, refgenes, train.dataset.columns)\n",
    "            # Forward pass ➡\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass ⬅\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Step with optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "            if i % mod == 0: # record every 2000 mini batches \n",
    "                metric_results = calculate_metrics(\n",
    "                    outputs=outputs,\n",
    "                    labels=labels,\n",
    "                    append_str='train',\n",
    "                    num_classes=model.output_dim,\n",
    "                    subset='weighted_accuracy',\n",
    "                )\n",
    "\n",
    "                wandb.log(metric_results)\n",
    "                running_loss = running_loss / mod\n",
    "                wandb.log({f\"batch_train_loss\": loss})\n",
    "\n",
    "                running_loss = 0.0\n",
    "            \n",
    "    wandb.log({f\"epoch_train_loss\": epoch_loss / len(train)})\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad(): # save memory but not computing gradients \n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for val in val_loader:\n",
    "            print(f'On loader {i = }')\n",
    "            for i, data in enumerate(val):\n",
    "                if i == 10:\n",
    "                    break \n",
    "                inputs, labels = data\n",
    "                # CLEAN INPUTS\n",
    "                inputs = clean_sample(inputs, refgenes, val.dataset.columns)\n",
    "                # Forward pass ➡\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if i % mod == 0: #every 2000 mini batches \n",
    "                    running_loss = running_loss / mod\n",
    "                    wandb.log({\"val_loss\": loss})\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                    metric_results = calculate_metrics(\n",
    "                        outputs=outputs,\n",
    "                        labels=labels,\n",
    "                        num_classes=model.output_dim,\n",
    "                        subset='weighted_accuracy',\n",
    "                        append_str='val',\n",
    "                    )\n",
    "\n",
    "                wandb.log(metric_results)\n",
    "    \n",
    "        wandb.log({f\"epoch_val_loss\": epoch_loss / len(train)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bdb29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabNetGeneClassifier(\n",
       "  (embedder): EmbeddingGenerator()\n",
       "  (tabnet): TabNetNoEmbeddings(\n",
       "    (initial_bn): BatchNorm1d(16604, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (encoder): TabNetEncoder(\n",
       "      (initial_bn): BatchNorm1d(16604, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (initial_splitter): FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (shared_layers): ModuleList(\n",
       "            (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "            (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "          )\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (specifics): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (feat_transformers): ModuleList(\n",
       "        (0): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (att_transformers): ModuleList(\n",
       "        (0): AttentiveTransformer(\n",
       "          (fc): Linear(in_features=8, out_features=16604, bias=False)\n",
       "          (bn): GBN(\n",
       "            (bn): BatchNorm1d(16604, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (selector): Sparsemax()\n",
       "        )\n",
       "        (1): AttentiveTransformer(\n",
       "          (fc): Linear(in_features=8, out_features=16604, bias=False)\n",
       "          (bn): GBN(\n",
       "            (bn): BatchNorm1d(16604, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (selector): Sparsemax()\n",
       "        )\n",
       "        (2): AttentiveTransformer(\n",
       "          (fc): Linear(in_features=8, out_features=16604, bias=False)\n",
       "          (bn): GBN(\n",
       "            (bn): BatchNorm1d(16604, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (selector): Sparsemax()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_mapping): Linear(in_features=8, out_features=19, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefd4305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_loop(\n",
    "    model,\n",
    "    testloaders,\n",
    "    refgenes,\n",
    "    criterion,\n",
    "    mod,\n",
    "):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, test in enumerate(testloaders):\n",
    "            print(f'On {idx = }')\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(test):\n",
    "                print(f'minibatch {i = }')\n",
    "                if i == 10:\n",
    "                    break\n",
    "                inputs, labels = data\n",
    "                # CLEAN INPUTS\n",
    "                inputs = clean_sample(inputs, refgenes, test.dataset.columns)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % mod == 0: #every 2000 mini batches \n",
    "                    running_loss = running_loss / mod\n",
    "                    wandb.log({\"test_loss\": loss})\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                    metric_results = calculate_metrics(\n",
    "                        outputs=outputs,\n",
    "                        labels=labels,\n",
    "                        num_classes=model.output_dim,\n",
    "                        subset='weighted_accuracy',\n",
    "                        append_str='test',\n",
    "                    )\n",
    "\n",
    "                    wandb.log(metric_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "955f0944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On idx = 0\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n",
      "On idx = 1\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n",
      "On idx = 2\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n",
      "On idx = 3\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n"
     ]
    }
   ],
   "source": [
    "test_loop(model, test_loader, refgenes, criterion, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7666179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAASPElEQVR4nO3df4xddZnH8fezHZwqdUunlB926E4RIrarac1NCbKbtPKrrGKrFpfuH5ZF08hKzGIIFlhtRf8AFldCdHfTqLExWQYWQuwGSVOQJmTdQKeVVQvU1lLDFKh1SoosKaX47B9zwMt4S2fm3pnb6ff9Sm7mnO/3Ofc+307Szz3n3JmJzESSVK4/a3cDkqT2MggkqXAGgSQVziCQpMIZBJJUuI52NzAaJ598cvb09LS7DUmaULZs2fK7zJwxdHxCBkFPTw99fX3tbkOSJpSI+E2jcS8NSVLhDAJJKpxBIEmFm5D3CCRppF577TX6+/s5ePBgu1sZc5MnT6a7u5sTTjhhWPUGgaQi9Pf38+53v5uenh4iot3tjJnMZGBggP7+fmbPnj2sY7w0JKkIBw8eZPr06cd1CABEBNOnTx/RmY9BIKkYx3sIvGGk6zQIJKlwBoEkjbGBgQHmzZvHvHnzOO2005g5c+ab+4cOHXrbY/v6+vjiF784pv15s1iSxtj06dN54oknAFizZg1Tpkzhuuuue3P+8OHDdHQ0/u+4VqtRq9XGtD/PCCSpDa688ko+//nPc+6553L99dfz+OOPc9555zF//nw+/OEPs337dgA2bdrExz72MWAwRK666ioWLlzImWeeyZ133tmSXjwjkFScr/3XNp587qWWPuec9/w5qy+bO6Jj+vv7+elPf8qkSZN46aWXePTRR+no6OChhx7ixhtv5L777vuTY55++mkeeeQRfv/73/O+972Pq6++etg/L3AkBoEktcnll1/OpEmTADhw4AArVqxgx44dRASvvfZaw2M++tGP0tnZSWdnJ6eccgp79+6lu7u7qT4MAknFGek797Fy4oknvrn9la98hUWLFnH//feze/duFi5c2PCYzs7ON7cnTZrE4cOHm+7DewSSdAw4cOAAM2fOBOAHP/jBuL62QSBJx4Drr7+eG264gfnz57fkXf5IRGaO6wu2Qq1WS/8wjaSReOqpp3j/+9/f7jbGTaP1RsSWzPyTz6J6RiBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBI0jhYtGgRGzZseMvYHXfcwdVXX92wfuHChYzXx+QNAkkaB8uXL6e3t/ctY729vSxfvrxNHf1RS4IgIhZHxPaI2BkRqxrMd0bE3dX8YxHRM2R+VkS8HBHXDT1Wko4Hy5Yt44EHHnjzD9Hs3r2b5557jrvuuotarcbcuXNZvXp1W3pr+pfORcQk4DvARUA/sDki1mfmk3VlnwVezMyzIuIK4Fbgb+vm/wV4sNleJGlYHlwFL/yitc952gfg0luOON3V1cWCBQt48MEHWbJkCb29vXz605/mxhtvpKuri9dff50LLriAn//853zwgx9sbW9H0YozggXAzszclZmHgF5gyZCaJcC6avte4IKo/rpyRCwFngG2taAXSTpm1V8eeuOy0D333MOHPvQh5s+fz7Zt23jyySeP8iyt14pfQz0TeLZuvx8490g1mXk4Ig4A0yPiIPBlBs8m3vayUESsBFYCzJo1qwVtSyrW27xzH0tLlizh2muvZevWrbzyyit0dXVx++23s3nzZqZNm8aVV17JwYMHx72vdt8sXgN8KzNfPlphZq7NzFpm1mbMmDH2nUlSi02ZMoVFixZx1VVXsXz5cl566SVOPPFEpk6dyt69e3nwwfZcIW/FGcEe4Iy6/e5qrFFNf0R0AFOBAQbPHJZFxG3AScAfIuJgZn67BX1J0jFn+fLlfOITn6C3t5dzzjmH+fPnc84553DGGWdw/vnnt6WnVgTBZuDsiJjN4H/4VwB/N6RmPbAC+B9gGfCTHPz913/9RkFErAFeNgQkHc+WLl1K/a//P9Ifodm0adP4NEQLgqC65n8NsAGYBHw/M7dFxM1AX2auB74H/DAidgL7GQwLSdIxoCV/szgzfwz8eMjYV+u2DwKXH+U51rSiF0nSyLT7ZrEkjZuJ+BcZR2Ok6zQIJBVh8uTJDAwMHPdhkJkMDAwwefLkYR/TkktDknSs6+7upr+/n3379rW7lTE3efJkuru7h11vEEgqwgknnMDs2bPb3cYxyUtDklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCteSIIiIxRGxPSJ2RsSqBvOdEXF3Nf9YRPRU4xdFxJaI+EX19SOt6EeSNHxNB0FETAK+A1wKzAGWR8ScIWWfBV7MzLOAbwG3VuO/Ay7LzA8AK4AfNtuPJGlkWnFGsADYmZm7MvMQ0AssGVKzBFhXbd8LXBARkZk/y8znqvFtwDsjorMFPUmShqkVQTATeLZuv78aa1iTmYeBA8D0ITWfArZm5qst6EmSNEwd7W4AICLmMni56OK3qVkJrASYNWvWOHUmSce/VpwR7AHOqNvvrsYa1kREBzAVGKj2u4H7gc9k5q+P9CKZuTYza5lZmzFjRgvaliRBa4JgM3B2RMyOiHcAVwDrh9SsZ/BmMMAy4CeZmRFxEvAAsCoz/7sFvUiSRqjpIKiu+V8DbACeAu7JzG0RcXNEfLwq+x4wPSJ2Al8C3viI6TXAWcBXI+KJ6nFKsz1JkoYvMrPdPYxYrVbLvr6+drchSRNKRGzJzNrQcX+yWJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwrUkCCJicURsj4idEbGqwXxnRNxdzT8WET11czdU49sj4pJW9CNJGr6mgyAiJgHfAS4F5gDLI2LOkLLPAi9m5lnAt4Bbq2PnAFcAc4HFwL9WzydJGietOCNYAOzMzF2ZeQjoBZYMqVkCrKu27wUuiIioxnsz89XMfAbYWT2fJGmctCIIZgLP1u33V2MNazLzMHAAmD7MYwGIiJUR0RcRffv27WtB25IkmEA3izNzbWbWMrM2Y8aMdrcjSceNVgTBHuCMuv3uaqxhTUR0AFOBgWEeK0kaQ60Igs3A2RExOyLeweDN3/VDatYDK6rtZcBPMjOr8SuqTxXNBs4GHm9BT5KkYepo9gky83BEXANsACYB38/MbRFxM9CXmeuB7wE/jIidwH4Gw4Kq7h7gSeAw8IXMfL3ZniRJwxeDb8wnllqtln19fe1uQ5ImlIjYkpm1oeMT5maxJGlsGASSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYVrKggioisiNkbEjurrtCPUrahqdkTEimrsXRHxQEQ8HRHbIuKWZnqRJI1Os2cEq4CHM/Ns4OFq/y0iogtYDZwLLABW1wXG7Zl5DjAfOD8iLm2yH0nSCDUbBEuAddX2OmBpg5pLgI2ZuT8zXwQ2Aosz85XMfAQgMw8BW4HuJvuRJI1Qs0FwamY+X22/AJzaoGYm8Gzdfn819qaIOAm4jMGzCknSOOo4WkFEPASc1mDqpvqdzMyIyJE2EBEdwF3AnZm5623qVgIrAWbNmjXSl5EkHcFRgyAzLzzSXETsjYjTM/P5iDgd+G2Dsj3Awrr9bmBT3f5aYEdm3nGUPtZWtdRqtREHjiSpsWYvDa0HVlTbK4AfNajZAFwcEdOqm8QXV2NExDeAqcA/NtmHJGmUmg2CW4CLImIHcGG1T0TUIuK7AJm5H/g6sLl63JyZ+yOim8HLS3OArRHxRER8rsl+JEkjFJkT7ypLrVbLvr6+drchSRNKRGzJzNrQcX+yWJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwjUVBBHRFREbI2JH9XXaEepWVDU7ImJFg/n1EfHLZnqRJI1Os2cEq4CHM/Ns4OFq/y0iogtYDZwLLABW1wdGRHwSeLnJPiRJo9RsECwB1lXb64ClDWouATZm5v7MfBHYCCwGiIgpwJeAbzTZhyRplJoNglMz8/lq+wXg1AY1M4Fn6/b7qzGArwPfBF452gtFxMqI6IuIvn379jXRsiSpXsfRCiLiIeC0BlM31e9kZkZEDveFI2Ie8N7MvDYieo5Wn5lrgbUAtVpt2K8jSXp7Rw2CzLzwSHMRsTciTs/M5yPidOC3Dcr2AAvr9ruBTcB5QC0idld9nBIRmzJzIZKkcdPspaH1wBufAloB/KhBzQbg4oiYVt0kvhjYkJn/lpnvycwe4K+AXxkCkjT+mg2CW4CLImIHcGG1T0TUIuK7AJm5n8F7AZurx83VmCTpGBCZE+9ye61Wy76+vna3IUkTSkRsycza0HF/sliSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklS4yMx29zBiEbEP+E27+xihk4HftbuJceaay+CaJ46/yMwZQwcnZBBMRBHRl5m1dvcxnlxzGVzzxOelIUkqnEEgSYUzCMbP2nY30AauuQyueYLzHoEkFc4zAkkqnEEgSYUzCFooIroiYmNE7Ki+TjtC3YqqZkdErGgwvz4ifjn2HTevmTVHxLsi4oGIeDoitkXELePb/chExOKI2B4ROyNiVYP5zoi4u5p/LCJ66uZuqMa3R8Ql49p4E0a75oi4KCK2RMQvqq8fGffmR6GZ73E1PysiXo6I68at6VbITB8tegC3Aauq7VXArQ1quoBd1ddp1fa0uvlPAv8B/LLd6xnrNQPvAhZVNe8AHgUubfeajrDOScCvgTOrXv8XmDOk5h+Af6+2rwDurrbnVPWdwOzqeSa1e01jvOb5wHuq7b8E9rR7PWO53rr5e4H/BK5r93pG8vCMoLWWAOuq7XXA0gY1lwAbM3N/Zr4IbAQWA0TEFOBLwDfGvtWWGfWaM/OVzHwEIDMPAVuB7rFveVQWADszc1fVay+Da69X/29xL3BBREQ13puZr2bmM8DO6vmOdaNec2b+LDOfq8a3Ae+MiM5x6Xr0mvkeExFLgWcYXO+EYhC01qmZ+Xy1/QJwaoOamcCzdfv91RjA14FvAq+MWYet1+yaAYiIk4DLgIfHoMdWOOoa6msy8zBwAJg+zGOPRc2sud6ngK2Z+eoY9dkqo15v9Sbuy8DXxqHPlutodwMTTUQ8BJzWYOqm+p3MzIgY9mdzI2Ie8N7MvHbodcd2G6s11z1/B3AXcGdm7hpdlzoWRcRc4Fbg4nb3MsbWAN/KzJerE4QJxSAYocy88EhzEbE3Ik7PzOcj4nTgtw3K9gAL6/a7gU3AeUAtInYz+H05JSI2ZeZC2mwM1/yGtcCOzLyj+W7HzB7gjLr97mqsUU1/FW5TgYFhHnssambNREQ3cD/wmcz89di327Rm1nsusCwibgNOAv4QEQcz89tj3nUrtPsmxfH0AP6Zt944va1BTReD1xGnVY9ngK4hNT1MnJvFTa2Zwfsh9wF/1u61HGWdHQze5J7NH28kzh1S8wXeeiPxnmp7Lm+9WbyLiXGzuJk1n1TVf7Ld6xiP9Q6pWcMEu1nc9gaOpweD10YfBnYAD9X9Z1cDvltXdxWDNwx3An/f4HkmUhCMes0MvuNK4CngierxuXav6W3W+jfArxj8ZMlN1djNwMer7ckMfmJkJ/A4cGbdsTdVx23nGP1kVCvXDPwT8H9139cngFPavZ6x/B7XPceECwJ/xYQkFc5PDUlS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVLj/B/mtJKp+/GB6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9b869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabc85c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/labels/primary_bhaduri_labels.csv',\n",
       " '../data/processed/labels/allen_cortex_labels.csv',\n",
       " '../data/processed/labels/allen_m1_region_labels.csv',\n",
       " '../data/processed/labels/whole_brain_bhaduri_labels.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c1a6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2099528",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Size of available data is not a multiple of the data-type size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_11070/2415507392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/interim/allen_cortex_T.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_dbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                     raise ValueError(\"Size of available data is not a \"\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \"multiple of the data-type size.\")\n\u001b[1;32m    241\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0m_dbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Size of available data is not a multiple of the data-type size."
     ]
    }
   ],
   "source": [
    "f = memmap('../data/interim/allen_cortex_T.csv', dtype=np.float64, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376629c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
