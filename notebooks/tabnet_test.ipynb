{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f6ea9a",
   "metadata": {},
   "source": [
    "# TabNet Model Test\n",
    "\n",
    "In this notebook, we'll test a training loop for the TabNet model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9edaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.lib.neural import *\n",
    "from models.lib.data import *\n",
    "from models.lib.train import *\n",
    "\n",
    "import helper \n",
    "from helper import gene_intersection\n",
    "from pytorch_tabnet.tab_network import TabNet\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "t = helper.INTERIM_DATA_AND_LABEL_FILES_LIST\n",
    "datafiles, labelfiles = zip(*t.items())\n",
    "datafiles = [f'../data/interim/{f}' for f in datafiles]\n",
    "labelfiles = [f'../data/processed/labels/{f}' for f in labelfiles]\n",
    "refgenes = gene_intersection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4a8cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = total_class_weights(labelfiles, 'Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ecc9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 17 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS/0lEQVR4nO3df4xd9Znf8fenOKGrbHYx6yl1bKghcpAg6nrJiKVtElHRBUOiQKpV1tYqkB9dBwWkRGq1chqpQamQ2B9s1LRbVs7GAqoUwi5LsBpnE4euFlWqCQPrGAMhDMQIW47thS1sm4ou8PSPeya5DHc847kzd2b8fb+kq3vuc77n3Geujz5z/T3n3klVIUlqw99b6gYkSaNj6EtSQwx9SWqIoS9JDTH0Jakhq5a6gdmsWbOmNmzYsNRtSNKK8cgjj/x1VY0NWrfsQ3/Dhg1MTEwsdRuStGIkeW6mdU7vSFJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ2b9RG6SncAHgWNV9e6u9nXg/G7IGcD/qqpNSTYATwJPdev2VtX13TbvAW4Hfg7YDXym/Asu0oq2Yfs3573twVs+sICdaK7m8jUMtwP/CbhzqlBVvzG1nORW4KW+8c9U1aYB+7kN+C3gIXqhvxn41kl3LEmat1mnd6rqQeDFQeuSBPgIcNeJ9pFkLfALVbW3e3d/J3DNSXcrSRrKsHP67wOOVtXTfbVzk/xVkr9M8r6utg441DfmUFeTJI3QsN+yuZU3vss/ApxTVS90c/jfSHLhye40yTZgG8A555wzZIuSpCnzfqefZBXwL4GvT9Wq6pWqeqFbfgR4BngXcBhY37f5+q42UFXtqKrxqhofGxv4ldCSpHkYZnrnXwA/qKqfTtskGUtyWrd8HrAReLaqjgAvJ7mkOw9wLXD/EM8tSZqHWUM/yV3A/wTOT3IoySe7VVt48wnc9wP7k+wD/hS4vqqmTgJ/GvhjYJLe/wC8ckeSRmzWOf2q2jpD/WMDavcC984wfgJ490n2J0laQH4iV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDZk19JPsTHIsyYG+2k1JDifZ192u6lv3uSSTSZ5KckVffXNXm0yyfeF/FEnSbObyTv92YPOA+peqalN32w2Q5AJgC3Bht81/TnJaktOAPwSuBC4AtnZjJUkjtGq2AVX1YJINc9zf1cDdVfUK8KMkk8DF3brJqnoWIMnd3dgnTr5lSdJ8DTOnf2OS/d30z+qutg54vm/Moa42U12SNELzDf3bgHcCm4AjwK0L1RBAkm1JJpJMHD9+fCF3LUlNm1foV9XRqnqtql4HvsLPpnAOA2f3DV3f1Waqz7T/HVU1XlXjY2Nj82lRkjTAvEI/ydq+hx8Gpq7s2QVsSXJ6knOBjcD3gIeBjUnOTfJWeid7d82/bUnSfMx6IjfJXcClwJokh4AvAJcm2QQUcBD4FEBVPZ7kHnonaF8Fbqiq17r93Ah8GzgN2FlVjy/0DyNJOrG5XL2zdUD5qycYfzNw84D6bmD3SXUnSVpQfiJXkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNmTX0k+xMcizJgb7a7yX5QZL9Se5LckZX35Dk/ybZ193+qG+b9yR5LMlkki8nyaL8RJKkGc3lnf7twOZptT3Au6vqHwM/BD7Xt+6ZqtrU3a7vq98G/BawsbtN36ckaZHNGvpV9SDw4rTad6rq1e7hXmD9ifaRZC3wC1W1t6oKuBO4Zl4dS5LmbSHm9D8BfKvv8blJ/irJXyZ5X1dbBxzqG3Ooq0mSRmjVMBsn+TzwKvC1rnQEOKeqXkjyHuAbSS6cx363AdsAzjnnnGFalCT1mfc7/SQfAz4I/GY3ZUNVvVJVL3TLjwDPAO8CDvPGKaD1XW2gqtpRVeNVNT42NjbfFiVJ08wr9JNsBn4b+FBV/aSvPpbktG75PHonbJ+tqiPAy0ku6a7auRa4f+juJUknZdbpnSR3AZcCa5IcAr5A72qd04E93ZWXe7srdd4PfDHJ3wGvA9dX1dRJ4E/TuxLo5+idA+g/DyBJGoFZQ7+qtg4of3WGsfcC986wbgJ490l1J0laUH4iV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhcwr9JDuTHEtyoK92ZpI9SZ7u7ld39ST5cpLJJPuTXNS3zXXd+KeTXLfwP44k6UTm+k7/dmDztNp24IGq2gg80D0GuBLY2N22AbdB75cE8AXgV4GLgS9M/aKQJI3GnEK/qh4EXpxWvhq4o1u+A7imr35n9ewFzkiyFrgC2FNVL1bV3wB7ePMvEknSIhpmTv+sqjrSLf8YOKtbXgc83zfuUFebqf4mSbYlmUgycfz48SFalCT1W5ATuVVVQC3Evrr97aiq8aoaHxsbW6jdSlLzhgn9o920Dd39sa5+GDi7b9z6rjZTXZI0IsOE/i5g6gqc64D7++rXdlfxXAK81E0DfRu4PMnq7gTu5V1NkjQiq+YyKMldwKXAmiSH6F2FcwtwT5JPAs8BH+mG7wauAiaBnwAfB6iqF5P8e+DhbtwXq2r6yWFJ0iKaU+hX1dYZVl02YGwBN8ywn53Azjl3J0laUH4iV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDZl36Cc5P8m+vtvLST6b5KYkh/vqV/Vt87kkk0meSnLFwvwIkqS5WjXfDavqKWATQJLTgMPAfcDHgS9V1e/3j09yAbAFuBB4B/DdJO+qqtfm24Mk6eQs1PTOZcAzVfXcCcZcDdxdVa9U1Y+ASeDiBXp+SdIcLFTobwHu6nt8Y5L9SXYmWd3V1gHP94051NXeJMm2JBNJJo4fP75ALUqShg79JG8FPgT8SVe6DXgnvamfI8CtJ7vPqtpRVeNVNT42NjZsi5KkzkK8078SeLSqjgJU1dGqeq2qXge+ws+mcA4DZ/dtt76rSZJGZCFCfyt9UztJ1vat+zBwoFveBWxJcnqSc4GNwPcW4PklSXM076t3AJK8Dfg14FN95d9Nsgko4ODUuqp6PMk9wBPAq8ANXrkjSaM1VOhX1f8Bfmla7aMnGH8zcPMwzylJmj8/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYMHfpJDiZ5LMm+JBNd7cwke5I83d2v7upJ8uUkk0n2J7lo2OeXJM3dQr3T/+dVtamqxrvH24EHqmoj8ED3GOBKYGN32wbctkDPL0mag8Wa3rkauKNbvgO4pq9+Z/XsBc5IsnaRepAkTbMQoV/Ad5I8kmRbVzurqo50yz8GzuqW1wHP9217qKu9QZJtSSaSTBw/fnwBWpQkAaxagH28t6oOJ/kHwJ4kP+hfWVWVpE5mh1W1A9gBMD4+flLbSpJmNvQ7/ao63N0fA+4DLgaOTk3bdPfHuuGHgbP7Nl/f1SRJIzBU6Cd5W5K3Ty0DlwMHgF3Add2w64D7u+VdwLXdVTyXAC/1TQNJkhbZsNM7ZwH3JZna13+tqj9P8jBwT5JPAs8BH+nG7wauAiaBnwAfH/L5R2LD9m/Oa7uDt3xggTuRpOEMFfpV9SzwywPqLwCXDagXcMMwzylJmj8/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIbMO/STnJ3kL5I8keTxJJ/p6jclOZxkX3e7qm+bzyWZTPJUkisW4geQJM3dqiG2fRX411X1aJK3A48k2dOt+1JV/X7/4CQXAFuAC4F3AN9N8q6qem2IHiRJJ2He7/Sr6khVPdot/y3wJLDuBJtcDdxdVa9U1Y+ASeDi+T6/JOnkLcicfpINwK8AD3WlG5PsT7Izyequtg54vm+zQ8zwSyLJtiQTSSaOHz++EC1KkliA0E/y88C9wGer6mXgNuCdwCbgCHDrye6zqnZU1XhVjY+NjQ3boiSpM1ToJ3kLvcD/WlX9GUBVHa2q16rqdeAr/GwK5zBwdt/m67uaJGlEhrl6J8BXgSer6g/66mv7hn0YONAt7wK2JDk9ybnARuB7831+SdLJG+bqnX8GfBR4LMm+rvZvga1JNgEFHAQ+BVBVjye5B3iC3pU/N3jljiSN1rxDv6r+B5ABq3afYJubgZvn+5ySpOEM805fkjSLDdu/Oa/tDt7ygQXupMevYZCkhvhOX9KSm++7YVi8d8SnKt/pS1JDDH1JaojTO9IJLLeTcNKwfKcvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoy8q9WTrIZ+A/AacAfV9Uto+5BkmZzqn6t9khDP8lpwB8CvwYcAh5OsquqnhhlH9JKdaoGkUZn1O/0LwYmq+pZgCR3A1cDhv5JWG5/T3S59QOGozSTVNXoniz5dWBzVf2r7vFHgV+tqhunjdsGbOseng88tQjtrAH+ehH2u5hWYs+wMvu259FZiX0v957/UVWNDVqxLP9cYlXtAHYs5nMkmaiq8cV8joW2EnuGldm3PY/OSux7JfY8ZdRX7xwGzu57vL6rSZJGYNSh/zCwMcm5Sd4KbAF2jbgHSWrWSKd3qurVJDcC36Z3yebOqnp8lD30WdTpo0WyEnuGldm3PY/OSux7JfYMjPhEriRpafmJXElqiKEvSQ055UM/yeYkTyWZTLJ9wPrTk3y9W/9Qkg1L0GZ/P2cn+YskTyR5PMlnBoy5NMlLSfZ1t3+3FL1O6+lgkse6fiYGrE+SL3ev8/4kFy1Fn9N6Or/vNdyX5OUkn502Zslf6yQ7kxxLcqCvdmaSPUme7u5Xz7Dtdd2Yp5Nct8Q9/16SH3T//vclOWOGbU94LC2mGfq+KcnhvmPgqhm2PWHWLBtVdcre6J0sfgY4D3gr8H3ggmljPg38Ube8Bfj6Eve8FrioW3478MMBPV8K/Lelfn2n9XQQWHOC9VcB3wICXAI8tNQ9DzhWfkzvQy3L6rUG3g9cBBzoq/0usL1b3g78zoDtzgSe7e5Xd8url7Dny4FV3fLvDOp5LsfSEvR9E/Bv5nD8nDBrlsvtVH+n/9Ovfaiq/wdMfe1Dv6uBO7rlPwUuS5IR9vgGVXWkqh7tlv8WeBJYt1T9LKCrgTurZy9wRpK1S91Un8uAZ6rquaVuZLqqehB4cVq5/7i9A7hmwKZXAHuq6sWq+htgD7B5sfrsN6jnqvpOVb3aPdxL73M6y8oMr/VczCVrloVTPfTXAc/3PT7EmwP0p2O6A/Il4JdG0t0suqmmXwEeGrD6nyT5fpJvJblwtJ0NVMB3kjzSfY3GdHP5t1hKW4C7Zli33F5rgLOq6ki3/GPgrAFjlvNr/gl6//MbZLZjaSnc2E1L7ZxhKm05v9ZvcKqH/oqV5OeBe4HPVtXL01Y/Sm8a4peB/wh8Y8TtDfLeqroIuBK4Icn7l7qhueo+KPgh4E8GrF6Or/UbVG9+YcVce53k88CrwNdmGLLcjqXbgHcCm4AjwK1L2s2QTvXQn8vXPvx0TJJVwC8CL4ykuxkkeQu9wP9aVf3Z9PVV9XJV/e9ueTfwliRrRtzm9J4Od/fHgPvo/Xe333L+Co4rgUer6uj0Fcvxte4cnZoe6+6PDRiz7F7zJB8DPgj8ZvfL6k3mcCyNVFUdrarXqup14Csz9LPsXuuZnOqhP5evfdgFTF3V8OvAf5/pYByF7nzCV4Enq+oPZhjzD6fOOyS5mN6/45L9okrytiRvn1qmd8LuwLRhu4Bru6t4LgFe6pueWGpbmWFqZ7m91n36j9vrgPsHjPk2cHmS1d2UxOVdbUmk9weUfhv4UFX9ZIYxczmWRmrauacPM7iflfMVM0t9Jnmxb/SuGvkhvTPrn+9qX6R34AH8fXr/rZ8Evgect8T9vpfef9X3A/u621XA9cD13ZgbgcfpXSGwF/inS9zzeV0v3+/6mnqd+3sOvT+g8wzwGDC+1MdG19fb6IX4L/bVltVrTe8X0hHg7+jNFX+S3nmnB4Cnge8CZ3Zjx+n9RbqpbT/RHduTwMeXuOdJevPeU8f11FVz7wB2n+hYWuK+/0t3zO6nF+Rrp/fdPX5T1izHm1/DIEkNOdWndyRJfQx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JD/D0NHlfSkAPzrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(weights)), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e117d9",
   "metadata": {},
   "source": [
    "First, we'll define our train, val and test sets, then generate the associated DataLoaders and try training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15f491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.neural import TabNetGeneClassifier\n",
    "\n",
    "model = TabNetGeneClassifier(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=19\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3775abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, refgenes, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.refgenes = refgenes\n",
    "        self.currgenes = self.dataset.columns \n",
    "            \n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            yield clean_sample(batch[0], self.refgenes, self.currgenes), batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f6d065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test = SampleLoader(refgenes=refgenes, dataset=train, batch_size=11, num_workers=0)\n",
    "# next(iter(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc26eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next(iter(test))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ef9ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, val, test = generate_loaders(datafiles, labelfiles, 'Type', refgenes=refgenes, shuffle=True, collocate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "273a6d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], size=(4, 0)), tensor([4, 4, 4, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2fbb6",
   "metadata": {},
   "source": [
    "## PyTorch-Lightning compatible TabNet architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd564eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.neural import TabNetGeneClassifier\n",
    "import torch.functional as F\n",
    "from torchmetrics.functional import accuracy, precision, recall \n",
    "\n",
    "base_model = TabNetGeneClassifier(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=19,\n",
    ")\n",
    "\n",
    "class GeneClassifier(pl.LightningModule):\n",
    "    \"\"\"\n",
    "        Initialize the gene classifier neural network\n",
    "\n",
    "        Parameters:\n",
    "        input_dim: Number of features in the inpute matrix \n",
    "        output_dim: Number of classes\n",
    "        weights: Weights to use in loss calculation to account for imbalance in class size \n",
    "        params: Dictionary of hyperparameters to use. Must include width, layers, lr, momentum, weight_decay\n",
    "        metrics: Dictionary of metrics to log, where keys are metric names and values are torchmetrics.functional methods\n",
    "        weighted_metrics: If True, use class-weighted calculation in metrics. Otherwise, use default 'micro' calculation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim, \n",
    "        output_dim,\n",
    "        base_model=None,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        optim_params: Dict[str, float]={\n",
    "            'lr': 0.001,\n",
    "            'weight_decay': 0.01,\n",
    "        },\n",
    "        metrics: Dict[str, Callable]={\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "        },\n",
    "        weighted_metrics=False,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        print(f'Model initialized. {input_dim = }, {output_dim = }. Metrics are {metrics.keys()} and {weighted_metrics = }')\n",
    "\n",
    "        if base_model is None:\n",
    "            self.base_model = TabNetGeneClassifier(\n",
    "                input_dim=input_dim,\n",
    "                output_dim=output_dim,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            )\n",
    "        else:\n",
    "            self.base_model = base_model\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.optimizer = optimizer\n",
    "        self.optim_params = optim_params\n",
    "        self.metrics = metrics\n",
    "        self.weighted_metrics = weighted_metrics\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.base_model(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, logger=True, on_epoch=True, on_step=True)\n",
    "        self._compute_metrics(y_hat, y, 'train')\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", val_loss, logger=True, on_epoch=True, on_step=True)\n",
    "        self._compute_metrics(y_hat, y, 'val')\n",
    "        \n",
    "        return val_loss\n",
    "    \n",
    "    def _compute_metrics(self, y_hat, y, tag, on_epoch=True, on_step=True):\n",
    "        for name, metric in self.metrics.items():\n",
    "            if not self.weighted_metrics: # We dont consider class support in calculation\n",
    "                val = metric(y_hat, y, average='weighted', num_classes=self.output_dim)\n",
    "                self.log(\n",
    "                    f\"weighted_{tag}_{name}\", \n",
    "                    val, \n",
    "                    on_epoch=on_epoch, \n",
    "                    on_step=on_step,\n",
    "                    logger=True,\n",
    "                )\n",
    "            else:\n",
    "                val = metric(y_hat, y)\n",
    "                self.log(\n",
    "                    f\"{tag}_{name}\", \n",
    "                    val, \n",
    "                    on_epoch=on_epoch, \n",
    "                    on_step=on_step,\n",
    "                    logger=True,\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer(self.parameters(), **self.optim_params)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34934de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16604"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a510881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. input_dim = 16604, output_dim = 19. Metrics are dict_keys(['accuracy', 'precision', 'recall']) and weighted_metrics = False\n"
     ]
    }
   ],
   "source": [
    "classifier = GeneClassifier(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=19,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dfac175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl \n",
    "from typing import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "def custom_collate(sample, refgenes, currgenes):\n",
    "    data = clean_sample(torch.stack([x[0] for x in sample]), refgenes, currgenes)\n",
    "    labels = torch.tensor([x[1] for x in sample])\n",
    "    return data, labels\n",
    "\n",
    "class CollateLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, refgenes, currgenes, *args, **kwargs):\n",
    "        collate_fn = functools.partial(custom_collate, refgenes=refgenes, currgenes=currgenes)\n",
    "        super().__init__(collate_fn = collate_fn, *args, **kwargs)\n",
    "\n",
    "class SequentialLoader:\n",
    "    def __init__(self, dataloaders):\n",
    "        self.dataloaders = dataloaders\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(dl) for dl in self.dataloaders])\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from chain(*self.dataloaders)\n",
    "                \n",
    "class GeneDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        datafiles: List[str],\n",
    "        labelfiles: List[str],\n",
    "        class_label: str,\n",
    "        data_path: str,\n",
    "        refgenes: List[str],\n",
    "        batch_size: int=16,\n",
    "        num_workers=32,\n",
    "        shuffle=False,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(**kwargs)\n",
    "\n",
    "        self.datafiles = datafiles\n",
    "        self.labelfiles = labelfiles\n",
    "        self.class_label = class_label\n",
    "        self.refgenes = refgenes\n",
    "        self.shuffle = shuffle\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.trainloaders = []\n",
    "        self.valloaders = []\n",
    "        self.testloaders = []\n",
    "        \n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        data_path = self.data_path\n",
    "        info =  helper.INTERIM_DATA_AND_LABEL_FILES_LIST\n",
    "\n",
    "        datafiles = info.keys()\n",
    "        labelfiles = [info[file] for file in datafiles]\n",
    "\n",
    "        for datafile, labelfile in zip(datafiles, labelfiles):\n",
    "            dfpath = os.path.join(data_path, 'interim', datafile)\n",
    "            lfpath = os.path.join(data_path, 'processed', 'labels', labelfile)\n",
    "\n",
    "            if not os.path.isfile(dfpath):\n",
    "                print(f'Downloading {dfpath}')\n",
    "                download(\n",
    "                    remote_name=os.path.join('jlehrer/expression_data/interim/', datafile),\n",
    "                    file_name=dfpath\n",
    "                )\n",
    "            else:\n",
    "                print(f'{dfpath} exists, continuing...')\n",
    "\n",
    "            if not os.path.isfile(lfpath):\n",
    "                print(f'Downloading {lfpath}')\n",
    "                download(\n",
    "                    remote_name=os.path.join('jlehrer/expression_data/labels/', labelfile),\n",
    "                    file_name=lfpath,\n",
    "                )\n",
    "            else:\n",
    "                print(f'{lfpath} exists, continuing...\\n')    \n",
    "                \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        trainloaders, valloaders, testloaders = generate_loaders(\n",
    "            datafiles=self.datafiles,\n",
    "            labelfiles=self.labelfiles,\n",
    "            class_label=self.class_label,\n",
    "            refgenes=self.refgenes,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=self.shuffle,\n",
    "            *self.args,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        \n",
    "        self.trainloaders = SequentialLoader(trainloaders)\n",
    "        self.valloaders = SequentialLoader(valloaders)\n",
    "        self.testloaders = SequentialLoader(testloaders)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self.trainloaders\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.valloaders\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e824c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = GeneDataModule(\n",
    "    datafiles=datafiles, \n",
    "    labelfiles=labelfiles, \n",
    "    class_label='Type'\n",
    "    data_path='../data', \n",
    "    refgenes=refgenes,\n",
    "    skip=3,\n",
    "    normalize=True,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d50005bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjlehrer1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/julian/Documents/Projects/organoid-classification/notebooks/wandb/run-20220406_213157-n9i3n09u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jlehrer1/TabNet%20Cell%20Type%20Classifier/runs/n9i3n09u\" target=\"_blank\">Tabnet with Metrics</a></strong> to <a href=\"https://wandb.ai/jlehrer1/TabNet%20Cell%20Type%20Classifier\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type                 | Params\n",
      "----------------------------------------------------\n",
      "0 | base_model | TabNetGeneClassifier | 1.1 M \n",
      "----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805bae55b4514e92b13e3a923b0e06ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniconda3/envs/base-data-science/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer \n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project='TabNet Cell Type Classifier', name='Tabnet with Metrics')\n",
    "trainer = Trainer(logger=wandb_logger)\n",
    "\n",
    "trainer.fit(classifier, datamodule=module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec01a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bbac60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    i+1 for i in range(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cbbf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db7e24f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9de13ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i for i in range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c66941cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import download\n",
    "\n",
    "def prepare_data(data_path):\n",
    "    info =  helper.INTERIM_DATA_AND_LABEL_FILES_LIST\n",
    "\n",
    "    datafiles = info.keys()\n",
    "    labelfiles = [info[file] for file in datafiles]\n",
    "\n",
    "    os.makedirs(os.path.join(data_path, 'interim'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(data_path, 'processed', 'labels'), exist_ok=True)\n",
    "\n",
    "\n",
    "    for datafile, labelfile in zip(datafiles, labelfiles):\n",
    "        dfpath = os.path.join(data_path, 'interim', datafile)\n",
    "        lfpath = os.path.join(data_path, 'processed', 'labels', labelfile)\n",
    "\n",
    "        if not os.path.isfile(dfpath):\n",
    "            download(\n",
    "                remote_name=os.path.join('jlehrer/expression_data/interim/', datafile),\n",
    "                file_name=dfpath,\n",
    "            )\n",
    "        else:\n",
    "            print(f'{dfpath} exists, continuing...')\n",
    "\n",
    "        if not os.path.isfile(lfpath):\n",
    "            print(f'Downloading {lfpath}')\n",
    "            download(\n",
    "                remote_name=os.path.join('jlehrer/expression_data/labels/', labelfile),\n",
    "                file_name=dfpath,\n",
    "            )\n",
    "        else:\n",
    "            print(f'{lfpath} exists, continuing...\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b689e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/interim/primary_bhaduri_T.csv exists, continuing...\n",
      "../data/processed/labels/primary_bhaduri_labels.csv exists, continuing...\n",
      "\n",
      "../data/interim/allen_cortex_T.csv exists, continuing...\n",
      "../data/processed/labels/allen_cortex_labels.csv exists, continuing...\n",
      "\n",
      "../data/interim/allen_m1_region_T.csv exists, continuing...\n",
      "../data/processed/labels/allen_m1_region_labels.csv exists, continuing...\n",
      "\n",
      "../data/interim/whole_brain_bhaduri_T.csv exists, continuing...\n",
      "../data/processed/labels/whole_brain_bhaduri_labels.csv exists, continuing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_data('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b12961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a', 'b'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d7fdc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7f700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science] *",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
