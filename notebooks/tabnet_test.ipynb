{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f6ea9a",
   "metadata": {},
   "source": [
    "# TabNet Model Test\n",
    "\n",
    "In this notebook, we'll test a training loop for the TabNet model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9edaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.lib.neural import *\n",
    "from models.lib.data import *\n",
    "from models.lib.train import *\n",
    "\n",
    "import helper \n",
    "from helper import gene_intersection\n",
    "from pytorch_tabnet.tab_network import TabNet\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "from helper import seed_everything\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e117d9",
   "metadata": {},
   "source": [
    "First, we'll define our train, val and test sets, then generate the associated DataLoaders and try training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113c0f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../data/interim/primary_bhaduri_T.csv',\n",
       "  '../data/interim/allen_cortex_T.csv',\n",
       "  '../data/interim/allen_m1_region_T.csv',\n",
       "  '../data/interim/whole_brain_bhaduri_T.csv'],\n",
       " ['../data/processed/labels/primary_bhaduri_labels.csv',\n",
       "  '../data/processed/labels/allen_cortex_labels.csv',\n",
       "  '../data/processed/labels/allen_m1_region_labels.csv',\n",
       "  '../data/processed/labels/whole_brain_bhaduri_labels.csv'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = helper.INTERIM_DATA_AND_LABEL_FILES_LIST\n",
    "datafiles, labelfiles = zip(*t.items())\n",
    "datafiles = [f'../data/interim/{f}' for f in datafiles]\n",
    "labelfiles = [f'../data/processed/labels/{f}' for f in labelfiles]\n",
    "refgenes = gene_intersection()\n",
    "\n",
    "datafiles, labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2d8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c95a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055191aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_single_dataset(\n",
    "    datafiles[0],\n",
    "    labelfiles[0],\n",
    "    'Type',\n",
    "    skip=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88909f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19765\n"
     ]
    }
   ],
   "source": [
    "print(len(train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4a7b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_map, _, _ = generate_single_dataloader(\n",
    "    datafile=datafiles[0], \n",
    "    labelfile=labelfiles[0], \n",
    "    class_label='Type',\n",
    "    skip=3,\n",
    "    map_genes=True\n",
    ")\n",
    "\n",
    "trainloader_nomap, _, _ = generate_single_dataloader(\n",
    "    datafile=datafiles[0], \n",
    "    labelfile=labelfiles[0], \n",
    "    class_label='Type',\n",
    "    skip=3,\n",
    "    map_genes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58ff9c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                                    | 200/29836 [00:13<32:58, 14.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(tqdm(trainloader_map)):\n",
    "    if i == 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2805ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                                    | 200/29836 [00:04<11:53, 41.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(tqdm(trainloader_nomap)):\n",
    "    if i == 200:\n",
    "        break\n",
    "    X = clean_sample(X, refgenes, train.features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79be48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = generate_loaders(\n",
    "    datafiles,\n",
    "    labelfiles,\n",
    "    'Type',\n",
    "    num_workers=0,\n",
    "    collocate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b02376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_88792/4263287783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/organoid-classification/notebooks/../src/models/lib/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c4fb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16604"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(refgenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15f491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.neural import TabNetGeneClassifier\n",
    "\n",
    "model = TabNetGeneClassifier(\n",
    "    input_dim=len(refgenes),\n",
    "    output_dim=19\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3775abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, refgenes, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.refgenes = refgenes\n",
    "        self.currgenes = self.dataset.columns \n",
    "            \n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            yield clean_sample(batch[0], self.refgenes, self.currgenes), batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bada44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = SampleLoader(refgenes=refgenes, dataset=data, batch_size=11, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f93d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "324a8389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([16, 16,  4,  4,  4,  4, 16,  4,  4,  4, 16]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = next(iter(test))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfc7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c2124a9",
   "metadata": {},
   "source": [
    "Now, we'll subset and define our DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31975f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1eseo35v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_train_loss</td><td>▄█▁▂</td></tr><tr><td>epoch_train_loss</td><td>▁</td></tr><tr><td>epoch_val_loss</td><td>▁</td></tr><tr><td>test_loss</td><td>█▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁</td></tr><tr><td>weighted_accuracy_test</td><td>█▁▁▁</td></tr><tr><td>weighted_accuracy_train</td><td>▁▁█▃</td></tr><tr><td>weighted_accuracy_val</td><td>██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_train_loss</td><td>1.6601</td></tr><tr><td>epoch_train_loss</td><td>0.00138</td></tr><tr><td>epoch_val_loss</td><td>0.0056</td></tr><tr><td>test_loss</td><td>2.62397</td></tr><tr><td>val_loss</td><td>3.08289</td></tr><tr><td>weighted_accuracy_test</td><td>0.0</td></tr><tr><td>weighted_accuracy_train</td><td>0.25</td></tr><tr><td>weighted_accuracy_val</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-wind-38</strong>: <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/1eseo35v\" target=\"_blank\">https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/1eseo35v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220404_111127-1eseo35v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1eseo35v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/julian/Documents/Projects/organoid-classification/notebooks/wandb/run-20220404_114512-tcrzlziw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/tcrzlziw\" target=\"_blank\">dazzling-water-39</a></strong> to <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On loader idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 2/29836 [00:00<39:25, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n",
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 6/29836 [00:00<33:59, 14.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n",
      "On minibatch i = 5/10\n",
      "On minibatch i = 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 10/29836 [00:00<34:11, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 7/10\n",
      "On minibatch i = 8/10\n",
      "On minibatch i = 9/10\n",
      "On minibatch i = 10/10\n",
      "On loader idx = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 2/7602 [00:00<10:28, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n",
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 4/7602 [00:00<10:30, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n",
      "On minibatch i = 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 8/7602 [00:00<10:40, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 6/10\n",
      "On minibatch i = 7/10\n",
      "On minibatch i = 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 10/7602 [00:00<10:51, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 9/10\n",
      "On minibatch i = 10/10\n",
      "On loader idx = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                 | 0/12245 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 2/12245 [00:00<18:58, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 4/12245 [00:00<18:09, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n",
      "On minibatch i = 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 6/12245 [00:00<18:23, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 6/10\n",
      "On minibatch i = 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 8/12245 [00:00<18:23, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 10/12245 [00:00<18:46, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 9/10\n",
      "On minibatch i = 10/10\n",
      "On loader idx = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/105528 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 0/10\n",
      "On minibatch i = 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 2/105528 [00:00<2:08:29, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 4/105528 [00:00<2:02:53, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 3/10\n",
      "On minibatch i = 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 6/105528 [00:00<2:04:06, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 5/10\n",
      "On minibatch i = 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 8/105528 [00:00<2:02:24, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 7/10\n",
      "On minibatch i = 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                     | 10/105528 [00:00<2:04:51, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 10/105528 [00:00<2:06:33, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On minibatch i = 10/10\n",
      "On loader i = 10\n",
      "On loader i = 10\n",
      "On loader i = 10\n",
      "On loader i = 10\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "wandb.init()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "mod = 10\n",
    "wandb.watch(model)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    for idx, train in enumerate(train_loader):\n",
    "        print(f'On loader {idx = }')\n",
    "        for i, data in enumerate(tqdm(train)):\n",
    "            print(f'On minibatch {i = }/10')\n",
    "            if i == 10:\n",
    "                break \n",
    "            inputs, labels = data\n",
    "            # CLEAN INPUTS\n",
    "            inputs = clean_sample(inputs, refgenes, train.dataset.columns)\n",
    "            # Forward pass ➡\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass ⬅\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Step with optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "            if i % mod == 0: # record every 2000 mini batches \n",
    "                metric_results = calculate_metrics(\n",
    "                    outputs=outputs,\n",
    "                    labels=labels,\n",
    "                    append_str='train',\n",
    "                    num_classes=model.output_dim,\n",
    "                    subset='weighted_accuracy',\n",
    "                )\n",
    "\n",
    "                wandb.log(metric_results)\n",
    "                running_loss = running_loss / mod\n",
    "                wandb.log({f\"batch_train_loss\": loss})\n",
    "\n",
    "                running_loss = 0.0\n",
    "            \n",
    "    wandb.log({f\"epoch_train_loss\": epoch_loss / len(train)})\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad(): # save memory but not computing gradients \n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for val in val_loader:\n",
    "            print(f'On loader {i = }')\n",
    "            for i, data in enumerate(val):\n",
    "                if i == 10:\n",
    "                    break \n",
    "                inputs, labels = data\n",
    "                # CLEAN INPUTS\n",
    "                inputs = clean_sample(inputs, refgenes, val.dataset.columns)\n",
    "                # Forward pass ➡\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if i % mod == 0: #every 2000 mini batches \n",
    "                    running_loss = running_loss / mod\n",
    "                    wandb.log({\"val_loss\": loss})\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                    metric_results = calculate_metrics(\n",
    "                        outputs=outputs,\n",
    "                        labels=labels,\n",
    "                        num_classes=model.output_dim,\n",
    "                        subset='weighted_accuracy',\n",
    "                        append_str='val',\n",
    "                    )\n",
    "\n",
    "                wandb.log(metric_results)\n",
    "    \n",
    "        wandb.log({f\"epoch_val_loss\": epoch_loss / len(train)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e39c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabNetGeneClassifier(\n",
       "  (embedder): EmbeddingGenerator()\n",
       "  (tabnet): TabNetNoEmbeddings(\n",
       "    (initial_bn): BatchNorm1d(16604, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (encoder): TabNetEncoder(\n",
       "      (initial_bn): BatchNorm1d(16604, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (initial_splitter): FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (shared_layers): ModuleList(\n",
       "            (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "            (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "          )\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (specifics): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (feat_transformers): ModuleList(\n",
       "        (0): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=16604, out_features=32, bias=False)\n",
       "              (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16604, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (att_transformers): ModuleList(\n",
       "        (0): AttentiveTransformer(\n",
       "          (fc): Linear(in_features=8, out_features=16604, bias=False)\n",
       "          (bn): GBN(\n",
       "            (bn): BatchNorm1d(16604, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (selector): Sparsemax()\n",
       "        )\n",
       "        (1): AttentiveTransformer(\n",
       "          (fc): Linear(in_features=8, out_features=16604, bias=False)\n",
       "          (bn): GBN(\n",
       "            (bn): BatchNorm1d(16604, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (selector): Sparsemax()\n",
       "        )\n",
       "        (2): AttentiveTransformer(\n",
       "          (fc): Linear(in_features=8, out_features=16604, bias=False)\n",
       "          (bn): GBN(\n",
       "            (bn): BatchNorm1d(16604, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (selector): Sparsemax()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_mapping): Linear(in_features=8, out_features=19, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae29264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_loop(\n",
    "    model,\n",
    "    testloaders,\n",
    "    refgenes,\n",
    "    criterion,\n",
    "    mod,\n",
    "):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, test in enumerate(testloaders):\n",
    "            print(f'On {idx = }')\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(test):\n",
    "                print(f'minibatch {i = }')\n",
    "                if i == 10:\n",
    "                    break\n",
    "                inputs, labels = data\n",
    "                # CLEAN INPUTS\n",
    "                inputs = clean_sample(inputs, refgenes, test.dataset.columns)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % mod == 0: #every 2000 mini batches \n",
    "                    running_loss = running_loss / mod\n",
    "                    wandb.log({\"test_loss\": loss})\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                    metric_results = calculate_metrics(\n",
    "                        outputs=outputs,\n",
    "                        labels=labels,\n",
    "                        num_classes=model.output_dim,\n",
    "                        subset='weighted_accuracy',\n",
    "                        append_str='test',\n",
    "                    )\n",
    "\n",
    "                    wandb.log(metric_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2b8c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On idx = 0\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n",
      "On idx = 1\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n",
      "On idx = 2\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n",
      "On idx = 3\n",
      "minibatch i = 0\n",
      "minibatch i = 1\n",
      "minibatch i = 2\n",
      "minibatch i = 3\n",
      "minibatch i = 4\n",
      "minibatch i = 5\n",
      "minibatch i = 6\n",
      "minibatch i = 7\n",
      "minibatch i = 8\n",
      "minibatch i = 9\n",
      "minibatch i = 10\n"
     ]
    }
   ],
   "source": [
    "test_loop(model, test_loader, refgenes, criterion, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7666179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9b869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabc85c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/labels/primary_bhaduri_labels.csv',\n",
       " '../data/processed/labels/allen_cortex_labels.csv',\n",
       " '../data/processed/labels/allen_m1_region_labels.csv',\n",
       " '../data/processed/labels/whole_brain_bhaduri_labels.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4aa3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6474f9c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Size of available data is not a multiple of the data-type size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_11070/2415507392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/interim/allen_cortex_T.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_dbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                     raise ValueError(\"Size of available data is not a \"\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \"multiple of the data-type size.\")\n\u001b[1;32m    241\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0m_dbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Size of available data is not a multiple of the data-type size."
     ]
    }
   ],
   "source": [
    "f = memmap('../data/interim/allen_cortex_T.csv', dtype=np.float64, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c758f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
