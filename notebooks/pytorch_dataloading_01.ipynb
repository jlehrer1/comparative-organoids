{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7267866e",
   "metadata": {},
   "source": [
    "# Dataloading 01\n",
    "\n",
    "In this notebook, we'll figure out how to use PyTorch's DataLoader class to load our massive files without reading the entirety of them into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c111cd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbbb093be30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd \n",
    "import torch\n",
    "import linecache \n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75396dd",
   "metadata": {},
   "source": [
    "We'll first design a custom dataset to use with PyTorch's `DataLoader` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9854304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneExpressionData(Dataset):\n",
    "    def __init__(self, filename, labelname):\n",
    "        self._filename = filename\n",
    "        self._labelname = labelname\n",
    "        self._total_data = 0\n",
    "        \n",
    "        with open(filename, \"r\") as f:\n",
    "            self._total_data = len(f.readlines()) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx == 0:\n",
    "            return self.__getitem__(1)\n",
    "        \n",
    "        line = linecache.getline(self._filename, idx + 1)\n",
    "        label = linecache.getline(self._labelname, idx + 1)\n",
    "        \n",
    "        csv_data = csv.reader([line])\n",
    "        csv_label = csv.reader([label])\n",
    "        \n",
    "        data = [x for x in csv_data][0]\n",
    "        label = [x for x in csv_label][0]\n",
    "        \n",
    "        return torch.from_numpy(np.array([float(x) for x in data])).float(), [int(float(x)) for x in label][0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._total_data\n",
    "    \n",
    "    def num_labels(self):\n",
    "        return pd.read_csv(self._labelname)['# label'].nunique()\n",
    "    \n",
    "    def num_features(self):\n",
    "        return len(self.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b3611",
   "metadata": {},
   "source": [
    "Since PyTorch loss functions require classes in $[0, C]$, we'll first add $1$ to the labels and re-write it out so we can use it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21adce01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fix_labels(file):\n",
    "    labels = pd.read_csv(file)\n",
    "    labels['# label'] = labels['# label'].astype(int) + 1\n",
    "    labels.to_csv('fixed_' + file.split('/')[-1], index=False)\n",
    "\n",
    "fix_labels('../data/processed/primary_labels_neighbors_50_components_50_clust_size_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a66373",
   "metadata": {},
   "source": [
    "Let's test this quickly and then continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1d977fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/processed/primary_labels_neighbors_50_components_50_clust_size_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8eecf6",
   "metadata": {},
   "source": [
    "Great, we now continue as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1c2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = GeneExpressionData(\n",
    "    filename='../data/processed/primary_reduction_neighbors_50_components_50.csv',\n",
    "    labelname='fixed_primary_labels_neighbors_50_components_50_clust_size_100.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d7cddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.744161</td>\n",
       "      <td>4.117685</td>\n",
       "      <td>4.331740</td>\n",
       "      <td>4.484131</td>\n",
       "      <td>6.329494</td>\n",
       "      <td>4.800045</td>\n",
       "      <td>8.771153</td>\n",
       "      <td>5.297653</td>\n",
       "      <td>1.556207</td>\n",
       "      <td>...</td>\n",
       "      <td>5.402350</td>\n",
       "      <td>3.368630</td>\n",
       "      <td>2.418743</td>\n",
       "      <td>6.432809</td>\n",
       "      <td>0.835661</td>\n",
       "      <td>1.250952</td>\n",
       "      <td>6.484134</td>\n",
       "      <td>6.123850</td>\n",
       "      <td>5.155292</td>\n",
       "      <td>5.048383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.736738</td>\n",
       "      <td>4.116271</td>\n",
       "      <td>4.351516</td>\n",
       "      <td>4.516574</td>\n",
       "      <td>6.312790</td>\n",
       "      <td>4.823830</td>\n",
       "      <td>8.744577</td>\n",
       "      <td>5.311924</td>\n",
       "      <td>1.578302</td>\n",
       "      <td>...</td>\n",
       "      <td>5.426800</td>\n",
       "      <td>3.394699</td>\n",
       "      <td>2.405094</td>\n",
       "      <td>6.430271</td>\n",
       "      <td>0.767878</td>\n",
       "      <td>1.236046</td>\n",
       "      <td>6.467800</td>\n",
       "      <td>6.092812</td>\n",
       "      <td>5.154266</td>\n",
       "      <td>5.026052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.746748</td>\n",
       "      <td>4.142232</td>\n",
       "      <td>4.338512</td>\n",
       "      <td>4.473803</td>\n",
       "      <td>6.406012</td>\n",
       "      <td>4.792516</td>\n",
       "      <td>8.739078</td>\n",
       "      <td>5.297864</td>\n",
       "      <td>1.562608</td>\n",
       "      <td>...</td>\n",
       "      <td>5.414892</td>\n",
       "      <td>3.362663</td>\n",
       "      <td>2.415097</td>\n",
       "      <td>6.435054</td>\n",
       "      <td>0.771711</td>\n",
       "      <td>1.220557</td>\n",
       "      <td>6.511899</td>\n",
       "      <td>6.157069</td>\n",
       "      <td>5.161437</td>\n",
       "      <td>5.075896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.700582</td>\n",
       "      <td>4.098061</td>\n",
       "      <td>4.376571</td>\n",
       "      <td>4.506793</td>\n",
       "      <td>6.336909</td>\n",
       "      <td>4.819511</td>\n",
       "      <td>8.761378</td>\n",
       "      <td>5.286463</td>\n",
       "      <td>1.478201</td>\n",
       "      <td>...</td>\n",
       "      <td>5.396242</td>\n",
       "      <td>3.379358</td>\n",
       "      <td>2.376040</td>\n",
       "      <td>6.443280</td>\n",
       "      <td>0.805606</td>\n",
       "      <td>1.196619</td>\n",
       "      <td>6.480151</td>\n",
       "      <td>6.122002</td>\n",
       "      <td>5.148429</td>\n",
       "      <td>5.038345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.747905</td>\n",
       "      <td>4.113430</td>\n",
       "      <td>4.337235</td>\n",
       "      <td>4.481512</td>\n",
       "      <td>6.325781</td>\n",
       "      <td>4.797932</td>\n",
       "      <td>8.767736</td>\n",
       "      <td>5.293727</td>\n",
       "      <td>1.562555</td>\n",
       "      <td>...</td>\n",
       "      <td>5.405585</td>\n",
       "      <td>3.369891</td>\n",
       "      <td>2.417424</td>\n",
       "      <td>6.433032</td>\n",
       "      <td>0.827843</td>\n",
       "      <td>1.240131</td>\n",
       "      <td>6.488463</td>\n",
       "      <td>6.131742</td>\n",
       "      <td>5.153129</td>\n",
       "      <td>5.050637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0  1.744161  4.117685  4.331740  4.484131  6.329494  4.800045   \n",
       "1           1  1.736738  4.116271  4.351516  4.516574  6.312790  4.823830   \n",
       "2           2  1.746748  4.142232  4.338512  4.473803  6.406012  4.792516   \n",
       "3           3  1.700582  4.098061  4.376571  4.506793  6.336909  4.819511   \n",
       "4           4  1.747905  4.113430  4.337235  4.481512  6.325781  4.797932   \n",
       "\n",
       "          6         7         8  ...        40        41        42        43  \\\n",
       "0  8.771153  5.297653  1.556207  ...  5.402350  3.368630  2.418743  6.432809   \n",
       "1  8.744577  5.311924  1.578302  ...  5.426800  3.394699  2.405094  6.430271   \n",
       "2  8.739078  5.297864  1.562608  ...  5.414892  3.362663  2.415097  6.435054   \n",
       "3  8.761378  5.286463  1.478201  ...  5.396242  3.379358  2.376040  6.443280   \n",
       "4  8.767736  5.293727  1.562555  ...  5.405585  3.369891  2.417424  6.433032   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0  0.835661  1.250952  6.484134  6.123850  5.155292  5.048383  \n",
       "1  0.767878  1.236046  6.467800  6.092812  5.154266  5.026052  \n",
       "2  0.771711  1.220557  6.511899  6.157069  5.161437  5.075896  \n",
       "3  0.805606  1.196619  6.480151  6.122002  5.148429  5.038345  \n",
       "4  0.827843  1.240131  6.488463  6.131742  5.153129  5.050637  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/processed/primary_reduction_neighbors_50_components_50.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e449b7b",
   "metadata": {},
   "source": [
    "Let's see how fast it takes to load a minibatch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "372f593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.34 ms, sys: 330 Âµs, total: 5.67 ms\n",
      "Wall time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for i in range(64):\n",
    "    t.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d406e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.num_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8092856",
   "metadata": {},
   "source": [
    "Before we train our model, we need to split our data into training and testing sets, in order to get an unbiased evaluation of our model's performance. Likely, we will initially overfit the training set since we provide no regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78575cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(t))\n",
    "test_size = len(t) - train_size\n",
    "\n",
    "train, test = torch.utils.data.random_split(t, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d216d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DataLoader(train, batch_size = 8, num_workers = 0)\n",
    "valdata = DataLoader(test, batch_size = 8, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695113b",
   "metadata": {},
   "source": [
    "Now that we've defined our `DataLoader`, let's test it when training a simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "021a73e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, N_features, N_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features=N_features),\n",
    "            nn.Linear(in_features=N_features, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=N_labels),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88f01656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 51, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN(\n",
    "    N_features=t.num_features(),\n",
    "    N_labels=t.num_labels()\n",
    ")\n",
    "\n",
    "m = torch.randn(10, t.num_features(), 1)\n",
    "\n",
    "m.unsqueeze(dim=3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49a68a",
   "metadata": {},
   "source": [
    "Now we can define our criterion, optimization method and train our model on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4588c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "loss_arr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159fe20",
   "metadata": {},
   "source": [
    "And finally train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e3994b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 is 2.791111469268799\n",
      "Epoch 1 is 2.796858310699463\n",
      "Epoch 2 is 2.7463631629943848\n",
      "Epoch 3 is 2.812925338745117\n",
      "Epoch 4 is 2.726506233215332\n",
      "Epoch 5 is 2.7621710300445557\n",
      "Epoch 6 is 2.7859160900115967\n",
      "Epoch 7 is 2.7637641429901123\n",
      "Epoch 8 is 2.7586119174957275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_15201/4266666406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for X, y in traindata:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_arr.append(loss.item())\n",
    "        \n",
    "    print(f'Epoch {i} is {loss_arr[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78718088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0587053998627307\n",
    "# 1.058727260653217\n",
    "# 1.0583432531826011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e498da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adfef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science] *",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
