{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7267866e",
   "metadata": {},
   "source": [
    "# Dataloading 01\n",
    "\n",
    "In this notebook, we'll figure out how to use PyTorch's DataLoader class to load our massive files without reading the entirety of them into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c111cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd \n",
    "import torch\n",
    "import linecache \n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75396dd",
   "metadata": {},
   "source": [
    "We'll first design a custom dataset to use with PyTorch's `DataLoader` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9854304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneExpressionData(Dataset):\n",
    "    def __init__(self, filename, labelname):\n",
    "        self._filename = filename\n",
    "        self._labelname = labelname\n",
    "        self._total_data = 0\n",
    "        \n",
    "        with open(filename, \"r\") as f:\n",
    "            self._total_data = len(f.readlines()) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        line = linecache.getline(self._filename, idx + 2)\n",
    "        label = linecache.getline(self._labelname, idx + 2)\n",
    "        \n",
    "        csv_data = csv.reader([line])\n",
    "        csv_label = csv.reader([label])\n",
    "        \n",
    "        data = [x for x in csv_data][0]\n",
    "        label = [x for x in csv_label][0]\n",
    "        return torch.from_numpy(np.array([float(x) for x in data])).float(), [int(float(x)) for x in label][0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._total_data\n",
    "    \n",
    "    def num_labels(self):\n",
    "        return pd.read_csv(self._labelname)['# label'].nunique()\n",
    "    \n",
    "    def num_features(self):\n",
    "        return len(self.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b3611",
   "metadata": {},
   "source": [
    "Since PyTorch loss functions require classes in $[0, C]$, we'll first add $1$ to the labels and re-write it out so we can use it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21adce01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fix_labels(file):\n",
    "    labels = pd.read_csv(file)\n",
    "    labels['# label'] = labels['# label'].astype(int) + 1\n",
    "    labels.to_csv('fixed_' + file.split('/')[-1], index=False)\n",
    "\n",
    "fix_labels('../data/processed/labels/primary_labels_neighbors_50_components_100_clust_size_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8eecf6",
   "metadata": {},
   "source": [
    "Great, we now continue as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1c2186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = GeneExpressionData(\n",
    "    filename='../data/processed/umap/primary_reduction_neighbors_100_components_3.csv',\n",
    "    labelname='fixed_primary_labels_neighbors_50_components_50_clust_size_100.csv'\n",
    ")\n",
    "t.num_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e449b7b",
   "metadata": {},
   "source": [
    "Let's see how fast it takes to load a minibatch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372f593c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 ms, sys: 15.9 ms, total: 51.6 ms\n",
      "Wall time: 51.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for i in range(64):\n",
    "    t.__getitem__(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8092856",
   "metadata": {},
   "source": [
    "Before we train our model, we need to split our data into training and testing sets, in order to get an unbiased evaluation of our model's performance. Likely, we will initially overfit the training set since we provide no regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78575cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(t))\n",
    "test_size = len(t) - train_size\n",
    "\n",
    "train, test = torch.utils.data.random_split(t, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d216d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DataLoader(train, batch_size = 8, num_workers = 0)\n",
    "valdata = DataLoader(test, batch_size = 8, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695113b",
   "metadata": {},
   "source": [
    "Now that we've defined our `DataLoader`, let's test it when training a simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c448e",
   "metadata": {},
   "source": [
    "## Using PyTorch Lightning\n",
    "\n",
    "PyTorch lightning seems nicer than Ignite, especially for GPU training. Let's test it out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5adfef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class GeneClassifier(pl.LightningModule):\n",
    "    def __init__(self, N_features, N_labels, weights):\n",
    "        \"\"\"\n",
    "        Initialize the gene classifier neural network\n",
    "\n",
    "        Parameters:\n",
    "        N_features: Number of features in the inpute matrix \n",
    "        N_labels: Number of classes \n",
    "        \"\"\"\n",
    "\n",
    "        super(GeneClassifier, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(N_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, N_labels),\n",
    "        )\n",
    "        \n",
    "        self.accuracy = Accuracy()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=1e-3, momentum=0.8)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y, weight=self.weights)\n",
    "        acc = self.accuracy(y_hat.softmax(dim=-1), y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train_accuracy\", acc, on_step=False, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y, weight=self.weights)\n",
    "        acc = self.accuracy(y_hat.softmax(dim=-1), y)\n",
    "\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"val_accuracy\", acc, on_step=False, on_epoch=True, logger=True)\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4c308",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db924463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def class_weights(label_df):\n",
    "    label_df = pd.read_csv(label_df)\n",
    "    \n",
    "    weights = compute_class_weight(\n",
    "        class_weight='balanced', \n",
    "        classes=np.unique(label_df), \n",
    "        y=label_df.values.reshape(-1)\n",
    "    ) \n",
    "\n",
    "    weights = torch.from_numpy(weights)\n",
    "    return weights.float()\n",
    "\n",
    "weights = class_weights('fixed_primary_labels_neighbors_50_components_50_clust_size_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2a8982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.6428,   2.0281,  43.2046,   1.8374,   0.8580,  33.3467, 102.0523,\n",
       "        100.3226,   0.5029,   0.6207,   2.0534,   0.4522,   0.3983,  13.3462,\n",
       "          1.3319,   0.3946])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c99f3ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneClassifier(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  )\n",
       "  (accuracy): Accuracy()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GeneClassifier(t.num_features(), t.num_labels(), weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "536d2548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class UploadCallback(pl.callbacks.Callback):\n",
    "    def __init__(self, path, WIDTH, LAYERS) -> None:\n",
    "        super().__init__()\n",
    "        self.path = path \n",
    "        self.width = WIDTH\n",
    "        self.layers = LAYERS\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        epoch = trainer.current_epoch\n",
    "        trainer.save_checkpoint(f'checkpoints/checkpoint-{epoch}-width-{self.width}-layers-{self.layers}.ckpt')\n",
    "        print(os.listdir('checkpoints'))\n",
    "        print ('Uploading file...')\n",
    "\n",
    "uploadcallback = UploadCallback('checkpoints', 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2a6705f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 1.3 K \n",
      "2 | accuracy          | Accuracy   | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9d1ca9aaaf40e3b7df1c7e3858373a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint-0.ckpt', 'checkpoint-1.ckpt', 'checkpoint-0-width-10-layers-10.ckpt', 'checkpoint-2.ckpt', 'checkpoint-3.ckpt']\n",
      "Uploading file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint-1-width-10-layers-10.ckpt', 'checkpoint-0.ckpt', 'checkpoint-1.ckpt', 'checkpoint-0-width-10-layers-10.ckpt', 'checkpoint-2.ckpt', 'checkpoint-3.ckpt']\n",
      "Uploading file...\n"
     ]
    }
   ],
   "source": [
    "traindata = DataLoader(train, batch_size = 64, num_workers = 0)\n",
    "valdata = DataLoader(test, batch_size = 64, num_workers = 0)\n",
    "\n",
    "trainer = pl.Trainer(auto_lr_find=True, max_epochs=10, callbacks=[uploadcallback])\n",
    "trainer.fit(model, traindata, valdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8fe8852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.6639,  2.5859,  6.3119]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d66e947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0477, 0.0561, 0.0707, 0.0713, 0.0322, 0.0288, 0.1416, 0.0733, 0.0969,\n",
       "         0.0315, 0.0316, 0.0734, 0.0482, 0.0638, 0.0587, 0.0743],\n",
       "        [0.0406, 0.0597, 0.0842, 0.0741, 0.0414, 0.0376, 0.1091, 0.0808, 0.0860,\n",
       "         0.0338, 0.0289, 0.0686, 0.0551, 0.0890, 0.0535, 0.0574],\n",
       "        [0.0486, 0.0700, 0.0776, 0.0796, 0.0426, 0.0398, 0.0968, 0.0645, 0.0694,\n",
       "         0.0479, 0.0325, 0.0698, 0.0588, 0.0836, 0.0589, 0.0597],\n",
       "        [0.0472, 0.0558, 0.0782, 0.0723, 0.0378, 0.0275, 0.1213, 0.0777, 0.1053,\n",
       "         0.0293, 0.0338, 0.0658, 0.0474, 0.0798, 0.0511, 0.0700],\n",
       "        [0.0424, 0.0585, 0.0837, 0.0704, 0.0475, 0.0430, 0.0946, 0.0803, 0.0861,\n",
       "         0.0366, 0.0335, 0.0660, 0.0581, 0.0853, 0.0557, 0.0584],\n",
       "        [0.0454, 0.0643, 0.0796, 0.0715, 0.0466, 0.0434, 0.0931, 0.0741, 0.0801,\n",
       "         0.0410, 0.0342, 0.0670, 0.0577, 0.0851, 0.0574, 0.0593],\n",
       "        [0.0380, 0.0606, 0.0871, 0.0812, 0.0356, 0.0360, 0.1190, 0.0721, 0.0751,\n",
       "         0.0366, 0.0235, 0.0829, 0.0552, 0.0918, 0.0518, 0.0536],\n",
       "        [0.0456, 0.0598, 0.0674, 0.0779, 0.0317, 0.0281, 0.1510, 0.0826, 0.0831,\n",
       "         0.0321, 0.0247, 0.0712, 0.0525, 0.0774, 0.0518, 0.0630]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.from_numpy(a)\n",
    "l = torch.from_numpy(l)\n",
    "t.softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac114263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0477, 0.0561, 0.0707, 0.0713, 0.0322, 0.0288, 0.1416, 0.0733, 0.0969,\n",
       "         0.0315, 0.0316, 0.0734, 0.0482, 0.0638, 0.0587, 0.0743],\n",
       "        [0.0406, 0.0597, 0.0842, 0.0741, 0.0414, 0.0376, 0.1091, 0.0808, 0.0860,\n",
       "         0.0338, 0.0289, 0.0686, 0.0551, 0.0890, 0.0535, 0.0574],\n",
       "        [0.0486, 0.0700, 0.0776, 0.0796, 0.0426, 0.0398, 0.0968, 0.0645, 0.0694,\n",
       "         0.0479, 0.0325, 0.0698, 0.0588, 0.0836, 0.0589, 0.0597],\n",
       "        [0.0472, 0.0558, 0.0782, 0.0723, 0.0378, 0.0275, 0.1213, 0.0777, 0.1053,\n",
       "         0.0293, 0.0338, 0.0658, 0.0474, 0.0798, 0.0511, 0.0700],\n",
       "        [0.0424, 0.0585, 0.0837, 0.0704, 0.0475, 0.0430, 0.0946, 0.0803, 0.0861,\n",
       "         0.0366, 0.0335, 0.0660, 0.0581, 0.0853, 0.0557, 0.0584],\n",
       "        [0.0454, 0.0643, 0.0796, 0.0715, 0.0466, 0.0434, 0.0931, 0.0741, 0.0801,\n",
       "         0.0410, 0.0342, 0.0670, 0.0577, 0.0851, 0.0574, 0.0593],\n",
       "        [0.0380, 0.0606, 0.0871, 0.0812, 0.0356, 0.0360, 0.1190, 0.0721, 0.0751,\n",
       "         0.0366, 0.0235, 0.0829, 0.0552, 0.0918, 0.0518, 0.0536],\n",
       "        [0.0456, 0.0598, 0.0674, 0.0779, 0.0317, 0.0281, 0.1510, 0.0826, 0.0831,\n",
       "         0.0321, 0.0247, 0.0712, 0.0525, 0.0774, 0.0518, 0.0630]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e362d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science] *",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
