{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be54c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import *\n",
    "from tqdm import tqdm\n",
    "import linecache \n",
    "\n",
    "sys.path.append('../src/')\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.lib.neural import GeneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16540141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.lib.data import *\n",
    "from src.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f2a8cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = GeneExpressionData(\n",
    "    filename='../data/interim/allen_cortex_T.csv',\n",
    "    labelname='../data/processed/labels/allen_cortex_labels.csv',\n",
    "    class_label='Type',\n",
    "    cast=True,\n",
    "    skip=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4972fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.6 ms ± 1.24 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "test[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7ad762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 s, sys: 57.6 ms, total: 2.33 s\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "refgenes = gene_intersection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ffd7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "loader = DataLoader(test, batch_size=4)\n",
    "sample = next(iter(loader))\n",
    "sample = sample[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c97585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sample(sample, refgenes, currgenes):\n",
    "    intersection = np.intersect1d(currgenes, refgenes, return_indices=True)\n",
    "    indices = intersection[1] # List of indices in currgenes that equal refgenes \n",
    "    \n",
    "    axis = (1 if sample.ndim == 2 else 0)\n",
    "    sample = np.sort(sample, axis=axis)\n",
    "    sample = np.take(sample, indices, axis=axis)\n",
    "\n",
    "    return torch.from_numpy(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc0ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../data/interim/primary_bhaduri_T.csv',\n",
       "  '../data/interim/allen_cortex_T.csv',\n",
       "  '../data/interim/allen_m1_region_T.csv',\n",
       "  '../data/interim/whole_brain_bhaduri_T.csv'],\n",
       " ['../data/processed/labels/primary_bhaduri_labels.csv',\n",
       "  '../data/processed/labels/allen_cortex_labels.csv',\n",
       "  '../data/processed/labels/allen_m1_region_labels.csv',\n",
       "  '../data/processed/labels/whole_brain_bhaduri_labels.csv'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles, labelfiles = list(INTERIM_DATA_AND_LABEL_FILES_LIST.keys()), list(INTERIM_DATA_AND_LABEL_FILES_LIST.values())\n",
    "\n",
    "datafiles = [os.path.join('..', 'data', 'interim', f) for f in datafiles]\n",
    "labelfiles = [os.path.join('..', 'data', 'processed/labels', f) for f in labelfiles]\n",
    "datafiles, labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07b88a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "loader = DataLoader(train, batch_size=4)\n",
    "currgenes = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541c6dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onedsample = train[0][0]\n",
    "len(onedsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e00668b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (clean_sample(onedsample, refgenes, currgenes))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ea2c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16604"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23097229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 19765])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twodsample = next(iter(loader))[0]\n",
    "twodsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5345a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "sample = clean_sample(twodsample, refgenes, currgenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f9cc93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab88a2c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for X, y in tqdm(loader):\n",
    "#     X = clean_sample(X, refgenes, currgenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a69eda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "263e2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(datafiles[0], nrows=1, header=1).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015779ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = []\n",
    "# for file in datafiles:\n",
    "#     # Read in columns, split by | (since some are PVALB|PVALB), and make sure all are uppercase\n",
    "#     temp = pd.read_csv(file, nrows=1, header=1).columns \n",
    "#     temp = [x.split('|')[0].upper().strip() for x in temp]\n",
    "    \n",
    "#     print(f'Temp is {temp[0:5]}...')\n",
    "#     cols.append(set(temp))\n",
    "\n",
    "# unique = list(set.intersection(*cols))\n",
    "# unique = sorted(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e128002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fbb29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = pd.read_csv(datafiles[0], nrows=1, header=1).columns \n",
    "# temp = [x.strip().upper() for x in temp]\n",
    "# l = train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3c3d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l == temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87674c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(unique).intersection(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e0ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dba3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(unique).intersection([x.upper().strip() for x in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc02b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "041a9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. N_features = 19765, N_labels = 9. Metrics are {'accuracy': <function accuracy at 0x7fba93c33040>, 'precision': <function precision at 0x7fba93c45b80>, 'recall': <function recall at 0x7fba93c45ca0>} and weighted_metrics = False\n"
     ]
    }
   ],
   "source": [
    "train = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "loader = DataLoader(train, batch_size=4)\n",
    "\n",
    "model = GeneClassifier(\n",
    "    N_features=len(train.columns),\n",
    "    N_labels=len(train.labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "842f0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8467, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.8507, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.6067, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(loader))[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "338da83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# model(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab419a27",
   "metadata": {},
   "source": [
    "Now let's time iterating over our dataloader with and without the extra data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea73cfb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for X, y in tqdm(loader):\n",
    "#     X\n",
    "#     model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dacaa60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. N_features = 16604, N_labels = 9. Metrics are {'accuracy': <function accuracy at 0x7fba93c33040>, 'precision': <function precision at 0x7fba93c45b80>, 'recall': <function recall at 0x7fba93c45ca0>} and weighted_metrics = False\n"
     ]
    }
   ],
   "source": [
    "train = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "loader = DataLoader(train, batch_size=4)\n",
    "\n",
    "model = GeneClassifier(\n",
    "    N_features=len(refgenes),\n",
    "    N_labels=len(train.labels)\n",
    ")\n",
    "\n",
    "# for X, y in tqdm(loader):\n",
    "#     X = clean_sample(X, refgenes, train.columns)\n",
    "#     model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0a9595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_data = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "df2_data = GeneExpressionData(datafiles[1], labelfiles[1], 'Type', skip=3)\n",
    "df3_data = GeneExpressionData(datafiles[2], labelfiles[2], 'Type', skip=3)\n",
    "df4_data = GeneExpressionData(datafiles[3], labelfiles[3], 'Type', skip=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9967b451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.,  ..., 0., 0., 0.]), 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f4b4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.models.lib.data import _generate_stratified_dataset\n",
    "\n",
    "train, test = _generate_stratified_dataset(\n",
    "        dataset_files=datafiles,\n",
    "        label_files=labelfiles,\n",
    "        class_label='Type',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d626a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abbb868",
   "metadata": {},
   "source": [
    "We can see that it's much faster to clean the sample on each minibatch, since numpy clearly scales well under-the-hood. Therefore, we'll have to write a manual training loop as we can no longer use pytorch lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34758e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# train = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "# loader = DataLoader(train, batch_size=4)\n",
    "\n",
    "# model = GeneClassifier(\n",
    "#     N_features=len(train.columns),\n",
    "#     load\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c69044",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined, test, insize, numlabels, weights = generate_datasets(datafiles, labelfiles, 'Type', skip=3)\n",
    "# numlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "trainloader = DataLoader(train, batch_size=4)\n",
    "\n",
    "net = GeneClassifier(\n",
    "    N_features=len(train.columns),\n",
    "    N_labels=max(train.labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = []\n",
    "refgenes = gene_intersection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datafile, labelfile in zip(datafiles, labelfiles):\n",
    "    data = GeneExpressionData(\n",
    "            datafile,\n",
    "            labelfile,\n",
    "            'Type',\n",
    "            cast=False,\n",
    "    )\n",
    "    \n",
    "#     print(data[0][0][0:5])\n",
    "    loaders.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cccb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in loaders:\n",
    "#     print(data.name)\n",
    "#     print(data[0][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [DataLoader(data, batch_size=4) for data in loaders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(datafiles[0], nrows=75, header=1)\n",
    "# df2 = pd.read_csv(datafiles[1], nrows=75, header=1)\n",
    "# df3 = pd.read_csv(datafiles[2], nrows=75, header=1)\n",
    "# df4 = pd.read_csv(datafiles[3], nrows=75, header=1)\n",
    "\n",
    "# df1_labels = pd.read_csv(labelfiles[0])\n",
    "# df2_labels = pd.read_csv(labelfiles[1])\n",
    "# df3_labels = pd.read_csv(labelfiles[2])\n",
    "# df4_labels = pd.read_csv(labelfiles[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd59a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df1_labels.loc[186471, 'cell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_labels['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d43f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f71ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_data = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "df2_data = GeneExpressionData(datafiles[1], labelfiles[1], 'Type', skip=3)\n",
    "df3_data = GeneExpressionData(datafiles[2], labelfiles[2], 'Type', skip=3)\n",
    "df4_data = GeneExpressionData(datafiles[3], labelfiles[3], 'Type', skip=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [df1_data, df2_data, df3_data, df4_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91991281",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset.columns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_data = GeneExpressionData(datafiles[1], labelfiles[1], 'Type', skip=2)\n",
    "len(df2_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d00b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bba39",
   "metadata": {},
   "source": [
    "The falses makes sense since the indices arent being changed when we're reading in the pure dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8830d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k1 = df2_data[0][0]\n",
    "# k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715ec7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.linalg.norm(df2.iloc[1, :] - k1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_labels_raw = pd.read_csv('../data/interim/labels/allen_cortex_labels.csv')\n",
    "# df2_labels_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all(np.isclose(df2.loc[0, :], df2_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_data = GeneExpressionData(datafiles[1], labelfiles[1], 'Type', skip=3)\n",
    "# all(np.isclose(df2.loc[1, :], df2_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb9474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70150717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4_labels.loc[5, 'cell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1331c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linalg.norm(df4.loc[7, :].values - df4_data[5][0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72255ed4",
   "metadata": {},
   "source": [
    "Ok, so this issue of non-matching just seems to be with the second dataset, which also requires a different skip number and seems to have some weird behavior. Investigate this one more, which is `allen_cortex_T.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d7390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     k = df1.loc[df1_labels.loc[i, 'cell']]\n",
    "#     s = df1_data[i][0]\n",
    "    \n",
    "#     print(all(np.isclose(k, s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d02a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     k = df2.loc[df2_labels.loc[i, 'cell']]\n",
    "#     s = df2_data[i][0]\n",
    "    \n",
    "#     print(all(np.isclose(k, s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_data = GeneExpressionData(datafiles[1], labelfiles[1], 'Type', skip=3)\n",
    "# df2_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ec447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     k = df2.loc[df2_labels.loc[i, 'cell']]\n",
    "#     s = df2_data[i][0]\n",
    "    \n",
    "#     print(all(np.isclose(k, s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784700b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     k = df3.loc[df3_labels.loc[i, 'cell']]\n",
    "#     s = df3_data[i][0]\n",
    "    \n",
    "#     print(all(np.isclose(k, s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01af39bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     k = df4.loc[df4_labels.loc[i, 'cell']]\n",
    "#     s = df4_data[i][0]\n",
    "    \n",
    "#     print(all(np.isclose(k, s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed7aef",
   "metadata": {},
   "source": [
    "Now, let's write our training loop using all four datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b867a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders = [df1_data, df2_data, df3_data, df4_data]\n",
    "# loaders = [DataLoader(data, batch_size=2) for data in loaders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(loaders[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa69a80",
   "metadata": {},
   "source": [
    "Now, let's time the DataLoader vs the custom DataLoader from Pytorch Tabular found here: https://github.com/hcarlens/pytorch-tabular/blob/master/fast_tensor_data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = GeneExpressionData(datafiles[0], labelfiles[0], 'Type', skip=3)\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=4)\n",
    "fastloader = FastTensorDataLoader(train, batch_size=4)\n",
    "\n",
    "train, val, test = generate_single_dataset(datafiles[0], labelfiles[0], 'Type', skip=3, index_col='cell', cast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bee364",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders, valloaders, testloaders = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loaders(batch_size, num_workers):\n",
    "    traindata = []\n",
    "    for datafile, labelfile in zip(datafiles, labelfiles):\n",
    "        train, val, test = generate_single_dataset(\n",
    "            datafile,\n",
    "            labelfile,\n",
    "            'Type', \n",
    "            skip=3, \n",
    "            index_col='cell', \n",
    "            cast=True\n",
    "        )\n",
    "\n",
    "        traindata.append(\n",
    "            GeneExpressionData(\n",
    "                datafile,\n",
    "                labelfile,\n",
    "                'Type',\n",
    "                skip=3,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        trainloaders.append(\n",
    "            DataLoader(train, batch_size=batch_size, num_workers=num_workers)\n",
    "        )\n",
    "\n",
    "        valloaders.append(\n",
    "            DataLoader(val, batch_size=batch_size, num_workers=num_workers)\n",
    "        )\n",
    "\n",
    "        testloaders.append(\n",
    "            DataLoader(test, batch_size=batch_size, num_workers=num_workers)\n",
    "        )\n",
    "        \n",
    "        return trainloaders, valloaders, testloaders\n",
    "        \n",
    "trainloaders, valloaders, testloaders = gen_loaders(4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a652a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders[0].dataset.dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe7ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, sample in enumerate(tqdm(trainloader)):\n",
    "    X, y = sample \n",
    "    net(X)\n",
    "    if i == 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea916ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(tqdm(fastloader)):\n",
    "    t = sample\n",
    "    \n",
    "    if i == 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c1ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = next(iter(trainloaders[0]))[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc91f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_sample(X, refgenes, traindata[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "from torchmetrics.functional import accuracy, f1_score, precision, recall\n",
    "\n",
    "def calculate_metrics(\n",
    "    outputs, \n",
    "    labels,\n",
    "    num_classes,\n",
    "    append_str='',\n",
    ") -> Dict[str, float]:\n",
    "    metrics = {\n",
    "        'micro_accuracy': partial(accuracy, average='micro', num_classes=num_classes),\n",
    "        'macro_accuracy': partial(accuracy, average='macro', num_classes=num_classes),\n",
    "        'weighted_accuracy': partial(accuracy, average='weighted', num_classes=num_classes),\n",
    "        'f1': f1_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }\n",
    "    results = {}\n",
    "    \n",
    "    for name, metric in metrics.items():\n",
    "        res = metric(\n",
    "            preds=outputs,\n",
    "            target=labels,\n",
    "        )\n",
    "        \n",
    "        results[f\"{name}{f'_{append_str}' if append_str else ''}\"] = res\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103d9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "def _inner_computation(\n",
    "    data,\n",
    "    model, \n",
    "    optim,\n",
    "    loader,\n",
    "    wandb, \n",
    "    i, \n",
    "    running_loss,\n",
    "    mode=['train', 'val', 'test'],\n",
    "):\n",
    "    inputs, labels = data\n",
    "    inputs = clean_sample(inputs, refgenes, valloader.dataset.dataset.columns)\n",
    "\n",
    "    outputs = model(batch)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        # Backward pass ⬅\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        running_loss = 0.0\n",
    "        metric_results = calculate_metrics(\n",
    "            outputs=outputs,\n",
    "            labels=labels,\n",
    "            append_str=mode,\n",
    "            num_classes=model.N_labels\n",
    "        )\n",
    "\n",
    "        wandb.log({f\"{mode}_loss\": loss})\n",
    "        wandb.log(metric_results)\n",
    "    \n",
    "    return running_loss\n",
    "\n",
    "model = GeneClassifier(\n",
    "    N_features=len(refgenes),\n",
    "    N_labels=18,\n",
    ")\n",
    "\n",
    "wandb.init()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "wandb.watch(model, log_freq=100)\n",
    "\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Train loop\n",
    "    for trainidx, trainloader in enumerate(trainloaders):\n",
    "        model.train()\n",
    "        print(f'Training on {trainidx}')\n",
    "        \n",
    "        for i, data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # CLEAN INPUTS\n",
    "            inputs = clean_sample(inputs, refgenes, trainloader.dataset.dataset.columns)\n",
    "            \n",
    "            # Forward pass ➡\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass ⬅\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Step with optimizer\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                running_loss = 0.0\n",
    "                metric_results = calculate_metrics(\n",
    "                    outputs=outputs,\n",
    "                    labels=labels,\n",
    "                    append_str='train',\n",
    "                    num_classes=model.N_labels\n",
    "                )\n",
    "                wandb.log({\"train_loss\": loss})\n",
    "                wandb.log(metric_results)\n",
    "                \n",
    "    \n",
    "    # Validation loops \n",
    "    for validx, valloader in enumerate(valloaders):\n",
    "        model.eval()\n",
    "        \n",
    "        for i, data in enumerate(tqdm(valloader)):\n",
    "            inputs, labels = data\n",
    "            inputs = clean_sample(inputs, refgenes, valloader.dataset.dataset.columns)\n",
    "            \n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                running_loss = 0.0\n",
    "                metric_results = calculate_metrics(\n",
    "                    outputs=outputs,\n",
    "                    labels=labels,\n",
    "                    append_str='val',\n",
    "                    num_classes=model.N_labels\n",
    "                )\n",
    "                \n",
    "                wandb.log({\"val_loss\": loss})\n",
    "                wandb.log(metric_results)\n",
    "    \n",
    "print('Finished train/validation, calculating test error')\n",
    "\n",
    "for testidx, testloader in enumerate(testloaders):\n",
    "    model.eval()\n",
    "    \n",
    "    for i, data in enumerate(tqdm(testloader)):\n",
    "        inputs, labels = data\n",
    "        inputs = clean_sample(inputs, refgenes, valloader.dataset.dataset.columns)\n",
    "\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            running_loss = 0.0\n",
    "            metric_results = calculate_metrics(\n",
    "                outputs=outputs,\n",
    "                labels=labels,\n",
    "                append_str='test',\n",
    "                num_classes=model.N_labels\n",
    "            )\n",
    "\n",
    "            wandb.log({\"test_loss\": loss})\n",
    "            wandb.log(metric_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "91df5907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "75f0b626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'micro_accuracy_val': tensor(0.2000),\n",
       " 'macro_accuracy_val': tensor(0.2000),\n",
       " 'weighted_accuracy_val': tensor(0.2000),\n",
       " 'f1_val': tensor(0.2000),\n",
       " 'precision_val': tensor(0.2000),\n",
       " 'recall_val': tensor(0.2000)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "\n",
    "calculate_metrics(preds, target, 5, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "383b9321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# import our library\n",
    "import torchmetrics\n",
    "\n",
    "# simulate a classification problem\n",
    "preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "\n",
    "acc = torchmetrics.functional.accuracy(preds, target)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48794542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(batch, labels, model, optimizer, criterion):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass ➡\n",
    "    outputs = model(batch)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def validate_model(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test images: {100 * correct / total}%\")\n",
    "        \n",
    "        wandb.log({\"test_accuracy\": correct / total})\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    torch.onnx.export(model, images, \"model.onnx\")\n",
    "    wandb.save(\"model.onnx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2288df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell wandb to get started\n",
    "with wandb.init(project=\"pytorch-demo\", config=hyperparameters):\n",
    "  # access all HPs through wandb.config, so logging matches execution!\n",
    "  config = wandb.config\n",
    "\n",
    "  # make the model, data, and optimization problem\n",
    "  model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "\n",
    "  # and use them to train the model\n",
    "  train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "  # and test its final performance\n",
    "  test(model, test_loader)\n",
    "\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676d126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446198f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.randn(10, 5).softmax(dim=-1))\n",
    "torch.randint(5, (10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c45bb7",
   "metadata": {},
   "source": [
    "## Linecache speed testing \n",
    "\n",
    "If we can improve the speed of our __getitem__ method, we can train our model a lot faster. Since currently it requires two list comprehensions, let's see if we can increase the time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache \n",
    "\n",
    "line = linecache.getline('../data/interim/primary_bhaduri_T.csv', 5)\n",
    "line = np.array(line.split(','), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "line = linecache.getline('../data/interim/primary_bhaduri_T.csv', 5)\n",
    "line = np.array(line.split(','), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "line = df1_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e18ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
