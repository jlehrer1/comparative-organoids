{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling 01\n",
    "\n",
    "In this notebook, we'll begin building the classifier to show that Layer 4 neurons do not exist in the organoid data. We will do this in the following manner.\n",
    "\n",
    "1. Identify cells in the primary data by which layer of the cortex they are in.\n",
    "2. Train a classifier on the primary data.\n",
    "3. Under the assumption that the space of gene expression is the same in organoids, classify the organoid cells to their respective cortex layer and show that none get classified as layer 4.\n",
    "4. Conclude that layer 4 cells do not exist in the organoid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import umap\n",
    "import hdbscan\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary = pd.read_csv('primary_labels_test.csv')\n",
    "df = pd.read_csv('../data/processed/primary_reduction_neighbors_500_components_100.csv', index_col='Unnamed: 0')\n",
    "df['label'] = primary['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.174407</td>\n",
       "      <td>4.605017</td>\n",
       "      <td>5.700520</td>\n",
       "      <td>4.349964</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>4.443735</td>\n",
       "      <td>4.977513</td>\n",
       "      <td>1.097707</td>\n",
       "      <td>4.923816</td>\n",
       "      <td>5.728352</td>\n",
       "      <td>...</td>\n",
       "      <td>6.758616</td>\n",
       "      <td>3.999133</td>\n",
       "      <td>4.044898</td>\n",
       "      <td>4.987543</td>\n",
       "      <td>1.790490</td>\n",
       "      <td>4.197807</td>\n",
       "      <td>6.984423</td>\n",
       "      <td>9.260715</td>\n",
       "      <td>7.174916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.187639</td>\n",
       "      <td>4.608121</td>\n",
       "      <td>5.704485</td>\n",
       "      <td>4.363834</td>\n",
       "      <td>0.024695</td>\n",
       "      <td>4.443859</td>\n",
       "      <td>4.973516</td>\n",
       "      <td>1.105194</td>\n",
       "      <td>4.919911</td>\n",
       "      <td>5.728892</td>\n",
       "      <td>...</td>\n",
       "      <td>6.762886</td>\n",
       "      <td>3.999778</td>\n",
       "      <td>4.040472</td>\n",
       "      <td>4.999935</td>\n",
       "      <td>1.792208</td>\n",
       "      <td>4.192843</td>\n",
       "      <td>6.986716</td>\n",
       "      <td>9.258625</td>\n",
       "      <td>7.172100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.179722</td>\n",
       "      <td>4.631567</td>\n",
       "      <td>5.731539</td>\n",
       "      <td>4.270429</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>4.434293</td>\n",
       "      <td>4.971396</td>\n",
       "      <td>1.129670</td>\n",
       "      <td>4.909443</td>\n",
       "      <td>5.748357</td>\n",
       "      <td>...</td>\n",
       "      <td>6.765180</td>\n",
       "      <td>4.005325</td>\n",
       "      <td>4.039588</td>\n",
       "      <td>5.014343</td>\n",
       "      <td>1.786922</td>\n",
       "      <td>4.206350</td>\n",
       "      <td>6.986751</td>\n",
       "      <td>9.256733</td>\n",
       "      <td>7.179493</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.233760</td>\n",
       "      <td>4.637250</td>\n",
       "      <td>5.735640</td>\n",
       "      <td>4.311743</td>\n",
       "      <td>0.078151</td>\n",
       "      <td>4.433172</td>\n",
       "      <td>4.963012</td>\n",
       "      <td>1.207390</td>\n",
       "      <td>4.900370</td>\n",
       "      <td>5.740662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.769579</td>\n",
       "      <td>3.998335</td>\n",
       "      <td>4.026979</td>\n",
       "      <td>4.999375</td>\n",
       "      <td>1.817481</td>\n",
       "      <td>4.194461</td>\n",
       "      <td>6.987063</td>\n",
       "      <td>9.243600</td>\n",
       "      <td>7.164564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.188722</td>\n",
       "      <td>4.624152</td>\n",
       "      <td>5.721036</td>\n",
       "      <td>4.324148</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>4.437555</td>\n",
       "      <td>4.966181</td>\n",
       "      <td>1.132194</td>\n",
       "      <td>4.908939</td>\n",
       "      <td>5.740864</td>\n",
       "      <td>...</td>\n",
       "      <td>6.764676</td>\n",
       "      <td>4.001324</td>\n",
       "      <td>4.034964</td>\n",
       "      <td>5.004535</td>\n",
       "      <td>1.799192</td>\n",
       "      <td>4.201400</td>\n",
       "      <td>6.986776</td>\n",
       "      <td>9.252455</td>\n",
       "      <td>7.172283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.174407  4.605017  5.700520  4.349964  0.009240  4.443735  4.977513   \n",
       "1  1.187639  4.608121  5.704485  4.363834  0.024695  4.443859  4.973516   \n",
       "2  1.179722  4.631567  5.731539  4.270429  0.007747  4.434293  4.971396   \n",
       "3  1.233760  4.637250  5.735640  4.311743  0.078151  4.433172  4.963012   \n",
       "4  1.188722  4.624152  5.721036  4.324148  0.035837  4.437555  4.966181   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  1.097707  4.923816  5.728352  ...  6.758616  3.999133  4.044898  4.987543   \n",
       "1  1.105194  4.919911  5.728892  ...  6.762886  3.999778  4.040472  4.999935   \n",
       "2  1.129670  4.909443  5.748357  ...  6.765180  4.005325  4.039588  5.014343   \n",
       "3  1.207390  4.900370  5.740662  ...  6.769579  3.998335  4.026979  4.999375   \n",
       "4  1.132194  4.908939  5.740864  ...  6.764676  4.001324  4.034964  5.004535   \n",
       "\n",
       "         95        96        97        98        99  label  \n",
       "0  1.790490  4.197807  6.984423  9.260715  7.174916      1  \n",
       "1  1.792208  4.192843  6.986716  9.258625  7.172100      1  \n",
       "2  1.786922  4.206350  6.986751  9.256733  7.179493      5  \n",
       "3  1.817481  4.194461  6.987063  9.243600  7.164564      1  \n",
       "4  1.799192  4.201400  6.986776  9.252455  7.172283      1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we begin the classification process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=100, out_features=16)\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=12)\n",
    "        self.fc3 = nn.Linear(in_features=12, out_features=12)\n",
    "        self.output = nn.Linear(in_features=12, out_features=primary['label'].nunique())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined a basic fully connected neural network, let's split our data into training and testing sets, then use K-fold CV to tune the architecture of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis=1).values\n",
    "y = [x+1 for x in df['label'].values] # So we dont have a label value of -1, noise is now label=0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can define our loss function, optimization algorithmn and a model instance and get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneClassifier(\n",
       "  (fc1): Linear(in_features=100, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=12, bias=True)\n",
       "  (fc3): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (output): Linear(in_features=12, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GeneClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train our model and view the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 3.5600473880767822\n",
      "Epoch: 10 Loss: 2.6198201179504395\n",
      "Epoch: 20 Loss: 2.5391647815704346\n",
      "Epoch: 30 Loss: 2.5087063312530518\n",
      "Epoch: 40 Loss: 2.496829032897949\n",
      "Epoch: 50 Loss: 2.4914090633392334\n",
      "Epoch: 60 Loss: 2.486801862716675\n",
      "Epoch: 70 Loss: 2.481786012649536\n",
      "Epoch: 80 Loss: 2.475231647491455\n",
      "Epoch: 90 Loss: 2.464743137359619\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_arr = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_hat = model.forward(X_train)\n",
    "    loss = criterion(y_hat, y_train)\n",
    "    loss_arr.append(loss)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} Loss: {loss}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to train this model much more on the full feature space with regularization methods, so for now let's try some simpler models like SVM's and tree methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'C': [0.1, 0.25, 0.5, 0.75, 1],\n",
    "}\n",
    "\n",
    "est = GridSearchCV(svc, parameters, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "model = est.fit(X_train, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
