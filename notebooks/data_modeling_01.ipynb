{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling 01\n",
    "\n",
    "In this notebook, we'll begin building the classifier to show that Layer 4 neurons do not exist in the organoid data. We will do this in the following manner.\n",
    "\n",
    "1. Identify cells in the primary data by which layer of the cortex they are in.\n",
    "2. Train a classifier on the primary data.\n",
    "3. Under the assumption that the space of gene expression is the same in organoids, classify the organoid cells to their respective cortex layer and show that none get classified as layer 4.\n",
    "4. Conclude that layer 4 cells do not exist in the organoid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import umap\n",
    "import hdbscan\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary = pd.read_csv('primary_labels_test.csv')\n",
    "df = pd.read_csv('../data/processed/primary_reduction_neighbors_500_components_100.csv', index_col='Unnamed: 0')\n",
    "df['label'] = primary['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.174407</td>\n",
       "      <td>4.605017</td>\n",
       "      <td>5.700520</td>\n",
       "      <td>4.349964</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>4.443735</td>\n",
       "      <td>4.977513</td>\n",
       "      <td>1.097707</td>\n",
       "      <td>4.923816</td>\n",
       "      <td>5.728352</td>\n",
       "      <td>...</td>\n",
       "      <td>6.758616</td>\n",
       "      <td>3.999133</td>\n",
       "      <td>4.044898</td>\n",
       "      <td>4.987543</td>\n",
       "      <td>1.790490</td>\n",
       "      <td>4.197807</td>\n",
       "      <td>6.984423</td>\n",
       "      <td>9.260715</td>\n",
       "      <td>7.174916</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.187639</td>\n",
       "      <td>4.608121</td>\n",
       "      <td>5.704485</td>\n",
       "      <td>4.363834</td>\n",
       "      <td>0.024695</td>\n",
       "      <td>4.443859</td>\n",
       "      <td>4.973516</td>\n",
       "      <td>1.105194</td>\n",
       "      <td>4.919911</td>\n",
       "      <td>5.728892</td>\n",
       "      <td>...</td>\n",
       "      <td>6.762886</td>\n",
       "      <td>3.999778</td>\n",
       "      <td>4.040472</td>\n",
       "      <td>4.999935</td>\n",
       "      <td>1.792208</td>\n",
       "      <td>4.192843</td>\n",
       "      <td>6.986716</td>\n",
       "      <td>9.258625</td>\n",
       "      <td>7.172100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.179722</td>\n",
       "      <td>4.631567</td>\n",
       "      <td>5.731539</td>\n",
       "      <td>4.270429</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>4.434293</td>\n",
       "      <td>4.971396</td>\n",
       "      <td>1.129670</td>\n",
       "      <td>4.909443</td>\n",
       "      <td>5.748357</td>\n",
       "      <td>...</td>\n",
       "      <td>6.765180</td>\n",
       "      <td>4.005325</td>\n",
       "      <td>4.039588</td>\n",
       "      <td>5.014343</td>\n",
       "      <td>1.786922</td>\n",
       "      <td>4.206350</td>\n",
       "      <td>6.986751</td>\n",
       "      <td>9.256733</td>\n",
       "      <td>7.179493</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.233760</td>\n",
       "      <td>4.637250</td>\n",
       "      <td>5.735640</td>\n",
       "      <td>4.311743</td>\n",
       "      <td>0.078151</td>\n",
       "      <td>4.433172</td>\n",
       "      <td>4.963012</td>\n",
       "      <td>1.207390</td>\n",
       "      <td>4.900370</td>\n",
       "      <td>5.740662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.769579</td>\n",
       "      <td>3.998335</td>\n",
       "      <td>4.026979</td>\n",
       "      <td>4.999375</td>\n",
       "      <td>1.817481</td>\n",
       "      <td>4.194461</td>\n",
       "      <td>6.987063</td>\n",
       "      <td>9.243600</td>\n",
       "      <td>7.164564</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.188722</td>\n",
       "      <td>4.624152</td>\n",
       "      <td>5.721036</td>\n",
       "      <td>4.324148</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>4.437555</td>\n",
       "      <td>4.966181</td>\n",
       "      <td>1.132194</td>\n",
       "      <td>4.908939</td>\n",
       "      <td>5.740864</td>\n",
       "      <td>...</td>\n",
       "      <td>6.764676</td>\n",
       "      <td>4.001324</td>\n",
       "      <td>4.034964</td>\n",
       "      <td>5.004535</td>\n",
       "      <td>1.799192</td>\n",
       "      <td>4.201400</td>\n",
       "      <td>6.986776</td>\n",
       "      <td>9.252455</td>\n",
       "      <td>7.172283</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.174407  4.605017  5.700520  4.349964  0.009240  4.443735  4.977513   \n",
       "1  1.187639  4.608121  5.704485  4.363834  0.024695  4.443859  4.973516   \n",
       "2  1.179722  4.631567  5.731539  4.270429  0.007747  4.434293  4.971396   \n",
       "3  1.233760  4.637250  5.735640  4.311743  0.078151  4.433172  4.963012   \n",
       "4  1.188722  4.624152  5.721036  4.324148  0.035837  4.437555  4.966181   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  1.097707  4.923816  5.728352  ...  6.758616  3.999133  4.044898  4.987543   \n",
       "1  1.105194  4.919911  5.728892  ...  6.762886  3.999778  4.040472  4.999935   \n",
       "2  1.129670  4.909443  5.748357  ...  6.765180  4.005325  4.039588  5.014343   \n",
       "3  1.207390  4.900370  5.740662  ...  6.769579  3.998335  4.026979  4.999375   \n",
       "4  1.132194  4.908939  5.740864  ...  6.764676  4.001324  4.034964  5.004535   \n",
       "\n",
       "         95        96        97        98        99  label  \n",
       "0  1.790490  4.197807  6.984423  9.260715  7.174916      4  \n",
       "1  1.792208  4.192843  6.986716  9.258625  7.172100     11  \n",
       "2  1.786922  4.206350  6.986751  9.256733  7.179493      4  \n",
       "3  1.817481  4.194461  6.987063  9.243600  7.164564      5  \n",
       "4  1.799192  4.201400  6.986776  9.252455  7.172283     11  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we begin the classification process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=primary['label'].nunique()),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined a basic fully connected neural network, let's split our data into training and testing sets, then use K-fold CV to tune the architecture of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis=1).values\n",
    "y = [x+1 for x in df['label'].values] # So we dont have a label value of -1, noise is now label=0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can define our loss function, optimization algorithmn and a model instance and get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneClassifier(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GeneClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train our model and view the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.6625729203224182\n",
      "Epoch: 10 Loss: 0.6636262536048889\n",
      "Epoch: 20 Loss: 0.6549345850944519\n",
      "Epoch: 30 Loss: 0.7396190166473389\n",
      "Epoch: 40 Loss: 0.8023156523704529\n",
      "Epoch: 50 Loss: 0.7407172322273254\n",
      "Epoch: 60 Loss: 0.6607627868652344\n",
      "Epoch: 70 Loss: 0.6531257033348083\n",
      "Epoch: 80 Loss: 0.6486878395080566\n",
      "Epoch: 90 Loss: 0.6450058221817017\n",
      "Epoch: 100 Loss: 0.6437074542045593\n",
      "Epoch: 110 Loss: 0.6420813798904419\n",
      "Epoch: 120 Loss: 0.6447199583053589\n",
      "Epoch: 130 Loss: 0.6405091285705566\n",
      "Epoch: 140 Loss: 0.6597336530685425\n",
      "Epoch: 150 Loss: 0.6403116583824158\n",
      "Epoch: 160 Loss: 0.9066668152809143\n",
      "Epoch: 170 Loss: 0.8605571985244751\n",
      "Epoch: 180 Loss: 0.754325807094574\n",
      "Epoch: 190 Loss: 0.7094987034797668\n",
      "Epoch: 200 Loss: 0.6634676456451416\n",
      "Epoch: 210 Loss: 0.6649220585823059\n",
      "Epoch: 220 Loss: 0.6392096877098083\n",
      "Epoch: 230 Loss: 0.6396535634994507\n",
      "Epoch: 240 Loss: 0.6353840827941895\n",
      "Epoch: 250 Loss: 0.6343037486076355\n",
      "Epoch: 260 Loss: 0.6330943703651428\n",
      "Epoch: 270 Loss: 0.6323433518409729\n",
      "Epoch: 280 Loss: 0.6443999409675598\n",
      "Epoch: 290 Loss: 0.6314255595207214\n",
      "Epoch: 300 Loss: 0.7481669187545776\n",
      "Epoch: 310 Loss: 0.7080739140510559\n",
      "Epoch: 320 Loss: 0.7774653434753418\n",
      "Epoch: 330 Loss: 1.1170538663864136\n",
      "Epoch: 340 Loss: 0.8268944621086121\n",
      "Epoch: 350 Loss: 0.6700178384780884\n",
      "Epoch: 360 Loss: 0.6723244786262512\n",
      "Epoch: 370 Loss: 0.6448694467544556\n",
      "Epoch: 380 Loss: 0.6491237878799438\n",
      "Epoch: 390 Loss: 0.6401110291481018\n",
      "Epoch: 400 Loss: 0.6331391930580139\n",
      "Epoch: 410 Loss: 0.629314124584198\n",
      "Epoch: 420 Loss: 0.6277782320976257\n",
      "Epoch: 430 Loss: 0.6263673305511475\n",
      "Epoch: 440 Loss: 0.6249669790267944\n",
      "Epoch: 450 Loss: 0.6238082051277161\n",
      "Epoch: 460 Loss: 0.6228687763214111\n",
      "Epoch: 470 Loss: 0.6222406029701233\n",
      "Epoch: 480 Loss: 0.6220176219940186\n",
      "Epoch: 490 Loss: 0.6394098997116089\n",
      "Epoch: 500 Loss: 0.6208826899528503\n",
      "Epoch: 510 Loss: 1.0757184028625488\n",
      "Epoch: 520 Loss: 1.1891933679580688\n",
      "Epoch: 530 Loss: 0.7843870520591736\n",
      "Epoch: 540 Loss: 0.7213838696479797\n",
      "Epoch: 550 Loss: 0.6589199304580688\n",
      "Epoch: 560 Loss: 0.642697274684906\n",
      "Epoch: 570 Loss: 0.6377295851707458\n",
      "Epoch: 580 Loss: 0.6287500262260437\n",
      "Epoch: 590 Loss: 0.6253630518913269\n",
      "Epoch: 600 Loss: 0.6219373941421509\n",
      "Epoch: 610 Loss: 0.620405912399292\n",
      "Epoch: 620 Loss: 0.6189097762107849\n",
      "Epoch: 630 Loss: 0.6176095604896545\n",
      "Epoch: 640 Loss: 0.6166192293167114\n",
      "Epoch: 650 Loss: 0.6157231330871582\n",
      "Epoch: 660 Loss: 0.6149038672447205\n",
      "Epoch: 670 Loss: 0.6141422986984253\n",
      "Epoch: 680 Loss: 0.6134801506996155\n",
      "Epoch: 690 Loss: 0.6767310500144958\n",
      "Epoch: 700 Loss: 0.6315722465515137\n",
      "Epoch: 710 Loss: 0.6538081169128418\n",
      "Epoch: 720 Loss: 0.6284343004226685\n",
      "Epoch: 730 Loss: 0.623816192150116\n",
      "Epoch: 740 Loss: 0.6138958930969238\n",
      "Epoch: 750 Loss: 0.6097488403320312\n",
      "Epoch: 760 Loss: 2.6133062839508057\n",
      "Epoch: 770 Loss: 1.1952831745147705\n",
      "Epoch: 780 Loss: 0.8865591883659363\n",
      "Epoch: 790 Loss: 0.7495632767677307\n",
      "Epoch: 800 Loss: 0.6883408427238464\n",
      "Epoch: 810 Loss: 0.6583330631256104\n",
      "Epoch: 820 Loss: 0.6380744576454163\n",
      "Epoch: 830 Loss: 0.6267289519309998\n",
      "Epoch: 840 Loss: 0.6209760904312134\n",
      "Epoch: 850 Loss: 0.616277813911438\n",
      "Epoch: 860 Loss: 0.614067018032074\n",
      "Epoch: 870 Loss: 0.6124057173728943\n",
      "Epoch: 880 Loss: 0.6111286878585815\n",
      "Epoch: 890 Loss: 0.6100613474845886\n",
      "Epoch: 900 Loss: 0.6091216206550598\n",
      "Epoch: 910 Loss: 0.6082601547241211\n",
      "Epoch: 920 Loss: 0.6082959175109863\n",
      "Epoch: 930 Loss: 0.6103540062904358\n",
      "Epoch: 940 Loss: 0.6066542863845825\n",
      "Epoch: 950 Loss: 0.6066237688064575\n",
      "Epoch: 960 Loss: 0.6100614666938782\n",
      "Epoch: 970 Loss: 0.605257511138916\n",
      "Epoch: 980 Loss: 0.7187929749488831\n",
      "Epoch: 990 Loss: 0.6629422307014465\n",
      "Epoch: 1000 Loss: 0.622627317905426\n",
      "Epoch: 1010 Loss: 0.6063670516014099\n",
      "Epoch: 1020 Loss: 0.6033583879470825\n",
      "Epoch: 1030 Loss: 0.6023764610290527\n",
      "Epoch: 1040 Loss: 0.6340240836143494\n",
      "Epoch: 1050 Loss: 0.6022017598152161\n",
      "Epoch: 1060 Loss: 0.6440246105194092\n",
      "Epoch: 1070 Loss: 0.6165421009063721\n",
      "Epoch: 1080 Loss: 0.8832652568817139\n",
      "Epoch: 1090 Loss: 1.818029522895813\n",
      "Epoch: 1100 Loss: 1.3402109146118164\n",
      "Epoch: 1110 Loss: 0.9181477427482605\n",
      "Epoch: 1120 Loss: 0.7980234622955322\n",
      "Epoch: 1130 Loss: 0.6960757970809937\n",
      "Epoch: 1140 Loss: 0.6455771923065186\n",
      "Epoch: 1150 Loss: 0.6310817003250122\n",
      "Epoch: 1160 Loss: 0.6196852326393127\n",
      "Epoch: 1170 Loss: 0.6145983934402466\n",
      "Epoch: 1180 Loss: 0.6097208261489868\n",
      "Epoch: 1190 Loss: 0.6064637303352356\n",
      "Epoch: 1200 Loss: 0.6041464805603027\n",
      "Epoch: 1210 Loss: 0.6025002598762512\n",
      "Epoch: 1220 Loss: 0.601248562335968\n",
      "Epoch: 1230 Loss: 0.6003243923187256\n",
      "Epoch: 1240 Loss: 0.6012652516365051\n",
      "Epoch: 1250 Loss: 0.5990793704986572\n",
      "Epoch: 1260 Loss: 0.6122570633888245\n",
      "Epoch: 1270 Loss: 0.6032750010490417\n",
      "Epoch: 1280 Loss: 0.6564827561378479\n",
      "Epoch: 1290 Loss: 0.6215193867683411\n",
      "Epoch: 1300 Loss: 0.59944087266922\n",
      "Epoch: 1310 Loss: 0.5969792008399963\n",
      "Epoch: 1320 Loss: 0.6480309963226318\n",
      "Epoch: 1330 Loss: 0.6068717837333679\n",
      "Epoch: 1340 Loss: 0.6031467914581299\n",
      "Epoch: 1350 Loss: 0.7009357810020447\n",
      "Epoch: 1360 Loss: 0.9801787734031677\n",
      "Epoch: 1370 Loss: 0.674709141254425\n",
      "Epoch: 1380 Loss: 0.9450618624687195\n",
      "Epoch: 1390 Loss: 0.7811224460601807\n",
      "Epoch: 1400 Loss: 0.6923832893371582\n",
      "Epoch: 1410 Loss: 0.6642712950706482\n",
      "Epoch: 1420 Loss: 0.6261776685714722\n",
      "Epoch: 1430 Loss: 0.6161395907402039\n",
      "Epoch: 1440 Loss: 0.6061306595802307\n",
      "Epoch: 1450 Loss: 0.6047145128250122\n",
      "Epoch: 1460 Loss: 0.60211580991745\n",
      "Epoch: 1470 Loss: 0.6000038981437683\n",
      "Epoch: 1480 Loss: 0.5984668731689453\n",
      "Epoch: 1490 Loss: 0.5974003672599792\n",
      "Epoch: 1500 Loss: 0.5963841080665588\n",
      "Epoch: 1510 Loss: 0.5954853296279907\n",
      "Epoch: 1520 Loss: 0.5946362614631653\n",
      "Epoch: 1530 Loss: 0.593833863735199\n",
      "Epoch: 1540 Loss: 0.5930611491203308\n",
      "Epoch: 1550 Loss: 0.5923027992248535\n",
      "Epoch: 1560 Loss: 0.5915927886962891\n",
      "Epoch: 1570 Loss: 0.590809166431427\n",
      "Epoch: 1580 Loss: 0.5900536179542542\n",
      "Epoch: 1590 Loss: 0.5897397398948669\n",
      "Epoch: 1600 Loss: 0.59516841173172\n",
      "Epoch: 1610 Loss: 0.5922399759292603\n",
      "Epoch: 1620 Loss: 0.5939512848854065\n",
      "Epoch: 1630 Loss: 0.6134325861930847\n",
      "Epoch: 1640 Loss: 0.5987024903297424\n",
      "Epoch: 1650 Loss: 0.599632740020752\n",
      "Epoch: 1660 Loss: 0.6095840930938721\n",
      "Epoch: 1670 Loss: 0.6037495732307434\n",
      "Epoch: 1680 Loss: 0.618230402469635\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_39833/2905317386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_39833/2455761905.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "loss_arr = []\n",
    "stop_tol = 50\n",
    "stopping = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_hat = model.forward(X_train)\n",
    "    loss = criterion(y_hat, y_train)\n",
    "    loss_arr.append(loss)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} Loss: {loss}')\n",
    "    \n",
    "    if i > 1:\n",
    "        if loss_arr[i].item() > loss_arr[i-1].item():\n",
    "            stopping += 1\n",
    "        else:\n",
    "            stopping = (0 if stopping == 0 else stopping - 1)\n",
    "    \n",
    "    if stopping == stop_tol:\n",
    "        print(f'Reached stopping criterion at iteration {i}')\n",
    "        break\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(loss_arr)), [x.item() for x in loss_arr]);\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Loss');\n",
    "plt.title('Loss vs Epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to train this model much more on the full feature space with regularization methods, so for now let's try some simpler models like SVM's and tree methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "parameters = {\n",
    "    'C': [0.1, 0.25, 0.5, 0.75, 1],\n",
    "}\n",
    "\n",
    "est = GridSearchCV(svc, parameters, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START C=0.1.......................................................\n"
     ]
    }
   ],
   "source": [
    "model = est.fit(X_train, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
