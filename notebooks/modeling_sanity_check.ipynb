{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5ff669",
   "metadata": {},
   "source": [
    "# Modeling Sanity Check: Making sure everything is ok\n",
    "\n",
    "In this notebook, we'll test our entire network pipeline because SURELY there are bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a997b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd \n",
    "import torch\n",
    "import linecache \n",
    "import csv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "sys.path.append('../src/')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123cab6",
   "metadata": {},
   "source": [
    "Let's define our custom data class and make sure everything is being streamed in correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c92b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lib.data import GeneExpressionData\n",
    "from models.lib.neural import GeneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77a771e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186476, 19765)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = GeneExpressionData(\n",
    "    filename='../data/interim/primary_bhaduri_T.csv',\n",
    "    labelname='../data/processed/labels/primary_bhaduri_labels.csv',\n",
    "    class_label='Type',\n",
    "    skip=3,\n",
    ")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb5aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. input_dim = 19765, output_dim = 17. Metrics are dict_keys(['accuracy', 'precision', 'recall']) and weighted_metrics = False\n"
     ]
    }
   ],
   "source": [
    "model = GeneClassifier(\n",
    "    input_dim = len(data.columns),\n",
    "    output_dim = max(data.labels), # Since indexed from zero\n",
    "#     weights=data.class_weights,\n",
    "    optim_params={\n",
    "        'optimizer': torch.optim.SGD,\n",
    "        'lr': 0.001,\n",
    "#         'momentum': 1e-4,\n",
    "#         'weight_decay': 1e-4\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84aeecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  4,  9, 11,  6,  8,  7,  3, 17])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccbc953",
   "metadata": {},
   "source": [
    "Now that we have our dataset, at least make sure a forward pass is computing correctly, and that our model can at least overfit on a small subset of the training set. Therefore, we'll subset our dataset and create the train and val loaders this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7994ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "tr_10k = Subset(data, range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b442539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data):\n",
    "    train_size = int(0.80 * len(data))\n",
    "    test_size = len(data) - train_size\n",
    "\n",
    "    train, test = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "\n",
    "    traindata = DataLoader(train, batch_size=4)\n",
    "    valdata = DataLoader(test, batch_size=4)\n",
    "    \n",
    "    return traindata, valdata\n",
    "\n",
    "train, test = train_test(tr_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f8f9343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.dataset), len(test.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cd5ebf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cols',\n",
       " '_is_protocol',\n",
       " '_labeldf',\n",
       " 'cast',\n",
       " 'class_label',\n",
       " 'class_weights',\n",
       " 'columns',\n",
       " 'features',\n",
       " 'filename',\n",
       " 'functions',\n",
       " 'index_col',\n",
       " 'indices',\n",
       " 'labelname',\n",
       " 'labels',\n",
       " 'register_datapipe_as_function',\n",
       " 'register_function',\n",
       " 'sep',\n",
       " 'shape',\n",
       " 'skip']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train.dataset.dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31378354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     122958\n",
       "16     29563\n",
       "7      20609\n",
       "8       4510\n",
       "6       3863\n",
       "17      2451\n",
       "11      1888\n",
       "9        363\n",
       "3        271\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dataset.dataset.dataset._labeldf['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0281be",
   "metadata": {},
   "source": [
    "Even though we'll ultimately be using PyTorch Lightning for GPU training, let's try writing the training loop here so we can debug each step. To do this, we'll need to redefine the optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e43af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/julian/Documents/Projects/organoid-classification/notebooks/wandb/run-20220419_131047-3skezxji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks/runs/3skezxji\" target=\"_blank\">effortless-oath-49</a></strong> to <a href=\"https://wandb.ai/jlehrer1/organoid-classification-notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type                 | Params\n",
      "----------------------------------------------------\n",
      "0 | base_model | TabNetGeneClassifier | 1.3 M \n",
      "----------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/miniconda3/envs/base-data-science/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/julian/miniconda3/envs/base-data-science/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cddb7e4fe04465a079602565c1da76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "logger = WandbLogger()\n",
    "\n",
    "run = Trainer(max_epochs=2000, logger=logger)\n",
    "run.fit(model, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fb01c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science] *",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
